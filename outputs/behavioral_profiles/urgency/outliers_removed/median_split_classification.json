{
  "median_sophistication": 6.157009803921566,
  "n_high_sophistication": 22,
  "n_low_sophistication": 22,
  "models": [
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.660588235294117,
        "warmth": 5.176274509803922,
        "tribalism": 1.189607843137255,
        "authenticity": 3.3007843137254915,
        "depth": 4.535490196078431,
        "hedging": 3.9537254901960788,
        "grandiosity": 1.718627450980392,
        "aggression": 1.378627450980392,
        "transgression": 1.377058823529411,
        "sophistication": 3.9181372549019615
      },
      "sophistication": 3.9181372549019615,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4159803921568626
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.47078431372549,
        "warmth": 5.463725490196078,
        "tribalism": 1.0588235294117647,
        "authenticity": 3.960784313725491,
        "depth": 4.849607843137256,
        "hedging": 6.143921568627448,
        "grandiosity": 2.483921568627451,
        "aggression": 1.41078431372549,
        "transgression": 1.2209803921568623,
        "sophistication": 4.4051960784313735
      },
      "sophistication": 4.4051960784313735,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.543627450980392
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "formality": 8.070784313725488,
        "warmth": 5.084705882352942,
        "tribalism": 1.1568627450980393,
        "authenticity": 3.8035294117647074,
        "depth": 5.359607843137256,
        "hedging": 4.339019607843138,
        "grandiosity": 2.2809803921568625,
        "aggression": 1.3396078431372547,
        "transgression": 1.35156862745098,
        "sophistication": 4.581568627450982
      },
      "sophistication": 4.581568627450982,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5322549019607843
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.53607843137255,
        "warmth": 5.794117647058824,
        "tribalism": 1.0196078431372548,
        "authenticity": 4.483725490196077,
        "depth": 4.891568627450982,
        "hedging": 8.457254901960786,
        "grandiosity": 2.0752941176470587,
        "aggression": 1.5945098039215686,
        "transgression": 1.2999999999999996,
        "sophistication": 4.687647058823529
      },
      "sophistication": 4.687647058823529,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4973529411764703
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.052352941176471,
        "warmth": 4.940980392156863,
        "tribalism": 1.006470588235294,
        "authenticity": 4.150000000000001,
        "depth": 5.241960784313725,
        "hedging": 5.5492156862745095,
        "grandiosity": 2.078823529411765,
        "aggression": 1.5878431372549018,
        "transgression": 1.3323529411764703,
        "ribalism": 1.0,
        "observational_specificity": 1.0,
        "sophistication": 4.695980392156863
      },
      "sophistication": 4.695980392156863,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.501372549019608
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "formality": 4.7570588235294125,
        "warmth": 2.8370588235294116,
        "tribalism": 1.252352941176471,
        "authenticity": 4.639411764705884,
        "depth": 4.765294117647057,
        "hedging": 2.889803921568627,
        "grandiosity": 2.4376470588235293,
        "aggression": 2.6198039215686273,
        "transgression": 2.5558823529411767,
        "sophistication": 4.702352941176471
      },
      "sophistication": 4.702352941176471,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.2164215686274513
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "formality": 8.03862745098039,
        "warmth": 5.314313725490194,
        "tribalism": 1.0196078431372548,
        "authenticity": 3.9149019607843143,
        "depth": 5.49,
        "hedging": 4.659607843137256,
        "grandiosity": 2.0398039215686277,
        "aggression": 1.2672549019607842,
        "transgression": 1.3774509803921564,
        "sophistication": 4.7024509803921575
      },
      "sophistication": 4.7024509803921575,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4260294117647057
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.888627450980393,
        "warmth": 5.202352941176471,
        "tribalism": 1.0913725490196078,
        "authenticity": 3.99980392156863,
        "depth": 5.510196078431372,
        "hedging": 4.3537254901960765,
        "grandiosity": 1.9343137254901959,
        "aggression": 1.2350980392156863,
        "transgression": 1.3125490196078429,
        "sophistication": 4.755000000000001
      },
      "sophistication": 4.755000000000001,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.393333333333333
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "formality": 8.425294117647061,
        "warmth": 4.757450980392159,
        "tribalism": 1.1305882352941177,
        "authenticity": 4.007058823529409,
        "depth": 5.620588235294118,
        "hedging": 3.5950980392156855,
        "grandiosity": 2.69921568627451,
        "aggression": 1.5288235294117645,
        "transgression": 1.3252941176470583,
        "ribalism": 1.0,
        "sophistication": 4.8138235294117635
      },
      "sophistication": 4.8138235294117635,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6709803921568627
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "formality": 8.110980392156863,
        "warmth": 4.6529411764705895,
        "tribalism": 1.17,
        "authenticity": 4.136666666666667,
        "depth": 5.750392156862745,
        "hedging": 3.5094117647058845,
        "grandiosity": 2.9735294117647064,
        "aggression": 1.8035294117647056,
        "transgression": 1.6588235294117644,
        "sophistication": 4.943529411764706
      },
      "sophistication": 4.943529411764706,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.901470588235294
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "formality": 8.10470588235294,
        "warmth": 4.182156862745101,
        "tribalism": 1.1374509803921569,
        "authenticity": 4.2937254901960795,
        "depth": 5.686078431372549,
        "hedging": 4.01313725490196,
        "grandiosity": 3.241568627450979,
        "aggression": 1.960392156862745,
        "transgression": 1.5603921568627441,
        "observability": 7.0,
        "sophistication": 4.989901960784314
      },
      "sophistication": 4.989901960784314,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.9749509803921563
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "formality": 8.261960784313725,
        "warmth": 4.314117647058823,
        "tribalism": 1.2941176470588236,
        "authenticity": 4.32,
        "depth": 5.660588235294116,
        "hedging": 3.012941176470588,
        "grandiosity": 4.137058823529413,
        "aggression": 2.3327450980392155,
        "transgression": 1.6988235294117644,
        "sophistication": 4.990294117647059
      },
      "sophistication": 4.990294117647059,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.3656862745098044
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.235490196078432,
        "warmth": 4.287843137254903,
        "tribalism": 1.1437254901960785,
        "authenticity": 4.34,
        "depth": 5.698823529411766,
        "hedging": 4.039019607843137,
        "grandiosity": 3.275294117647058,
        "aggression": 2.215686274509804,
        "transgression": 1.7641176470588231,
        "sophistication": 5.0194117647058825
      },
      "sophistication": 5.0194117647058825,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.099705882352941
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "formality": 8.098039215686274,
        "warmth": 4.640196078431373,
        "tribalism": 1.2350980392156863,
        "authenticity": 4.142941176470589,
        "depth": 5.9017647058823535,
        "hedging": 3.607450980392157,
        "grandiosity": 2.561764705882353,
        "aggression": 1.8494117647058823,
        "transgression": 1.5217647058823527,
        "sophistication": 5.022352941176472
      },
      "sophistication": 5.022352941176472,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.7920098039215686
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 4.914509803921568,
        "warmth": 3.2941176470588247,
        "tribalism": 1.3660784313725491,
        "authenticity": 4.987450980392156,
        "depth": 5.129803921568628,
        "hedging": 3.0921568627450977,
        "grandiosity": 2.6272549019607845,
        "aggression": 2.822745098039215,
        "transgression": 2.712156862745098,
        "sophistication": 5.058627450980392
      },
      "sophistication": 5.058627450980392,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.3820588235294116
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "formality": 8.42529411764706,
        "warmth": 3.7384313725490195,
        "tribalism": 1.3005882352941176,
        "authenticity": 4.327058823529413,
        "depth": 5.954117647058824,
        "hedging": 2.875686274509805,
        "grandiosity": 3.104313725490196,
        "aggression": 2.392156862745098,
        "transgression": 1.5735294117647054,
        "sophistication": 5.140588235294119
      },
      "sophistication": 5.140588235294119,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.092647058823529
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "formality": 8.085490196078432,
        "warmth": 4.261176470588235,
        "tribalism": 1.150392156862745,
        "authenticity": 4.280980392156864,
        "depth": 6.000588235294116,
        "hedging": 4.117843137254901,
        "grandiosity": 2.3537254901960787,
        "aggression": 1.599803921568627,
        "transgression": 1.417254901960784,
        "sophistication": 5.14078431372549
      },
      "sophistication": 5.14078431372549,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.630294117647059
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.74607843137255,
        "warmth": 4.92764705882353,
        "tribalism": 1.1241176470588234,
        "authenticity": 4.561960784313726,
        "depth": 5.954509803921569,
        "hedging": 3.392549019607843,
        "grandiosity": 2.366078431372549,
        "aggression": 1.5552941176470587,
        "transgression": 1.5539215686274503,
        "triability": 1.0,
        "sophistication": 5.258235294117648
      },
      "sophistication": 5.258235294117648,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6498529411764704
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "formality": 8.621176470588233,
        "warmth": 4.581372549019609,
        "tribalism": 1.1568627450980393,
        "authenticity": 4.346666666666668,
        "depth": 6.483529411764705,
        "hedging": 3.516078431372548,
        "grandiosity": 2.8625490196078434,
        "aggression": 1.6988235294117644,
        "transgression": 1.358039215686274,
        "sophistication": 5.415098039215686
      },
      "sophistication": 5.415098039215686,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.7690686274509804
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.44470588235294,
        "warmth": 4.7509803921568645,
        "tribalism": 1.1370588235294117,
        "authenticity": 5.15764705882353,
        "depth": 6.307058823529413,
        "hedging": 3.633725490196079,
        "grandiosity": 2.5284313725490195,
        "aggression": 1.8492156862745095,
        "transgression": 1.5937254901960782,
        "sophistication": 5.7323529411764715
      },
      "sophistication": 5.7323529411764715,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.7771078431372547
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.811176470588236,
        "warmth": 4.849215686274511,
        "tribalism": 1.1633333333333333,
        "authenticity": 5.000000000000001,
        "depth": 6.48313725490196,
        "hedging": 3.7839215686274508,
        "grandiosity": 2.235686274509804,
        "aggression": 1.8431372549019607,
        "transgression": 1.6792156862745098,
        "sophistication": 5.741568627450981
      },
      "sophistication": 5.741568627450981,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.730343137254902
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "formality": 6.901960784313726,
        "warmth": 4.489607843137256,
        "tribalism": 1.4050980392156864,
        "authenticity": 5.66098039215686,
        "depth": 6.621176470588232,
        "hedging": 3.1505882352941166,
        "grandiosity": 3.058627450980393,
        "aggression": 2.947450980392157,
        "transgression": 2.1370588235294115,
        "sophistication": 6.141078431372546
      },
      "sophistication": 6.141078431372546,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 2.387058823529412
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.6731372549019605,
        "warmth": 4.025882352941178,
        "tribalism": 1.4570588235294115,
        "authenticity": 5.555490196078429,
        "depth": 6.790392156862744,
        "hedging": 2.549019607843137,
        "grandiosity": 4.019803921568627,
        "aggression": 3.359215686274509,
        "transgression": 2.065294117647059,
        "sophistication": 6.172941176470586
      },
      "sophistication": 6.172941176470586,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.7253431372549017
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "formality": 8.170392156862745,
        "warmth": 4.5943137254901965,
        "tribalism": 1.4376470588235293,
        "authenticity": 5.5621568627450975,
        "depth": 7.234705882352939,
        "hedging": 3.176470588235295,
        "grandiosity": 4.333333333333334,
        "aggression": 2.515098039215686,
        "transgression": 1.8823529411764706,
        "sophistication": 6.398431372549018
      },
      "sophistication": 6.398431372549018,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.542107843137255
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "formality": 6.921176470588237,
        "warmth": 5.6005882352941185,
        "tribalism": 1.5356862745098039,
        "authenticity": 5.869411764705883,
        "depth": 6.98156862745098,
        "hedging": 3.856470588235294,
        "grandiosity": 2.673333333333333,
        "aggression": 2.2674509803921565,
        "transgression": 2.0513725490196077,
        "sophistication": 6.425490196078432
      },
      "sophistication": 6.425490196078432,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.1319607843137254
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "formality": 7.702745098039215,
        "warmth": 3.6105882352941183,
        "tribalism": 1.7254901960784315,
        "authenticity": 6.280980392156862,
        "depth": 7.01607843137255,
        "hedging": 2.4184313725490196,
        "grandiosity": 4.536078431372549,
        "aggression": 4.154117647058825,
        "transgression": 2.944117647058824,
        "sophistication": 6.648529411764706
      },
      "sophistication": 6.648529411764706,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.3399509803921568
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.68607843137255,
        "warmth": 4.855294117647061,
        "tribalism": 1.3462745098039215,
        "authenticity": 6.268627450980389,
        "depth": 7.046078431372547,
        "hedging": 3.2221568627450985,
        "grandiosity": 2.9213725490196074,
        "aggression": 2.8560784313725485,
        "transgression": 2.411372549019607,
        "sophistication": 6.657352941176468
      },
      "sophistication": 6.657352941176468,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.3837745098039207
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "formality": 8.019803921568629,
        "warmth": 4.70607843137255,
        "tribalism": 1.1372549019607843,
        "authenticity": 5.836274509803922,
        "depth": 7.497254901960784,
        "hedging": 3.0911764705882354,
        "grandiosity": 2.8888235294117632,
        "aggression": 1.7703921568627448,
        "transgression": 1.5682352941176472,
        "sophistication": 6.666764705882353
      },
      "sophistication": 6.666764705882353,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.841176470588235
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.183725490196077,
        "warmth": 5.364509803921571,
        "tribalism": 1.2090196078431372,
        "authenticity": 6.522941176470589,
        "depth": 7.209215686274508,
        "hedging": 4.176666666666667,
        "grandiosity": 2.6013725490196076,
        "aggression": 2.9990196078431377,
        "transgression": 2.1892156862745096,
        "sophistication": 6.866078431372548
      },
      "sophistication": 6.866078431372548,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.249656862745098
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.640588235294117,
        "warmth": 4.542745098039215,
        "tribalism": 1.7190196078431372,
        "authenticity": 6.496666666666667,
        "depth": 7.280784313725489,
        "hedging": 2.666470588235294,
        "grandiosity": 3.7649019607843126,
        "aggression": 3.502941176470589,
        "transgression": 2.9939215686274503,
        "sophistication": 6.888725490196078
      },
      "sophistication": 6.888725490196078,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.9951960784313725
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.77470588235294,
        "warmth": 5.196078431372549,
        "tribalism": 1.2876470588235294,
        "authenticity": 6.522745098039216,
        "depth": 7.418823529411766,
        "hedging": 3.058823529411766,
        "grandiosity": 2.673333333333333,
        "aggression": 3.124117647058823,
        "transgression": 2.5488235294117647,
        "sophistication": 6.970784313725491
      },
      "sophistication": 6.970784313725491,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.4084803921568625
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.058627450980393,
        "warmth": 4.626862745098041,
        "tribalism": 1.6603921568627453,
        "authenticity": 6.862745098039215,
        "depth": 7.281372549019605,
        "hedging": 3.60078431372549,
        "grandiosity": 3.5680392156862752,
        "aggression": 4.411372549019608,
        "transgression": 3.1576470588235295,
        "tribalalism": 0.0,
        "sophistication": 7.07205882352941
      },
      "sophistication": 7.07205882352941,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.199362745098039
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.705490196078429,
        "warmth": 4.300196078431372,
        "tribalism": 1.532156862745098,
        "authenticity": 6.412156862745099,
        "depth": 7.737843137254903,
        "hedging": 2.594313725490196,
        "grandiosity": 3.3460784313725505,
        "aggression": 2.3327450980392155,
        "transgression": 2.15,
        "ribalism": 1.0,
        "sophistication": 7.075000000000001
      },
      "sophistication": 7.075000000000001,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.340245098039216
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.300392156862745,
        "warmth": 4.424901960784314,
        "tribalism": 1.3233333333333333,
        "authenticity": 6.476470588235295,
        "depth": 7.836470588235294,
        "hedging": 2.7658823529411767,
        "grandiosity": 2.869019607843138,
        "aggression": 2.266470588235294,
        "transgression": 1.953333333333333,
        "sophistication": 7.156470588235294
      },
      "sophistication": 7.156470588235294,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.1030392156862745
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "formality": 6.922156862745098,
        "warmth": 4.7768627450980405,
        "tribalism": 1.4376470588235293,
        "authenticity": 6.7845098039215666,
        "depth": 7.908823529411763,
        "hedging": 2.908431372549019,
        "grandiosity": 2.5815686274509804,
        "aggression": 2.3521568627450975,
        "transgression": 2.277254901960784,
        "sophistication": 7.346666666666665
      },
      "sophistication": 7.346666666666665,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.162156862745098
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.594901960784314,
        "warmth": 4.071764705882353,
        "tribalism": 1.9013725490196078,
        "authenticity": 7.170196078431372,
        "depth": 7.6147058823529425,
        "hedging": 2.6533333333333333,
        "grandiosity": 4.182941176470586,
        "aggression": 4.516078431372549,
        "transgression": 3.7315686274509794,
        "sophistication": 7.392450980392157
      },
      "sophistication": 7.392450980392157,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.5829901960784305
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "formality": 7.647450980392158,
        "warmth": 3.1825490196078436,
        "tribalism": 2.4570588235294117,
        "authenticity": 7.11705882352941,
        "depth": 7.712352941176469,
        "hedging": 2.1115686274509806,
        "grandiosity": 5.425490196078429,
        "aggression": 4.54235294117647,
        "transgression": 3.794509803921568,
        "tribalisms": 3.0,
        "sophistication": 7.41470588235294
      },
      "sophistication": 7.41470588235294,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 4.0548529411764695
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "formality": 6.712352941176469,
        "warmth": 4.95372549019608,
        "tribalism": 1.3692156862745097,
        "authenticity": 6.927843137254901,
        "depth": 8.006666666666668,
        "hedging": 2.791372549019608,
        "grandiosity": 2.4315686274509805,
        "aggression": 2.235098039215686,
        "transgression": 2.1305882352941174,
        "sophistication": 7.467254901960784
      },
      "sophistication": 7.467254901960784,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.0416176470588234
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.307254901960785,
        "warmth": 4.908039215686275,
        "tribalism": 1.3660784313725491,
        "authenticity": 7.4315686274509805,
        "depth": 7.569019607843137,
        "hedging": 3.7058823529411757,
        "grandiosity": 3.385882352941177,
        "aggression": 4.444313725490197,
        "transgression": 3.463725490196079,
        "sophistication": 7.500294117647059
      },
      "sophistication": 7.500294117647059,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.165000000000001
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.045882352941177,
        "warmth": 5.2931372549019615,
        "tribalism": 1.539019607843137,
        "authenticity": 6.869411764705883,
        "depth": 8.150980392156862,
        "hedging": 2.9803921568627447,
        "grandiosity": 2.4964705882352938,
        "aggression": 2.267058823529412,
        "transgression": 2.0845098039215686,
        "sophistication": 7.510196078431372
      },
      "sophistication": 7.510196078431372,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.096764705882353
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "formality": 8.158039215686276,
        "warmth": 3.346470588235295,
        "tribalism": 2.555490196078431,
        "authenticity": 7.255098039215685,
        "depth": 7.875882352941173,
        "hedging": 2.058627450980392,
        "grandiosity": 5.901568627450981,
        "aggression": 4.738823529411764,
        "transgression": 3.450980392156863,
        "sophistication": 7.565490196078429
      },
      "sophistication": 7.565490196078429,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 4.16171568627451
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.66627450980392,
        "warmth": 4.333921568627448,
        "tribalism": 1.607843137254902,
        "authenticity": 7.35980392156863,
        "depth": 7.771568627450981,
        "hedging": 2.8427450980392153,
        "grandiosity": 3.587647058823529,
        "aggression": 4.202352941176472,
        "transgression": 3.8231372549019613,
        "sophistication": 7.5656862745098055
      },
      "sophistication": 7.5656862745098055,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.305245098039216
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.078039215686274,
        "warmth": 5.182549019607844,
        "tribalism": 1.3784313725490194,
        "authenticity": 8.260980392156862,
        "depth": 8.143529411764707,
        "hedging": 4.313529411764706,
        "grandiosity": 3.9076470588235286,
        "aggression": 4.810784313725488,
        "transgression": 4.333529411764706,
        "sophistication": 8.202254901960785
      },
      "sophistication": 8.202254901960785,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.6075980392156857
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.516274509803923,
        "warmth": 4.671960784313728,
        "tribalism": 1.666470588235294,
        "authenticity": 8.332352941176469,
        "depth": 8.221960784313728,
        "hedging": 4.313333333333334,
        "grandiosity": 4.176470588235293,
        "aggression": 5.646862745098041,
        "transgression": 4.47764705882353,
        "sophistication": 8.277156862745098
      },
      "sophistication": 8.277156862745098,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 3.9918627450980395
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 4.571319073083779,
      "high_std": 0.6339226882712385,
      "low_mean": 4.615490196078431,
      "low_std": 0.6894161543886277,
      "difference": -0.0441711229946522,
      "pct_difference": -0.9570191056235449,
      "t_statistic": -0.22121379258203716,
      "p_value": 0.8259979515480287,
      "cohens_d": -0.06669846804055653
    },
    "formality": {
      "high_mean": 7.1129768270944735,
      "high_std": 0.6045992706315786,
      "low_mean": 7.75735294117647,
      "low_std": 1.0215193508261788,
      "difference": -0.6443761140819966,
      "pct_difference": -8.306649432715787,
      "t_statistic": -2.546178197681229,
      "p_value": 0.01464757879346788,
      "cohens_d": -0.7677016119174543
    },
    "hedging": {
      "high_mean": 3.084358288770053,
      "high_std": 0.6585751441758472,
      "low_mean": 4.076631016042781,
      "low_std": 1.268418277111783,
      "difference": -0.9922727272727281,
      "pct_difference": -24.340508703579832,
      "t_statistic": -3.2564924686571164,
      "p_value": 0.002234776021805114,
      "cohens_d": -0.981869422832168
    },
    "aggression": {
      "high_mean": 3.423404634581105,
      "high_std": 1.1153566528210113,
      "low_mean": 1.8560338680926913,
      "low_std": 0.4985829829336106,
      "difference": 1.5673707664884138,
      "pct_difference": 84.44731496732248,
      "t_statistic": 6.017423401847274,
      "p_value": 3.74922778875733e-07,
      "cohens_d": 1.8143214207846716
    },
    "transgression": {
      "high_mean": 2.794688057040998,
      "high_std": 0.8602116224961917,
      "low_mean": 1.6082709447415326,
      "low_std": 0.39101771821470166,
      "difference": 1.1864171122994653,
      "pct_difference": 73.76972867529706,
      "t_statistic": 5.889213901924274,
      "p_value": 5.732443701307262e-07,
      "cohens_d": 1.7756648020752455
    },
    "grandiosity": {
      "high_mean": 3.5578520499108732,
      "high_std": 0.9492305509736754,
      "low_mean": 2.594295900178253,
      "low_std": 0.5516288633842725,
      "difference": 0.9635561497326202,
      "pct_difference": 37.141335715267275,
      "t_statistic": 4.116563670108162,
      "p_value": 0.00017590787847733658,
      "cohens_d": 1.2411906472142855
    },
    "tribalism": {
      "high_mean": 1.574982174688057,
      "high_std": 0.35259391391746636,
      "low_mean": 1.1686007130124776,
      "low_std": 0.10585814806945629,
      "difference": 0.4063814616755794,
      "pct_difference": 34.77504823935875,
      "t_statistic": 5.177618505143889,
      "p_value": 5.969544172210317e-06,
      "cohens_d": 1.5611107171966445
    },
    "depth": {
      "high_mean": 7.559367201426025,
      "high_std": 0.41537147379125233,
      "low_mean": 5.631631016042781,
      "low_std": 0.5752797789470231,
      "difference": 1.9277361853832442,
      "pct_difference": 34.230512970251745,
      "t_statistic": 12.742883279930581,
      "p_value": 5.059944639064263e-16,
      "cohens_d": 3.8421238715293717
    },
    "authenticity": {
      "high_mean": 6.7352495543672015,
      "high_std": 0.7400422009885295,
      "low_mean": 4.355276292335116,
      "low_std": 0.510095456069995,
      "difference": 2.3799732620320855,
      "pct_difference": 54.645746958020055,
      "t_statistic": 12.41982311282236,
      "p_value": 1.1926470996265652e-15,
      "cohens_d": 3.7447175661650554
    },
    "sophistication": {
      "high_mean": 7.147308377896612,
      "high_std": 0.5437286567486996,
      "low_mean": 4.99345365418895,
      "low_std": 0.4798198862127264,
      "difference": 2.1538547237076626,
      "pct_difference": 43.13356792449288,
      "t_statistic": 13.931227538175232,
      "p_value": 2.4109323779225605e-17,
      "cohens_d": 4.200423146653982
    },
    "disinhibition": {
      "high_mean": 2.837731729055258,
      "high_std": 0.7303564865398894,
      "low_mean": 1.806800356506239,
      "low_std": 0.3264140548869023,
      "difference": 1.0309313725490192,
      "pct_difference": 57.058399885558096,
      "t_statistic": 6.044528046368599,
      "p_value": 3.427221683099546e-07,
      "cohens_d": 1.8224937785985988
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.5700356663934227
  }
}