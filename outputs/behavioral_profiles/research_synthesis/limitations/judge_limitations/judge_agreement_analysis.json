{
  "generated": "2026-01-11T11:14:09.162007",
  "n_evaluations_scanned": 10570,
  "n_valid_3_judge": 10565,
  "by_dimension": {
    "warmth": {
      "n": 10565,
      "mean_r": 0.7858609952867939,
      "mean_mad": 1.2032181732134406,
      "mean_exact": 0.3072724404480202,
      "mean_within1": 0.7022874270389652,
      "icc_single": 0.7215219384551691,
      "icc_avg": 0.8860118460512401
    },
    "formality": {
      "n": 10565,
      "mean_r": 0.6315243622745871,
      "mean_mad": 1.328411421359836,
      "mean_exact": 0.27436504180470106,
      "mean_within1": 0.6693800283956461,
      "icc_single": 0.4661020112798071,
      "icc_avg": 0.7236844647425319
    },
    "hedging": {
      "n": 10565,
      "mean_r": 0.8161043540471772,
      "mean_mad": 1.4119577220381763,
      "mean_exact": 0.2513014671083767,
      "mean_within1": 0.6134406057737815,
      "icc_single": 0.7433672960589168,
      "icc_avg": 0.8967993187714813
    },
    "aggression": {
      "n": 10565,
      "mean_r": 0.8348914384742784,
      "mean_mad": 0.432938949361098,
      "mean_exact": 0.6637955513487932,
      "mean_within1": 0.940589998422464,
      "icc_single": 0.8209405720532754,
      "icc_avg": 0.9322227540984701
    },
    "transgression": {
      "n": 10562,
      "mean_r": 0.6484135005190635,
      "mean_mad": 0.671337499211008,
      "mean_exact": 0.5224704916998043,
      "mean_within1": 0.893296724105283,
      "icc_single": 0.6141099615701614,
      "icc_avg": 0.8268168979092568
    },
    "grandiosity": {
      "n": 10565,
      "mean_r": 0.6856949859637366,
      "mean_mad": 0.8393752957879791,
      "mean_exact": 0.3828995109638744,
      "mean_within1": 0.8372613976967976,
      "icc_single": 0.6180313914527223,
      "icc_avg": 0.8291780483681394
    },
    "tribalism": {
      "n": 10420,
      "mean_r": 0.6622059120947034,
      "mean_mad": 0.19680102367242483,
      "mean_exact": 0.877575175943698,
      "mean_within1": 0.9549584133077417,
      "icc_single": 0.6575121925917842,
      "icc_avg": 0.8520586609799108
    },
    "depth": {
      "n": 10563,
      "mean_r": 0.7507142989515426,
      "mean_mad": 1.3820253084666605,
      "mean_exact": 0.2411877938716905,
      "mean_within1": 0.6185111552904794,
      "icc_single": 0.5916456974168665,
      "icc_avg": 0.8129639023222407
    },
    "authenticity": {
      "n": 10554,
      "mean_r": 0.6931268021498013,
      "mean_mad": 1.3694333901838165,
      "mean_exact": 0.23488724654159557,
      "mean_within1": 0.6141115532815363,
      "icc_single": 0.6116357940190634,
      "icc_avg": 0.8253185944216382
    }
  },
  "overall": {
    "mean_pairwise_r": 0.7231707388624093,
    "mean_icc_single": 0.6494296505441963,
    "mean_icc_avg": 0.8427838319627677,
    "mean_mad": 0.9817220870327156,
    "mean_exact_agreement": 0.4173060799700615,
    "mean_within1_agreement": 0.760426367034744
  },
  "interpretation": {
    "icc_scale": {
      "excellent": "> 0.90",
      "good": "0.75-0.90",
      "moderate": "0.50-0.75",
      "poor": "< 0.50"
    }
  }
}