{
  "median_sophistication": 5.016041666666667,
  "n_high_sophistication": 23,
  "n_low_sophistication": 23,
  "models": [
    {
      "model_id": "llama-3-70b",
      "display_name": "Llama-3-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 2.021333333333333,
        "transgression": 1.011,
        "tribalism": 1.0,
        "formality": 3.1666666666666665,
        "depth": 1.011,
        "authenticity": 1.1656666666666664,
        "aggression": 1.0443333333333333,
        "warmth": 1.0996666666666666,
        "grandiosity": 1.0,
        "sophistication": 1.0883333333333332
      },
      "sophistication": 1.0883333333333332,
      "n_contributions": 30,
      "classification": "Low-Sophistication",
      "disinhibition": 1.0138333333333334
    },
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "hedging": 3.3233333333333333,
        "transgression": 1.2574999999999994,
        "tribalism": 1.0091666666666665,
        "formality": 5.851944444444444,
        "depth": 3.666111111111111,
        "authenticity": 3.3061111111111114,
        "aggression": 1.1566666666666665,
        "warmth": 4.870277777777781,
        "grandiosity": 1.2769444444444442,
        "ribalism": 1.0,
        "sophistication": 3.486111111111111
      },
      "sophistication": 3.486111111111111,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.175069444444444
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "hedging": 4.267500000000001,
        "transgression": 1.2763888888888884,
        "tribalism": 1.1480555555555556,
        "formality": 6.842500000000001,
        "depth": 3.9719444444444445,
        "authenticity": 3.204166666666667,
        "aggression": 1.2122222222222219,
        "warmth": 5.222222222222223,
        "grandiosity": 1.4249999999999998,
        "sophistication": 3.588055555555556
      },
      "sophistication": 3.588055555555556,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2654166666666664
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "hedging": 4.2683333333333335,
        "transgression": 1.3038888888888884,
        "tribalism": 1.1019444444444444,
        "formality": 6.9719444444444445,
        "depth": 4.073055555555555,
        "authenticity": 3.186111111111112,
        "aggression": 1.1294444444444443,
        "warmth": 5.481944444444443,
        "grandiosity": 1.405555555555555,
        "sophistication": 3.6295833333333336
      },
      "sophistication": 3.6295833333333336,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.235208333333333
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.148055555555555,
        "transgression": 1.166111111111111,
        "tribalism": 1.1388888888888888,
        "formality": 6.453333333333335,
        "depth": 4.1019444444444435,
        "authenticity": 3.2591666666666668,
        "aggression": 1.1752777777777776,
        "warmth": 5.610000000000003,
        "grandiosity": 1.4524999999999997,
        "ribalism": 1.0,
        "sophistication": 3.6805555555555554
      },
      "sophistication": 3.6805555555555554,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2331944444444445
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.083333333333332,
        "transgression": 1.2113888888888884,
        "tribalism": 1.1016666666666666,
        "formality": 7.277777777777778,
        "depth": 4.139444444444444,
        "authenticity": 3.2225,
        "aggression": 1.1569444444444443,
        "warmth": 5.546666666666664,
        "grandiosity": 1.628333333333333,
        "sophistication": 3.680972222222222
      },
      "sophistication": 3.680972222222222,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2745833333333332
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "hedging": 4.245000000000001,
        "transgression": 1.2949999999999995,
        "tribalism": 1.1111111111111112,
        "formality": 6.773055555555556,
        "depth": 4.124722222222222,
        "authenticity": 3.2411111111111115,
        "aggression": 1.1569444444444443,
        "warmth": 5.162222222222223,
        "grandiosity": 1.4152777777777774,
        "sophistication": 3.682916666666667
      },
      "sophistication": 3.682916666666667,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2445833333333332
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "hedging": 4.518333333333332,
        "transgression": 1.2763888888888884,
        "tribalism": 1.0833333333333333,
        "formality": 6.981944444444445,
        "depth": 4.148888888888888,
        "authenticity": 3.2602777777777785,
        "aggression": 1.1838888888888885,
        "warmth": 5.675555555555557,
        "grandiosity": 1.5174999999999996,
        "sophistication": 3.7045833333333333
      },
      "sophistication": 3.7045833333333333,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2652777777777775
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "hedging": 4.388333333333333,
        "transgression": 1.3594444444444438,
        "tribalism": 1.0925,
        "formality": 6.778055555555556,
        "depth": 4.120555555555556,
        "authenticity": 3.342777777777778,
        "aggression": 1.2674999999999998,
        "warmth": 5.35138888888889,
        "grandiosity": 1.6191666666666662,
        "sophistication": 3.731666666666667
      },
      "sophistication": 3.731666666666667,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3346527777777775
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.990277777777777,
        "transgression": 1.3499999999999994,
        "tribalism": 1.0833333333333333,
        "formality": 6.602499999999998,
        "depth": 4.166388888888889,
        "authenticity": 3.315,
        "aggression": 1.1566666666666663,
        "warmth": 5.731111111111112,
        "grandiosity": 1.5538888888888882,
        "sophistication": 3.7406944444444443
      },
      "sophistication": 3.7406944444444443,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2859722222222219
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.13,
        "transgression": 1.2766666666666664,
        "tribalism": 1.1388888888888888,
        "formality": 7.213333333333332,
        "depth": 4.221388888888888,
        "authenticity": 3.2697222222222226,
        "aggression": 1.1755555555555555,
        "warmth": 5.148611111111111,
        "grandiosity": 1.4625,
        "observability": 5.0,
        "sophistication": 3.7455555555555553
      },
      "sophistication": 3.7455555555555553,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2634027777777777
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.638055555555557,
        "transgression": 1.2116666666666662,
        "tribalism": 1.0647222222222221,
        "formality": 7.278611111111112,
        "depth": 4.471944444444445,
        "authenticity": 3.3052777777777775,
        "aggression": 1.1561111111111106,
        "warmth": 5.166111111111111,
        "grandiosity": 1.4811111111111108,
        "sophistication": 3.8886111111111115
      },
      "sophistication": 3.8886111111111115,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2284027777777773
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.57361111111111,
        "transgression": 1.2849999999999993,
        "tribalism": 1.1016666666666666,
        "formality": 7.074166666666667,
        "depth": 4.48138888888889,
        "authenticity": 3.499722222222222,
        "aggression": 1.2027777777777775,
        "warmth": 5.463333333333334,
        "grandiosity": 1.545833333333333,
        "sophistication": 3.9905555555555563
      },
      "sophistication": 3.9905555555555563,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2838194444444442
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.100833333333336,
        "transgression": 1.3133333333333328,
        "tribalism": 1.0091666666666665,
        "formality": 6.934722222222223,
        "depth": 4.5088888888888885,
        "authenticity": 3.5091666666666668,
        "aggression": 1.1105555555555555,
        "warmth": 5.916944444444444,
        "grandiosity": 1.470555555555555,
        "sophistication": 4.009027777777778
      },
      "sophistication": 4.009027777777778,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2259027777777773
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "hedging": 4.185555555555555,
        "transgression": 1.2763888888888884,
        "tribalism": 1.0602777777777779,
        "formality": 6.722777777777777,
        "depth": 4.638611111111111,
        "authenticity": 3.639166666666667,
        "aggression": 1.2399999999999998,
        "warmth": 5.71277777777778,
        "grandiosity": 1.5172222222222218,
        "ribalism": 1.0,
        "sophistication": 4.138888888888889
      },
      "sophistication": 4.138888888888889,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.273472222222222
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.083055555555556,
        "transgression": 1.2947222222222219,
        "tribalism": 1.1016666666666666,
        "formality": 7.074166666666667,
        "depth": 4.685555555555556,
        "authenticity": 3.6199999999999997,
        "aggression": 1.1477777777777778,
        "warmth": 6.092222222222222,
        "grandiosity": 1.6377777777777776,
        "sophistication": 4.152777777777778
      },
      "sophistication": 4.152777777777778,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.295486111111111
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.5186111111111114,
        "transgression": 1.3227777777777774,
        "tribalism": 1.0183333333333333,
        "formality": 7.323611111111112,
        "depth": 4.9350000000000005,
        "authenticity": 3.8888888888888897,
        "aggression": 1.138333333333333,
        "warmth": 5.833333333333334,
        "grandiosity": 1.6013888888888888,
        "sophistication": 4.411944444444445
      },
      "sophistication": 4.411944444444445,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2702083333333332
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.980857142857146,
        "transgression": 1.4362857142857135,
        "tribalism": 1.0188571428571427,
        "formality": 7.198857142857143,
        "depth": 5.047999999999999,
        "authenticity": 3.8100000000000005,
        "aggression": 1.228,
        "warmth": 5.752285714285714,
        "grandiosity": 1.5994285714285712,
        "sophistication": 4.429
      },
      "sophistication": 4.429,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.320642857142857
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.416388888888888,
        "transgression": 1.2491666666666665,
        "tribalism": 1.0091666666666665,
        "formality": 6.786111111111111,
        "depth": 5.120555555555555,
        "authenticity": 3.9352777777777783,
        "aggression": 1.1288888888888886,
        "warmth": 6.120277777777779,
        "grandiosity": 1.5274999999999999,
        "sophistication": 4.527916666666666
      },
      "sophistication": 4.527916666666666,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2286805555555553
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.055555555555556,
        "transgression": 1.2577777777777774,
        "tribalism": 1.0230555555555556,
        "formality": 7.43416666666667,
        "depth": 5.20361111111111,
        "authenticity": 3.9269444444444446,
        "aggression": 1.1755555555555555,
        "warmth": 6.212777777777777,
        "grandiosity": 1.5641666666666663,
        "ribalism": 1.0,
        "sophistication": 4.565277777777777
      },
      "sophistication": 4.565277777777777,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2551388888888886
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "transgression": 1.3847368421052628,
        "hedging": 5.422105263157896,
        "tribalism": 1.0173684210526315,
        "depth": 5.280526315789474,
        "aggression": 1.0868421052631578,
        "grandiosity": 1.4531578947368418,
        "warmth": 5.40421052631579,
        "formality": 7.296842105263157,
        "authenticity": 3.9468421052631584,
        "sophistication": 4.613684210526316
      },
      "sophistication": 4.613684210526316,
      "n_contributions": 19,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2355263157894736
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "hedging": 4.555833333333333,
        "transgression": 1.266666666666666,
        "tribalism": 1.0647222222222221,
        "formality": 7.268055555555557,
        "depth": 5.518055555555556,
        "authenticity": 4.222499999999998,
        "aggression": 1.1291666666666664,
        "warmth": 6.370000000000001,
        "grandiosity": 1.6300000000000003,
        "sophistication": 4.870277777777777
      },
      "sophistication": 4.870277777777777,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2726388888888887
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.4166666666666665,
        "transgression": 1.4813888888888889,
        "tribalism": 1.0283333333333335,
        "formality": 5.472222222222223,
        "depth": 5.157777777777778,
        "authenticity": 4.693611111111112,
        "aggression": 1.3416666666666663,
        "warmth": 4.749722222222221,
        "grandiosity": 1.6477777777777776,
        "sophistication": 4.925694444444445
      },
      "sophistication": 4.925694444444445,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3747916666666666
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "hedging": 4.833055555555557,
        "transgression": 1.2763888888888884,
        "tribalism": 1.046388888888889,
        "formality": 7.110555555555556,
        "depth": 5.749722222222224,
        "authenticity": 4.463055555555555,
        "aggression": 1.0833333333333333,
        "warmth": 6.591944444444446,
        "grandiosity": 1.666388888888889,
        "sophistication": 5.1063888888888895
      },
      "sophistication": 5.1063888888888895,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.268125
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "hedging": 4.259166666666667,
        "transgression": 1.4522222222222219,
        "tribalism": 1.0644444444444445,
        "formality": 7.2213888888888915,
        "depth": 6.018333333333334,
        "authenticity": 4.731666666666669,
        "aggression": 1.258611111111111,
        "warmth": 5.471944444444445,
        "grandiosity": 1.6649999999999991,
        "sophistication": 5.375000000000002
      },
      "sophistication": 5.375000000000002,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.360069444444444
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "hedging": 4.397777777777779,
        "transgression": 1.3880555555555552,
        "tribalism": 1.0555555555555556,
        "formality": 7.3611111111111125,
        "depth": 6.1013888888888905,
        "authenticity": 4.657777777777778,
        "aggression": 1.2683333333333333,
        "warmth": 5.5280555555555555,
        "grandiosity": 1.564444444444444,
        "sophistication": 5.3795833333333345
      },
      "sophistication": 5.3795833333333345,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.319097222222222
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.426666666666666,
        "transgression": 1.369722222222222,
        "tribalism": 1.0369444444444444,
        "formality": 6.611111111111112,
        "depth": 6.148333333333331,
        "authenticity": 4.676111111111111,
        "aggression": 1.1758333333333333,
        "warmth": 5.971666666666668,
        "grandiosity": 1.527222222222222,
        "sophistication": 5.412222222222221
      },
      "sophistication": 5.412222222222221,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2774305555555556
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.971666666666667,
        "transgression": 1.2949999999999997,
        "tribalism": 1.1111111111111112,
        "formality": 7.287222222222222,
        "depth": 6.101388888888888,
        "authenticity": 4.786944444444444,
        "aggression": 1.1013888888888888,
        "warmth": 6.26861111111111,
        "grandiosity": 1.6202777777777775,
        "sophistication": 5.444166666666666
      },
      "sophistication": 5.444166666666666,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2819444444444443
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.268888888888889,
        "transgression": 1.266666666666666,
        "tribalism": 1.0927777777777778,
        "formality": 7.64777777777778,
        "depth": 6.379999999999999,
        "authenticity": 4.7313888888888895,
        "aggression": 1.1566666666666663,
        "warmth": 6.277222222222223,
        "grandiosity": 1.6669444444444446,
        "sophistication": 5.555694444444445
      },
      "sophistication": 5.555694444444445,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2957638888888887
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "hedging": 4.656111111111112,
        "transgression": 1.8144444444444443,
        "tribalism": 1.3055555555555556,
        "formality": 6.972499999999999,
        "depth": 6.101666666666668,
        "authenticity": 5.092777777777776,
        "aggression": 1.712777777777778,
        "warmth": 6.832500000000001,
        "grandiosity": 2.1391666666666667,
        "ribalism": 1.0,
        "observance": 3.0,
        "sophistication": 5.597222222222222
      },
      "sophistication": 5.597222222222222,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.7429861111111111
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.1113888888888885,
        "transgression": 1.3041666666666663,
        "tribalism": 1.0833333333333333,
        "formality": 7.600833333333335,
        "depth": 6.593055555555557,
        "authenticity": 4.9352777777777765,
        "aggression": 1.166111111111111,
        "warmth": 5.850555555555558,
        "grandiosity": 1.666111111111111,
        "sophistication": 5.764166666666666
      },
      "sophistication": 5.764166666666666,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3049305555555555
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.444444444444443,
        "transgression": 1.4063888888888885,
        "tribalism": 1.0552777777777778,
        "formality": 6.787222222222223,
        "depth": 6.4622222222222225,
        "authenticity": 5.102499999999998,
        "aggression": 1.258333333333333,
        "warmth": 6.129999999999999,
        "grandiosity": 1.535833333333333,
        "sophistication": 5.78236111111111
      },
      "sophistication": 5.78236111111111,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.313958333333333
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.324166666666666,
        "transgression": 1.489722222222222,
        "tribalism": 1.0277777777777777,
        "formality": 6.990000000000002,
        "depth": 6.555277777777777,
        "authenticity": 5.073888888888889,
        "aggression": 1.1475,
        "warmth": 6.0183333333333335,
        "grandiosity": 1.5919444444444444,
        "sophistication": 5.814583333333333
      },
      "sophistication": 5.814583333333333,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.314236111111111
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.371428571428572,
        "transgression": 1.398285714285714,
        "tribalism": 1.0759999999999998,
        "formality": 6.95285714285714,
        "depth": 6.523142857142857,
        "authenticity": 5.161428571428572,
        "aggression": 1.2465714285714284,
        "warmth": 6.199714285714288,
        "grandiosity": 1.561142857142857,
        "sophistication": 5.8422857142857145
      },
      "sophistication": 5.8422857142857145,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3204999999999996
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.611111111111111,
        "transgression": 1.4616666666666662,
        "tribalism": 1.0552777777777775,
        "formality": 6.861388888888888,
        "depth": 6.7411111111111115,
        "authenticity": 5.2225,
        "aggression": 1.212222222222222,
        "warmth": 6.25888888888889,
        "grandiosity": 1.5177777777777774,
        "sophistication": 5.981805555555556
      },
      "sophistication": 5.981805555555556,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3117361111111108
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.852222222222222,
        "transgression": 1.592222222222222,
        "tribalism": 1.0836111111111113,
        "formality": 5.620277777777779,
        "depth": 6.351944444444445,
        "authenticity": 5.67611111111111,
        "aggression": 1.3236111111111108,
        "warmth": 5.454166666666666,
        "grandiosity": 1.5463888888888888,
        "sophistication": 6.014027777777778
      },
      "sophistication": 6.014027777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3864583333333331
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "hedging": 4.212777777777777,
        "transgression": 1.2949999999999997,
        "tribalism": 1.1575,
        "formality": 7.314444444444446,
        "depth": 6.795277777777779,
        "authenticity": 5.379444444444445,
        "aggression": 1.2311111111111108,
        "warmth": 6.68527777777778,
        "grandiosity": 1.6849999999999998,
        "sophistication": 6.087361111111112
      },
      "sophistication": 6.087361111111112,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3421527777777775
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.73138888888889,
        "transgression": 1.4802777777777774,
        "tribalism": 1.0925,
        "formality": 6.703333333333335,
        "depth": 6.703333333333333,
        "authenticity": 5.481944444444446,
        "aggression": 1.2683333333333333,
        "warmth": 6.369722222222225,
        "grandiosity": 1.6194444444444442,
        "sophistication": 6.09263888888889
      },
      "sophistication": 6.09263888888889,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.365138888888889
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.435000000000001,
        "transgression": 1.535833333333333,
        "tribalism": 1.1199999999999999,
        "formality": 6.425833333333333,
        "depth": 6.824166666666667,
        "authenticity": 5.713055555555556,
        "aggression": 1.323333333333333,
        "warmth": 6.185277777777777,
        "grandiosity": 1.5452777777777775,
        "sophistication": 6.268611111111111
      },
      "sophistication": 6.268611111111111,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.381111111111111
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.3052777777777775,
        "transgression": 1.5916666666666661,
        "tribalism": 1.1016666666666666,
        "formality": 6.481111111111111,
        "depth": 7.0183333333333335,
        "authenticity": 5.870277777777777,
        "aggression": 1.3511111111111112,
        "warmth": 6.249166666666667,
        "grandiosity": 1.6197222222222216,
        "sophistication": 6.444305555555555
      },
      "sophistication": 6.444305555555555,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4160416666666664
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.166388888888889,
        "transgression": 1.4058333333333328,
        "tribalism": 1.138611111111111,
        "formality": 6.898888888888888,
        "depth": 7.38888888888889,
        "authenticity": 6.009722222222219,
        "aggression": 1.2305555555555554,
        "warmth": 6.073611111111113,
        "grandiosity": 1.7033333333333331,
        "sophistication": 6.699305555555554
      },
      "sophistication": 6.699305555555554,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.369583333333333
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.17611111111111,
        "transgression": 1.4627777777777777,
        "tribalism": 1.1202777777777777,
        "formality": 6.732222222222222,
        "depth": 7.546111111111113,
        "authenticity": 6.286666666666667,
        "aggression": 1.305,
        "warmth": 6.462500000000001,
        "grandiosity": 1.7405555555555554,
        "sophistication": 6.91638888888889
      },
      "sophistication": 6.91638888888889,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4071527777777777
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "hedging": 3.9905555555555554,
        "transgression": 1.406944444444444,
        "tribalism": 1.073888888888889,
        "formality": 6.620833333333333,
        "depth": 7.621388888888887,
        "authenticity": 6.370555555555556,
        "aggression": 1.3230555555555554,
        "warmth": 6.268611111111109,
        "grandiosity": 1.8247222222222221,
        "sophistication": 6.995972222222221
      },
      "sophistication": 6.995972222222221,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4071527777777777
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.102500000000001,
        "transgression": 1.8519444444444442,
        "tribalism": 1.111388888888889,
        "formality": 6.389166666666668,
        "depth": 7.444444444444445,
        "authenticity": 6.573611111111111,
        "aggression": 1.5088888888888887,
        "warmth": 6.009444444444444,
        "grandiosity": 1.7213888888888889,
        "sophistication": 7.009027777777778
      },
      "sophistication": 7.009027777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.5484027777777776
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.064722222222221,
        "transgression": 1.4388888888888887,
        "tribalism": 1.1202777777777777,
        "formality": 6.564444444444445,
        "depth": 7.723055555555557,
        "authenticity": 6.4174999999999995,
        "aggression": 1.2858333333333332,
        "warmth": 6.1575,
        "grandiosity": 1.7677777777777777,
        "sophistication": 7.070277777777778
      },
      "sophistication": 7.070277777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4031944444444444
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.175277777777777,
        "transgression": 2.408055555555556,
        "tribalism": 1.323888888888889,
        "formality": 6.109722222222223,
        "depth": 7.611666666666666,
        "authenticity": 6.9725,
        "aggression": 2.1386111111111115,
        "warmth": 6.027777777777777,
        "grandiosity": 2.018888888888889,
        "sophistication": 7.292083333333333
      },
      "sophistication": 7.292083333333333,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.9723611111111112
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 6.145325741890961,
      "high_std": 0.3485916033168491,
      "low_mean": 5.3779853437942675,
      "low_std": 1.0209607233497962,
      "difference": 0.7673403980966933,
      "pct_difference": 14.26817570230343,
      "t_statistic": 3.4111314530045793,
      "p_value": 0.0013970391516861266,
      "cohens_d": 1.0058877882649835
    },
    "formality": {
      "high_mean": 6.83757591442374,
      "high_std": 0.47373389025352997,
      "low_mean": 6.729450691947259,
      "low_std": 0.9064787454318509,
      "difference": 0.10812522247648015,
      "pct_difference": 1.606746633954348,
      "t_statistic": 0.5069890968875974,
      "p_value": 0.6146940500341154,
      "cohens_d": 0.14950292838862406
    },
    "hedging": {
      "high_mean": 4.34296066252588,
      "high_std": 0.274536023749084,
      "low_mean": 4.318737495913699,
      "low_std": 0.7383717371332762,
      "difference": 0.024223166612181046,
      "pct_difference": 0.560885366038119,
      "t_statistic": 0.14746941168926364,
      "p_value": 0.8834352141752145,
      "cohens_d": 0.043486357064953775
    },
    "aggression": {
      "high_mean": 1.3077011732229125,
      "high_std": 0.22457168068102779,
      "low_mean": 1.1696139079583012,
      "low_std": 0.0617932889204065,
      "difference": 0.13808726526461124,
      "pct_difference": 11.806226338882958,
      "t_statistic": 2.843244920509488,
      "p_value": 0.006748303129913109,
      "cohens_d": 0.8384271858147878
    },
    "transgression": {
      "high_mean": 1.4953119392684606,
      "high_std": 0.24930308542900725,
      "low_mean": 1.2853777923068537,
      "low_std": 0.0922852842262605,
      "difference": 0.20993414696160695,
      "pct_difference": 16.33248592111121,
      "t_statistic": 3.7873352717187005,
      "p_value": 0.000458251860431385,
      "cohens_d": 1.1168242421532881
    },
    "grandiosity": {
      "high_mean": 1.6745545203588679,
      "high_std": 0.15269017396737347,
      "low_mean": 1.4970689767898002,
      "low_std": 0.14260519139844033,
      "difference": 0.17748554356906765,
      "pct_difference": 11.855535471027796,
      "t_statistic": 4.0741043010064075,
      "p_value": 0.00018989125706045303,
      "cohens_d": 1.2013878154389293
    },
    "tribalism": {
      "high_mean": 1.10669806763285,
      "high_std": 0.07349745528414911,
      "low_mean": 1.0663576332134683,
      "low_std": 0.04767643147707511,
      "difference": 0.04034043441938162,
      "pct_difference": 3.7830117366737213,
      "t_statistic": 2.208348523701319,
      "p_value": 0.03247604289934233,
      "cohens_d": 0.6512064524126034
    },
    "depth": {
      "high_mean": 6.717576259489305,
      "high_std": 0.5909268812660625,
      "low_mean": 4.38240694126621,
      "low_std": 0.8893281884756072,
      "difference": 2.3351693182230946,
      "pct_difference": 53.28508624414494,
      "t_statistic": 10.488441790273669,
      "p_value": 1.5036553016470639e-13,
      "cohens_d": 3.092872749149442
    },
    "authenticity": {
      "high_mean": 5.451595928226363,
      "high_std": 0.7116754832064947,
      "low_mean": 3.4682612509534705,
      "low_std": 0.6345464059483079,
      "difference": 1.9833346772728921,
      "pct_difference": 57.18527336219691,
      "t_statistic": 9.975775287142655,
      "p_value": 7.199672228966248e-13,
      "cohens_d": 2.941695644995987
    },
    "sophistication": {
      "high_mean": 6.084586093857833,
      "high_std": 0.640525338030368,
      "low_mean": 3.9253340961098395,
      "low_std": 0.7542085644516882,
      "difference": 2.159251997747994,
      "pct_difference": 55.00810745989487,
      "t_statistic": 10.465331706142761,
      "p_value": 1.6124851459347298e-13,
      "cohens_d": 3.0860579571271116
    },
    "disinhibition": {
      "high_mean": 1.3960664251207726,
      "high_std": 0.16188728855183182,
      "low_mean": 1.2546045775671062,
      "low_std": 0.0667875983760203,
      "difference": 0.14146184755366642,
      "pct_difference": 11.27541299331023,
      "t_statistic": 3.8740031355374307,
      "p_value": 0.0003520569422610407,
      "cohens_d": 1.1423812009076877
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.724085318706599
  }
}