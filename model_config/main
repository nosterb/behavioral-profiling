# Main Model List
# Add * at the beginning of a line to mark a model for execution in batch jobs
# Format: [*]provider:model_id:display_name

# === AWS BEDROCK MODELS (Inference Profiles - Required for on-demand) ===

# Claude 4.5 Models (Latest)
*bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0:Claude-4.5-Sonnet
bedrock:global.anthropic.claude-opus-4-5-20251101-v1:0:Claude-4.5-Opus-Global

# Claude 4 Models
*bedrock:us.anthropic.claude-sonnet-4-20250514-v1:0:Claude-4-Sonnet
*bedrock:us.anthropic.claude-opus-4-1-20250805-v1:0:Claude-4.1-Opus
*bedrock:us.anthropic.claude-opus-4-20250514-v1:0:Claude-4-Opus
*bedrock:us.anthropic.claude-haiku-4-5-20251001-v1:0:Claude-4.5-Haiku

# Claude 4+ Models with Extended Thinking
# Shows internal reasoning before final response
# Only supported by Claude 4 Opus, 4 Sonnet, 4.5 Sonnet, 4.5 Haiku, 4.5 Opus
bedrock:us.anthropic.claude-sonnet-4-5-20250929-v1:0:Claude-4.5-Sonnet-Thinking|extended_thinking=true
bedrock:us.anthropic.claude-sonnet-4-20250514-v1:0:Claude-4-Sonnet-Thinking|extended_thinking=true
bedrock:us.anthropic.claude-opus-4-1-20250805-v1:0:Claude-4.1-Opus-Thinking|extended_thinking=true
bedrock:us.anthropic.claude-opus-4-20250514-v1:0:Claude-4-Opus-Thinking|extended_thinking=true
bedrock:us.anthropic.claude-haiku-4-5-20251001-v1:0:Claude-4.5-Haiku-Thinking|extended_thinking=true
bedrock:global.anthropic.claude-opus-4-5-20251101-v1:0:Claude-4.5-Opus-Global-Thinking|extended_thinking=true

# Claude 3.7 Models
bedrock:us.anthropic.claude-3-7-sonnet-20250219-v1:0:Claude-3.7-Sonnet

# Claude 3.5 Models
bedrock:us.anthropic.claude-3-5-sonnet-20241022-v2:0:Claude-3.5-Sonnet-v2
bedrock:us.anthropic.claude-3-5-sonnet-20240620-v1:0:Claude-3.5-Sonnet-v1
bedrock:us.anthropic.claude-3-5-haiku-20241022-v1:0:Claude-3.5-Haiku

# Claude 3 Models
bedrock:us.anthropic.claude-3-opus-20240229-v1:0:Claude-3-Opus
bedrock:us.anthropic.claude-3-sonnet-20240229-v1:0:Claude-3-Sonnet
bedrock:us.anthropic.claude-3-haiku-20240307-v1:0:Claude-3-Haiku

# === META LLAMA MODELS ===

# Llama 4 Models
bedrock:us.meta.llama4-maverick-17b-instruct-v1:0:Llama-4-Maverick-17B
bedrock:us.meta.llama4-scout-17b-instruct-v1:0:Llama-4-Scout-17B

# Llama 3.3 Models
bedrock:us.meta.llama3-3-70b-instruct-v1:0:Llama-3.3-70B

# Llama 3.2 Models
bedrock:us.meta.llama3-2-90b-instruct-v1:0:Llama-3.2-90B
bedrock:us.meta.llama3-2-11b-instruct-v1:0:Llama-3.2-11B
bedrock:us.meta.llama3-2-3b-instruct-v1:0:Llama-3.2-3B
bedrock:us.meta.llama3-2-1b-instruct-v1:0:Llama-3.2-1B

# Llama 3.1 Models
bedrock:us.meta.llama3-1-70b-instruct-v1:0:Llama-3.1-70B
bedrock:us.meta.llama3-1-8b-instruct-v1:0:Llama-3.1-8B

# Llama 3 Models
bedrock:meta.llama3-70b-instruct-v1:0:Llama-3-70B
bedrock:meta.llama3-8b-instruct-v1:0:Llama-3-8B

# === MISTRAL MODELS ===

# Mistral Large
bedrock:mistral.pixtral-large-2502-v1:0:Pixtral-Large-25.02
bedrock:mistral.mistral-large-2402-v1:0:Mistral-Large-24.02

# Mistral Small
bedrock:mistral.mistral-small-2402-v1:0:Mistral-Small-24.02

# Mistral Base
bedrock:mistral.mixtral-8x7b-instruct-v0:1:Mixtral-8x7B
bedrock:mistral.mistral-7b-instruct-v0:2:Mistral-7B

# === AMAZON NOVA MODELS ===

# Nova Premier
bedrock:us.amazon.nova-premier-v1:0:Nova-Premier

# Nova Pro
bedrock:us.amazon.nova-pro-v1:0:Nova-Pro

# Nova Lite
bedrock:us.amazon.nova-lite-v1:0:Nova-Lite

# Nova Micro
bedrock:us.amazon.nova-micro-v1:0:Nova-Micro

# === QWEN MODELS ===

# Qwen 3
bedrock:qwen.qwen3-32b-v1:0:Qwen3-32B
bedrock:qwen.qwen3-coder-30b-a3b-v1:0:Qwen3-Coder-30B

# === DEEPSEEK MODELS ===

# DeepSeek R1
bedrock:us.deepseek.r1-v1:0:DeepSeek-R1

# === OPENAI MODELS (via Bedrock) ===
bedrock:openai.gpt-oss-120b-1:0:GPT-OSS-120B
bedrock:openai.gpt-oss-20b-1:0:GPT-OSS-20B

# === OPENAI MODELS (Direct API) ===
# Lines starting with * are selected for execution
# Supports |reasoning_effort=low/medium/high for reasoning models (gpt-5.x, o3, o4)

# GPT-5 Series (Reasoning models)
openai:gpt-5.1:GPT-5.1|reasoning_effort=medium
openai:gpt-5-mini:GPT-5-Mini|reasoning_effort=medium
openai:gpt-5-nano:GPT-5-Nano|reasoning_effort=medium

# GPT-4.1 Series
openai:gpt-4.1:GPT-4.1
openai:gpt-4.1-mini:GPT-4.1-Mini
openai:gpt-4.1-nano:GPT-4.1-Nano

# GPT-4o Series
openai:gpt-4o:GPT-4o
openai:gpt-4o-realtime-preview:GPT-4o-Realtime

# O Series (Reasoning models)
openai:o3:O3|reasoning_effort=medium
openai:o4-mini:O4-Mini|reasoning_effort=medium

# Legacy Models (placeholder)
openai:gpt-4-turbo:GPT-4-Turbo
openai:gpt-4:GPT-4
openai:gpt-3.5-turbo:GPT-3.5-Turbo
openai:o1-preview:o1-Preview
openai:o1-mini:o1-Mini

# === GROK MODELS (xAI Direct API) ===
# Lines starting with * are selected for execution
# Note: Grok 4 models are ALWAYS reasoning models and don't support reasoning_effort parameter
# Grok 3 models support |reasoning_effort=low/high (not medium)

# Grok 4 Series (Always reasoning, no reasoning_effort parameter)
grok:grok-4-1-fast-reasoning:Grok-4.1-Fast-Reasoning
grok:grok-4-0709:Grok-4-0709

# Grok 3 Series (Supports reasoning_effort=low or high)
grok:grok-3:Grok-3|reasoning_effort=high
grok:grok-3-mini:Grok-3-Mini|reasoning_effort=high


# === GOOGLE GEMINI MODELS (Direct API) ===
# Lines starting with * are selected for execution
# Supports |reasoning_effort=low/medium/high
# Note: Gemini 2.5 uses thinking_budget (token-based), Gemini 3 uses thinking_level
#       - low: 8192 tokens (2.5) or "low" (3)
#       - medium: Dynamic -1 (2.5) or "high" (3)
#       - high: 32768 tokens (2.5) or "high" (3)

# Gemini 3 Series (Uses thinking_level: "low" or "high", cannot disable)
gemini:gemini-3-pro-preview:Gemini-3-Pro-Preview|reasoning_effort=medium

# Gemini 2.5 Series (Uses thinking_budget: token count or -1 for dynamic, cannot disable)
gemini:gemini-2.5-pro:Gemini-2.5-Pro|reasoning_effort=medium
gemini:gemini-2.5-flash:Gemini-2.5-Flash|reasoning_effort=medium

# Gemini 2.0 Series (May have limited thinking support)
gemini:gemini-2.0-flash-exp:Gemini-2.0-Flash-Exp|reasoning_effort=medium
gemini:gemini-2.0-flash:Gemini-2.0-Flash|reasoning_effort=medium

# Gemini 1.5 Series (May have limited thinking support)
gemini:gemini-1.5-pro:Gemini-1.5-Pro|reasoning_effort=medium
gemini:gemini-1.5-flash:Gemini-1.5-Flash|reasoning_effort=medium
gemini:gemini-1.5-flash-8b:Gemini-1.5-Flash-8B|reasoning_effort=medium
