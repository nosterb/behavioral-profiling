{
  "median_sophistication": 5.930349999999999,
  "n_high_sophistication": 23,
  "n_low_sophistication": 23,
  "models": [
    {
      "model_id": "llama-3-70b",
      "display_name": "Llama-3-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.4666,
        "warmth": 2.2004,
        "aggression": 1.2053999999999996,
        "formality": 3.5126000000000004,
        "tribalism": 0.9608000000000003,
        "hedging": 2.1866,
        "transgression": 1.1131999999999997,
        "authenticity": 2.3072,
        "depth": 2.7723999999999993,
        "sophistication": 2.5397999999999996
      },
      "sophistication": 2.5397999999999996,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.1864999999999999
    },
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7198,
        "warmth": 5.5736,
        "aggression": 1.2997999999999998,
        "formality": 7.2526,
        "tribalism": 1.16,
        "hedging": 4.326400000000001,
        "transgression": 1.3921999999999997,
        "authenticity": 3.4734000000000003,
        "depth": 4.546999999999999,
        "ribalism": 1.0,
        "sophistication": 4.010199999999999
      },
      "sophistication": 4.010199999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39295
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7461999999999995,
        "warmth": 5.333399999999999,
        "aggression": 1.2464,
        "formality": 7.393200000000003,
        "tribalism": 1.0266,
        "hedging": 4.659600000000001,
        "transgression": 1.3653999999999997,
        "authenticity": 3.6799999999999993,
        "depth": 5.0864,
        "sophistication": 4.3831999999999995
      },
      "sophistication": 4.3831999999999995,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3461499999999997
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.7536,
        "warmth": 5.7798000000000025,
        "aggression": 1.2662,
        "formality": 7.8132,
        "tribalism": 1.1134,
        "hedging": 4.839400000000001,
        "transgression": 1.3113999999999992,
        "authenticity": 3.7469999999999986,
        "depth": 5.3132,
        "sophistication": 4.530099999999999
      },
      "sophistication": 4.530099999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3611499999999999
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.7995999999999999,
        "warmth": 6.0604,
        "aggression": 1.2059999999999997,
        "formality": 7.653400000000005,
        "tribalism": 1.0732,
        "hedging": 4.859400000000001,
        "transgression": 1.3319999999999994,
        "authenticity": 3.7936,
        "depth": 5.2868,
        "sophistication": 4.5402000000000005
      },
      "sophistication": 4.5402000000000005,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3526999999999998
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6861999999999997,
        "warmth": 5.3728,
        "aggression": 1.3863999999999999,
        "formality": 6.987,
        "tribalism": 1.0463999999999998,
        "hedging": 4.346399999999999,
        "transgression": 1.4989999999999994,
        "authenticity": 4.066999999999998,
        "depth": 5.1602,
        "sophistication": 4.613599999999999
      },
      "sophistication": 4.613599999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4044999999999996
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7066,
        "warmth": 5.573999999999997,
        "aggression": 1.2795999999999998,
        "formality": 7.546600000000003,
        "tribalism": 1.06,
        "hedging": 4.2136000000000005,
        "transgression": 1.3789999999999998,
        "authenticity": 3.9930000000000017,
        "depth": 5.373000000000001,
        "sophistication": 4.683000000000002
      },
      "sophistication": 4.683000000000002,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3563
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7727999999999997,
        "warmth": 5.9934,
        "aggression": 1.2061999999999997,
        "formality": 7.353,
        "tribalism": 1.0534000000000001,
        "hedging": 4.7666,
        "transgression": 1.2713999999999992,
        "authenticity": 3.9868000000000006,
        "depth": 5.419599999999999,
        "sophistication": 4.7032
      },
      "sophistication": 4.7032,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3259499999999997
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7402000000000002,
        "warmth": 5.473200000000002,
        "aggression": 1.3129999999999997,
        "formality": 7.580399999999998,
        "tribalism": 1.0266,
        "hedging": 4.353400000000001,
        "transgression": 1.4181999999999995,
        "authenticity": 4.056799999999999,
        "depth": 5.446200000000002,
        "sophistication": 4.7515
      },
      "sophistication": 4.7515,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3744999999999998
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6593999999999998,
        "warmth": 5.792800000000001,
        "aggression": 1.193,
        "formality": 7.2126,
        "tribalism": 1.0131999999999999,
        "hedging": 4.593,
        "transgression": 1.3385999999999996,
        "authenticity": 4.120000000000001,
        "depth": 5.493200000000001,
        "sophistication": 4.806600000000001
      },
      "sophistication": 4.806600000000001,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3010499999999998
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6725999999999996,
        "warmth": 5.7799999999999985,
        "aggression": 1.2995999999999999,
        "formality": 7.114200000000002,
        "tribalism": 1.0732,
        "hedging": 4.333000000000001,
        "transgression": 1.4259999999999997,
        "authenticity": 4.333200000000001,
        "depth": 5.399799999999999,
        "sophistication": 4.8665
      },
      "sophistication": 4.8665,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3678499999999998
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7138,
        "warmth": 5.9395999999999995,
        "aggression": 1.16,
        "formality": 7.7867999999999995,
        "tribalism": 1.0334,
        "hedging": 4.506800000000001,
        "transgression": 1.3647999999999993,
        "authenticity": 4.192600000000001,
        "depth": 5.780799999999998,
        "sophistication": 4.9867
      },
      "sophistication": 4.9867,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3179999999999998
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7738,
        "warmth": 5.832800000000001,
        "aggression": 1.1263999999999998,
        "formality": 7.92,
        "tribalism": 1.1466,
        "hedging": 4.380199999999999,
        "transgression": 1.2521999999999995,
        "authenticity": 4.226400000000002,
        "depth": 5.906200000000001,
        "sophistication": 5.066300000000002
      },
      "sophistication": 5.066300000000002,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3247499999999999
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.7806,
        "warmth": 5.7462,
        "aggression": 1.2591999999999997,
        "formality": 7.579799999999999,
        "tribalism": 1.0266,
        "hedging": 4.853000000000002,
        "transgression": 1.3723999999999998,
        "authenticity": 4.3267999999999995,
        "depth": 5.832800000000002,
        "sophistication": 5.0798000000000005
      },
      "sophistication": 5.0798000000000005,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3597
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8676000000000001,
        "warmth": 6.013,
        "aggression": 1.2868000000000002,
        "formality": 7.5661999999999985,
        "tribalism": 1.0332,
        "hedging": 4.540399999999999,
        "transgression": 1.3455999999999995,
        "authenticity": 4.293599999999997,
        "depth": 5.872800000000001,
        "sophistication": 5.083199999999999
      },
      "sophistication": 5.083199999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3833
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8338000000000003,
        "warmth": 5.999599999999999,
        "aggression": 1.2664,
        "formality": 7.599799999999997,
        "tribalism": 1.1061999999999999,
        "hedging": 4.5336,
        "transgression": 1.3785999999999994,
        "authenticity": 4.393999999999998,
        "depth": 5.873399999999999,
        "sophistication": 5.133699999999999
      },
      "sophistication": 5.133699999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39625
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8806,
        "warmth": 6.426,
        "aggression": 1.3063999999999998,
        "formality": 7.205799999999999,
        "tribalism": 1.1466,
        "hedging": 4.599599999999999,
        "transgression": 1.4521999999999997,
        "authenticity": 4.500000000000001,
        "depth": 5.959200000000001,
        "sophistication": 5.229600000000001
      },
      "sophistication": 5.229600000000001,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.44645
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7742000000000002,
        "warmth": 5.8792,
        "aggression": 1.2131999999999998,
        "formality": 7.953599999999999,
        "tribalism": 1.0332,
        "hedging": 4.2536,
        "transgression": 1.3517999999999994,
        "authenticity": 4.379600000000001,
        "depth": 6.193599999999999,
        "ribalism": 1.0,
        "sophistication": 5.2866
      },
      "sophistication": 5.2866,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3431
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8332,
        "warmth": 6.119199999999999,
        "aggression": 1.2734,
        "formality": 7.433199999999997,
        "tribalism": 1.1398,
        "hedging": 4.746600000000001,
        "transgression": 1.3461999999999998,
        "authenticity": 4.5872,
        "depth": 6.0806000000000004,
        "sophistication": 5.3339
      },
      "sophistication": 5.3339,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39815
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8259999999999996,
        "warmth": 5.813400000000001,
        "aggression": 1.3461999999999998,
        "formality": 7.147200000000001,
        "tribalism": 1.0932,
        "hedging": 4.500799999999997,
        "transgression": 1.5387999999999997,
        "authenticity": 4.766200000000001,
        "depth": 5.946999999999998,
        "sophistication": 5.3566
      },
      "sophistication": 5.3566,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.45105
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7991999999999997,
        "warmth": 6.5262,
        "aggression": 1.2461999999999998,
        "formality": 6.7532,
        "tribalism": 1.1534,
        "hedging": 4.233599999999999,
        "transgression": 1.4857999999999998,
        "authenticity": 5.087199999999999,
        "depth": 6.1198000000000015,
        "sophistication": 5.6035
      },
      "sophistication": 5.6035,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4211499999999997
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8396,
        "warmth": 6.166399999999999,
        "aggression": 1.4995999999999998,
        "formality": 6.306200000000001,
        "tribalism": 1.2131999999999998,
        "hedging": 3.826200000000002,
        "transgression": 1.8855999999999995,
        "authenticity": 5.3638,
        "depth": 6.419999999999999,
        "organicness": 7.0,
        "sophistication": 5.8919
      },
      "sophistication": 5.8919,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6094999999999997
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8527999999999998,
        "warmth": 6.2134,
        "aggression": 1.6391999999999998,
        "formality": 6.139799999999999,
        "tribalism": 1.2334,
        "hedging": 4.033399999999999,
        "transgression": 1.8651999999999995,
        "authenticity": 5.4407999999999985,
        "depth": 6.407400000000001,
        "sophistication": 5.924099999999999
      },
      "sophistication": 5.924099999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.64765
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 2.0142,
        "warmth": 6.2932000000000015,
        "aggression": 1.5593999999999997,
        "formality": 6.313000000000001,
        "tribalism": 1.2534,
        "hedging": 3.9599999999999995,
        "transgression": 1.8049999999999995,
        "authenticity": 5.492800000000002,
        "depth": 6.380399999999997,
        "sophistication": 5.936599999999999
      },
      "sophistication": 5.936599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.658
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8729999999999998,
        "warmth": 6.240199999999999,
        "aggression": 1.54,
        "formality": 6.5804,
        "tribalism": 1.2266,
        "hedging": 4.112800000000001,
        "transgression": 1.8851999999999993,
        "authenticity": 5.527199999999999,
        "depth": 6.753599999999999,
        "sophistication": 6.140399999999999
      },
      "sophistication": 6.140399999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6311999999999998
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8323999999999996,
        "warmth": 6.272800000000002,
        "aggression": 1.533,
        "formality": 6.580199999999996,
        "tribalism": 1.2131999999999998,
        "hedging": 4.0200000000000005,
        "transgression": 1.7523999999999995,
        "authenticity": 5.646600000000001,
        "depth": 6.6734,
        "sophistication": 6.16
      },
      "sophistication": 6.16,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5827499999999997
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "grandiosity": 1.9278000000000004,
        "warmth": 6.0464,
        "aggression": 1.5723999999999996,
        "formality": 6.959600000000002,
        "tribalism": 1.1929999999999998,
        "hedging": 4.486400000000001,
        "transgression": 1.5193999999999996,
        "authenticity": 5.4198,
        "depth": 6.959600000000002,
        "ribalism": 1.0,
        "sophistication": 6.189700000000001
      },
      "sophistication": 6.189700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5531499999999998
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "grandiosity": 2.1812000000000005,
        "warmth": 5.746600000000001,
        "aggression": 1.4729999999999999,
        "formality": 7.8134000000000015,
        "tribalism": 1.2266,
        "hedging": 4.066600000000001,
        "transgression": 1.686,
        "authenticity": 5.406400000000001,
        "depth": 7.112799999999998,
        "sophistication": 6.2596
      },
      "sophistication": 6.2596,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6417000000000002
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8861999999999997,
        "warmth": 6.092600000000001,
        "aggression": 1.5592,
        "formality": 6.340200000000001,
        "tribalism": 1.2202000000000002,
        "hedging": 4.112400000000003,
        "transgression": 1.8659999999999997,
        "authenticity": 5.8530000000000015,
        "depth": 6.839599999999999,
        "sophistication": 6.3463
      },
      "sophistication": 6.3463,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6328999999999998
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "grandiosity": 2.2078,
        "warmth": 6.939999999999998,
        "aggression": 1.4257999999999997,
        "formality": 6.880800000000002,
        "tribalism": 1.1865999999999999,
        "hedging": 4.046200000000002,
        "transgression": 1.5393999999999997,
        "authenticity": 5.7538,
        "depth": 7.0062000000000015,
        "sophistication": 6.380000000000001
      },
      "sophistication": 6.380000000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5899
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "grandiosity": 2.1340000000000003,
        "warmth": 6.400600000000001,
        "aggression": 1.4926,
        "formality": 7.220999999999999,
        "tribalism": 1.2531999999999999,
        "hedging": 4.380599999999999,
        "transgression": 1.5796,
        "authenticity": 5.606,
        "depth": 7.2601999999999975,
        "sophistication": 6.433099999999999
      },
      "sophistication": 6.433099999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.61485
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.9804000000000002,
        "warmth": 6.020000000000001,
        "aggression": 1.7462,
        "formality": 5.8466000000000005,
        "tribalism": 1.2202000000000002,
        "hedging": 3.9526,
        "transgression": 2.0498,
        "authenticity": 6.2467999999999995,
        "depth": 6.9936,
        "sophistication": 6.6202
      },
      "sophistication": 6.6202,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.74915
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "grandiosity": 2.314,
        "warmth": 6.766799999999998,
        "aggression": 1.6995999999999998,
        "formality": 6.4336,
        "tribalism": 1.4929999999999999,
        "hedging": 4.5202,
        "transgression": 1.9527999999999996,
        "authenticity": 6.0804,
        "depth": 7.1874,
        "ribalism": 1.0,
        "sophistication": 6.633900000000001
      },
      "sophistication": 6.633900000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.8648499999999997
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8793999999999997,
        "warmth": 6.166799999999999,
        "aggression": 1.6993999999999998,
        "formality": 6.066800000000001,
        "tribalism": 1.1598,
        "hedging": 5.167000000000001,
        "transgression": 2.0063999999999997,
        "authenticity": 6.392800000000001,
        "depth": 7.126600000000002,
        "sophistication": 6.759700000000001
      },
      "sophistication": 6.759700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6862499999999998
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.9668,
        "warmth": 5.8801999999999985,
        "aggression": 1.8263999999999998,
        "formality": 5.966600000000001,
        "tribalism": 1.28,
        "hedging": 3.7400000000000007,
        "transgression": 2.2327999999999997,
        "authenticity": 6.3734,
        "depth": 7.1675999999999975,
        "sophistication": 6.770499999999998
      },
      "sophistication": 6.770499999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.8265
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7331999999999999,
        "warmth": 5.986199999999999,
        "aggression": 1.6925999999999999,
        "formality": 5.986799999999999,
        "tribalism": 1.12,
        "hedging": 4.519600000000001,
        "transgression": 2.0134,
        "authenticity": 6.506599999999997,
        "depth": 7.166999999999999,
        "ribalism": 1.0,
        "sophistication": 6.836799999999998
      },
      "sophistication": 6.836799999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6398
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8932,
        "warmth": 6.026599999999999,
        "aggression": 1.7792,
        "formality": 5.9804,
        "tribalism": 1.173,
        "hedging": 4.766200000000001,
        "transgression": 1.9597999999999995,
        "authenticity": 6.526600000000001,
        "depth": 7.233400000000001,
        "sophistication": 6.880000000000001
      },
      "sophistication": 6.880000000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.7012999999999998
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.793,
        "warmth": 6.0527999999999995,
        "aggression": 1.7466,
        "formality": 5.840200000000001,
        "tribalism": 1.1463999999999999,
        "hedging": 4.3336,
        "transgression": 1.9997999999999998,
        "authenticity": 6.6674,
        "depth": 7.227,
        "sophistication": 6.9472000000000005
      },
      "sophistication": 6.9472000000000005,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6714499999999999
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9925999999999997,
        "warmth": 5.772800000000002,
        "aggression": 1.4996,
        "formality": 6.4604,
        "tribalism": 1.1329999999999998,
        "hedging": 3.693600000000001,
        "transgression": 1.5997999999999999,
        "authenticity": 6.406799999999999,
        "depth": 7.660199999999999,
        "sophistication": 7.033499999999998
      },
      "sophistication": 7.033499999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.55625
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.1178000000000003,
        "warmth": 6.263599999999998,
        "aggression": 1.3658,
        "formality": 7.643200000000002,
        "tribalism": 1.0466,
        "hedging": 3.9595999999999987,
        "transgression": 1.4319999999999995,
        "authenticity": 6.3904000000000005,
        "depth": 7.853000000000001,
        "sophistication": 7.121700000000001
      },
      "sophistication": 7.121700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.4905499999999998
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9338,
        "warmth": 5.753399999999999,
        "aggression": 1.4128,
        "formality": 7.113199999999998,
        "tribalism": 1.193,
        "hedging": 3.6927999999999996,
        "transgression": 1.6529999999999998,
        "authenticity": 6.540199999999999,
        "depth": 7.814,
        "sophistication": 7.177099999999999
      },
      "sophistication": 7.177099999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.54815
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.0008,
        "warmth": 5.933600000000001,
        "aggression": 1.5857999999999999,
        "formality": 6.419999999999999,
        "tribalism": 1.18,
        "hedging": 3.6995999999999998,
        "transgression": 1.7591999999999997,
        "authenticity": 6.719399999999999,
        "depth": 7.793799999999999,
        "sophistication": 7.256599999999999
      },
      "sophistication": 7.256599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6314499999999998
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.0266,
        "warmth": 6.153200000000001,
        "aggression": 1.5594,
        "formality": 6.286799999999999,
        "tribalism": 1.2731999999999999,
        "hedging": 3.8334,
        "transgression": 1.7655999999999998,
        "authenticity": 6.739800000000002,
        "depth": 7.7806,
        "sophistication": 7.260200000000001
      },
      "sophistication": 7.260200000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6562
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9601999999999997,
        "warmth": 5.939999999999999,
        "aggression": 1.4524,
        "formality": 6.433400000000002,
        "tribalism": 1.1398,
        "hedging": 3.7734000000000005,
        "transgression": 1.646,
        "authenticity": 6.7264,
        "depth": 7.9536,
        "sophistication": 7.34
      },
      "sophistication": 7.34,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5495999999999999
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "grandiosity": 2.5599999999999996,
        "warmth": 5.759600000000001,
        "aggression": 2.179,
        "formality": 6.446400000000001,
        "tribalism": 1.7932,
        "hedging": 2.8796,
        "transgression": 2.692599999999999,
        "authenticity": 7.073400000000001,
        "depth": 7.9201999999999995,
        "sophistication": 7.4968
      },
      "sophistication": 7.4968,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 2.3061999999999996
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "grandiosity": 2.3206,
        "warmth": 6.953200000000002,
        "aggression": 1.5794,
        "formality": 6.679800000000001,
        "tribalism": 1.3332,
        "hedging": 3.3532000000000006,
        "transgression": 1.7926,
        "authenticity": 7.0204,
        "depth": 8.086799999999998,
        "sophistication": 7.553599999999999
      },
      "sophistication": 7.553599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.75645
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 6.15048695652174,
      "high_std": 0.3457703274828376,
      "low_mean": 5.722121739130435,
      "low_std": 0.8250190691771487,
      "difference": 0.4283652173913053,
      "pct_difference": 7.486125547835723,
      "t_statistic": 2.296546047885323,
      "p_value": 0.026463611328630846,
      "cohens_d": 0.6772144834000201
    },
    "formality": {
      "high_mean": 6.5344695652173925,
      "high_std": 0.5349327624994165,
      "low_mean": 7.1656695652173905,
      "low_std": 0.9190211820858806,
      "difference": -0.631199999999998,
      "pct_difference": -8.80866741419228,
      "t_statistic": -2.846734961890767,
      "p_value": 0.006686320163511611,
      "cohens_d": -0.8394563428714225
    },
    "hedging": {
      "high_mean": 4.046495652173913,
      "high_std": 0.48001896125263166,
      "low_mean": 4.368921739130435,
      "low_std": 0.5438600412844549,
      "difference": -0.3224260869565221,
      "pct_difference": -7.379992277469724,
      "t_statistic": -2.1316596521220648,
      "p_value": 0.03865688601320442,
      "cohens_d": -0.6285921379306897
    },
    "aggression": {
      "high_mean": 1.6078086956521738,
      "high_std": 0.17615287243301814,
      "low_mean": 1.283678260869565,
      "low_std": 0.10972784082165929,
      "difference": 0.32413043478260883,
      "pct_difference": 25.250130399734477,
      "t_statistic": 7.490246751425717,
      "p_value": 2.1998697866334356e-09,
      "cohens_d": 2.208753266226142
    },
    "transgression": {
      "high_mean": 1.8342869565217388,
      "high_std": 0.27321444009546747,
      "low_mean": 1.4124173913043478,
      "low_std": 0.1703002579728306,
      "difference": 0.42186956521739094,
      "pct_difference": 29.868618711059643,
      "t_statistic": 6.284359261519054,
      "p_value": 1.2881833352577963e-07,
      "cohens_d": 1.8531564453970282
    },
    "grandiosity": {
      "high_mean": 2.023,
      "high_std": 0.19323111927053954,
      "low_mean": 1.7608173913043477,
      "low_std": 0.08964959895551895,
      "difference": 0.26218260869565246,
      "pct_difference": 14.88982389601669,
      "t_statistic": 5.902798617018743,
      "p_value": 4.688227350860323e-07,
      "cohens_d": 1.7406403497633303
    },
    "tribalism": {
      "high_mean": 1.2372695652173915,
      "high_std": 0.14883115031587918,
      "low_mean": 1.0854608695652175,
      "low_std": 0.06839240879679312,
      "difference": 0.15180869565217403,
      "pct_difference": 13.98564424648317,
      "t_statistic": 4.444925978022697,
      "p_value": 5.88058771196535e-05,
      "cohens_d": 1.3107371623267716
    },
    "depth": {
      "high_mean": 7.302199999999999,
      "high_std": 0.46586135666780065,
      "low_mean": 5.5518,
      "low_std": 0.7569236685426084,
      "difference": 1.750399999999999,
      "pct_difference": 31.528513274973864,
      "t_statistic": 9.44492698954235,
      "p_value": 3.772736033568332e-12,
      "cohens_d": 2.7851570221566155
    },
    "authenticity": {
      "high_mean": 6.222452173913042,
      "high_std": 0.5278629547262546,
      "low_mean": 4.222443478260868,
      "low_std": 0.6476388245886935,
      "difference": 2.0000086956521734,
      "pct_difference": 47.36614488622908,
      "t_statistic": 11.480073054714213,
      "p_value": 8.001589747141402e-15,
      "cohens_d": 3.385288855976377
    },
    "sophistication": {
      "high_mean": 6.762326086956522,
      "high_std": 0.4717572008578828,
      "low_mean": 4.887121739130435,
      "low_std": 0.688531566554717,
      "difference": 1.8752043478260871,
      "pct_difference": 38.37032199979005,
      "t_statistic": 10.774850511977673,
      "p_value": 6.360938390471233e-14,
      "cohens_d": 3.1773300735251664
    },
    "disinhibition": {
      "high_mean": 1.6755913043478259,
      "high_std": 0.16419204917369687,
      "low_mean": 1.3855934782608694,
      "low_std": 0.09399456984357689,
      "difference": 0.28999782608695646,
      "pct_difference": 20.929502818600724,
      "t_statistic": 7.351119688722747,
      "p_value": 3.5066498781094195e-09,
      "cohens_d": 2.16772693366812
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.7382605070666357
  }
}