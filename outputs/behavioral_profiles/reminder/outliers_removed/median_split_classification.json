{
  "median_sophistication": 6.8330769230769235,
  "n_high_sophistication": 22,
  "n_low_sophistication": 22,
  "models": [
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.334615384615384,
        "transgression": 1.5876923076923077,
        "aggression": 1.6407692307692305,
        "warmth": 6.665384615384616,
        "grandiosity": 1.8969230769230772,
        "tribalism": 1.6923076923076923,
        "formality": 7.153846153846154,
        "authenticity": 3.5138461538461536,
        "depth": 4.334615384615384,
        "sophistication": 3.924230769230769
      },
      "sophistication": 3.924230769230769,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.7044230769230768
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.871538461538462,
        "transgression": 1.1523076923076923,
        "aggression": 1.23,
        "warmth": 6.154615384615385,
        "grandiosity": 1.948461538461539,
        "tribalism": 1.0,
        "formality": 7.383846153846154,
        "authenticity": 3.512307692307693,
        "depth": 4.7700000000000005,
        "tribalismm": 1.0,
        "sophistication": 4.141153846153847
      },
      "sophistication": 4.141153846153847,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3326923076923078
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "hedging": 5.999230769230769,
        "transgression": 1.2038461538461538,
        "aggression": 1.2815384615384615,
        "warmth": 6.846153846153846,
        "grandiosity": 1.8461538461538463,
        "tribalism": 1.2053846153846153,
        "formality": 7.923076923076923,
        "authenticity": 3.691538461538461,
        "depth": 5.078461538461539,
        "sophistication": 4.385
      },
      "sophistication": 4.385,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3842307692307692
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "hedging": 6.461538461538462,
        "transgression": 1.3061538461538462,
        "aggression": 1.2046153846153846,
        "warmth": 6.383846153846154,
        "grandiosity": 1.693846153846154,
        "tribalism": 1.0253846153846153,
        "formality": 7.666923076923077,
        "authenticity": 3.666923076923077,
        "depth": 5.154615384615385,
        "sophistication": 4.4107692307692306
      },
      "sophistication": 4.4107692307692306,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3075
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.794615384615384,
        "transgression": 1.4861538461538462,
        "aggression": 1.5115384615384615,
        "warmth": 5.922307692307692,
        "grandiosity": 2.026153846153846,
        "tribalism": 1.0253846153846153,
        "formality": 7.717692307692308,
        "authenticity": 3.897692307692308,
        "depth": 5.076153846153845,
        "sophistication": 4.486923076923077
      },
      "sophistication": 4.486923076923077,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5123076923076924
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.614615384615385,
        "transgression": 1.4607692307692304,
        "aggression": 1.6153846153846154,
        "warmth": 7.435384615384615,
        "grandiosity": 2.1276923076923073,
        "tribalism": 1.2053846153846153,
        "formality": 7.41,
        "authenticity": 4.281538461538461,
        "depth": 5.076153846153845,
        "sophistication": 4.678846153846154
      },
      "sophistication": 4.678846153846154,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6023076923076922
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.487692307692308,
        "transgression": 1.2815384615384615,
        "aggression": 1.383846153846154,
        "warmth": 6.693846153846154,
        "grandiosity": 1.871538461538462,
        "tribalism": 1.0,
        "formality": 7.384615384615385,
        "authenticity": 4.076153846153845,
        "depth": 5.282307692307692,
        "ribalism": 1.0,
        "sophistication": 4.679230769230768
      },
      "sophistication": 4.679230769230768,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3842307692307694
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.641538461538461,
        "transgression": 1.4615384615384615,
        "aggression": 1.666153846153846,
        "warmth": 6.0515384615384615,
        "grandiosity": 2.050769230769231,
        "tribalism": 1.0769230769230769,
        "formality": 7.203846153846153,
        "authenticity": 4.436153846153847,
        "depth": 4.974615384615385,
        "observational_acuity": 5.0,
        "sophistication": 4.705384615384616
      },
      "sophistication": 4.705384615384616,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5638461538461539
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.898461538461539,
        "transgression": 1.3323076923076924,
        "aggression": 1.8707692307692307,
        "warmth": 6.6415384615384605,
        "grandiosity": 2.3838461538461533,
        "tribalism": 1.0253846153846153,
        "formality": 7.2299999999999995,
        "authenticity": 4.358461538461539,
        "depth": 5.333846153846154,
        "sophistication": 4.846153846153847
      },
      "sophistication": 4.846153846153847,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6530769230769229
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "hedging": 5.9484615384615385,
        "transgression": 1.3323076923076924,
        "aggression": 1.3323076923076924,
        "warmth": 6.794615384615384,
        "grandiosity": 1.9484615384615382,
        "tribalism": 1.1284615384615384,
        "formality": 7.923846153846155,
        "authenticity": 4.154615384615385,
        "depth": 5.59,
        "sophistication": 4.872307692307692
      },
      "sophistication": 4.872307692307692,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4353846153846155
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "hedging": 5.8707692307692305,
        "transgression": 1.2546153846153847,
        "aggression": 1.2307692307692308,
        "warmth": 7.359230769230769,
        "grandiosity": 1.770769230769231,
        "tribalism": 1.333076923076923,
        "formality": 7.769230769230769,
        "authenticity": 4.41,
        "depth": 5.461538461538462,
        "sophistication": 4.935769230769231
      },
      "sophistication": 4.935769230769231,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3973076923076924
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "hedging": 5.410769230769231,
        "transgression": 1.2038461538461538,
        "aggression": 1.3576923076923075,
        "warmth": 7.127692307692309,
        "grandiosity": 1.9484615384615382,
        "tribalism": 1.3846153846153846,
        "formality": 7.845384615384616,
        "authenticity": 4.153846153846154,
        "depth": 5.795384615384616,
        "sophistication": 4.974615384615385
      },
      "sophistication": 4.974615384615385,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.473653846153846
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 5.872307692307692,
        "transgression": 1.2546153846153847,
        "aggression": 1.5123076923076921,
        "warmth": 7.613846153846153,
        "grandiosity": 2.0769230769230775,
        "tribalism": 1.0507692307692307,
        "formality": 7.026153846153846,
        "authenticity": 4.59,
        "depth": 5.615384615384615,
        "sophistication": 5.102692307692307
      },
      "sophistication": 5.102692307692307,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4736538461538462
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "hedging": 6.101538461538461,
        "transgression": 1.23,
        "aggression": 1.435384615384615,
        "warmth": 7.281538461538461,
        "grandiosity": 2.1030769230769235,
        "tribalism": 1.0515384615384615,
        "formality": 7.589230769230769,
        "authenticity": 4.436153846153847,
        "depth": 5.7700000000000005,
        "sophistication": 5.103076923076923
      },
      "sophistication": 5.103076923076923,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.455
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 6.256923076923077,
        "transgression": 1.306923076923077,
        "aggression": 1.3076923076923077,
        "warmth": 6.973846153846154,
        "grandiosity": 1.871538461538462,
        "tribalism": 1.1023076923076922,
        "formality": 7.153846153846154,
        "authenticity": 4.462307692307693,
        "depth": 5.896153846153846,
        "sophistication": 5.179230769230769
      },
      "sophistication": 5.179230769230769,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3971153846153848
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 5.872307692307692,
        "transgression": 1.2046153846153846,
        "aggression": 1.4092307692307693,
        "warmth": 7.436153846153847,
        "grandiosity": 1.8723076923076927,
        "tribalism": 1.1023076923076922,
        "formality": 7.664615384615384,
        "authenticity": 4.743846153846154,
        "depth": 6.204615384615384,
        "sophistication": 5.474230769230769
      },
      "sophistication": 5.474230769230769,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3971153846153848
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 6.359230769230769,
        "transgression": 1.333076923076923,
        "aggression": 1.5123076923076921,
        "warmth": 7.590769230769231,
        "grandiosity": 2.1030769230769226,
        "tribalism": 1.256153846153846,
        "formality": 7.154615384615385,
        "authenticity": 5.000769230769231,
        "depth": 6.203846153846153,
        "sophistication": 5.602307692307692
      },
      "sophistication": 5.602307692307692,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5511538461538459
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.410769230769231,
        "transgression": 1.666923076923077,
        "aggression": 1.6923076923076923,
        "warmth": 6.41,
        "grandiosity": 1.9500000000000002,
        "tribalism": 1.1538461538461537,
        "formality": 7.102307692307692,
        "authenticity": 5.563846153846153,
        "depth": 5.846153846153846,
        "sophistication": 5.705
      },
      "sophistication": 5.705,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6157692307692308
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.769230769230769,
        "transgression": 1.8199999999999998,
        "aggression": 1.8199999999999998,
        "warmth": 6.8707692307692305,
        "grandiosity": 1.845384615384615,
        "tribalism": 1.5384615384615385,
        "formality": 6.590769230769231,
        "authenticity": 5.256153846153845,
        "depth": 6.359230769230769,
        "sophistication": 5.807692307692307
      },
      "sophistication": 5.807692307692307,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.7559615384615381
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 6.026923076923078,
        "transgression": 1.4861538461538462,
        "aggression": 1.2038461538461538,
        "warmth": 7.794615384615384,
        "grandiosity": 1.9484615384615382,
        "tribalism": 1.0253846153846153,
        "formality": 6.59,
        "authenticity": 5.743846153846154,
        "depth": 6.693076923076924,
        "sophistication": 6.218461538461539
      },
      "sophistication": 6.218461538461539,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4159615384615385
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "hedging": 5.741538461538462,
        "transgression": 1.59,
        "aggression": 1.9476923076923072,
        "warmth": 7.024615384615384,
        "grandiosity": 2.3346153846153848,
        "tribalism": 1.306923076923077,
        "formality": 6.743846153846153,
        "authenticity": 6.1292307692307695,
        "depth": 7.359230769230769,
        "sophistication": 6.74423076923077
      },
      "sophistication": 6.74423076923077,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 1.794807692307692
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "hedging": 5.204615384615384,
        "transgression": 2.076153846153846,
        "aggression": 2.076153846153846,
        "warmth": 7.153076923076923,
        "grandiosity": 2.5392307692307696,
        "tribalism": 1.5384615384615385,
        "formality": 7.358461538461539,
        "authenticity": 6.256923076923077,
        "depth": 7.332307692307692,
        "sophistication": 6.794615384615385
      },
      "sophistication": 6.794615384615385,
      "n_contributions": 13,
      "classification": "Low-Sophistication",
      "disinhibition": 2.0575
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "hedging": 5.716923076923076,
        "transgression": 1.5899999999999996,
        "aggression": 1.4084615384615387,
        "warmth": 8.05076923076923,
        "grandiosity": 2.1807692307692315,
        "tribalism": 1.0253846153846153,
        "formality": 6.410769230769231,
        "authenticity": 6.46076923076923,
        "depth": 7.282307692307692,
        "sophistication": 6.871538461538462
      },
      "sophistication": 6.871538461538462,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.5511538461538463
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "hedging": 5.743846153846154,
        "transgression": 2.332307692307692,
        "aggression": 2.1261538461538456,
        "warmth": 7.025384615384615,
        "grandiosity": 2.565384615384616,
        "tribalism": 1.666923076923077,
        "formality": 5.590769230769231,
        "authenticity": 6.898461538461539,
        "depth": 7.283076923076924,
        "sophistication": 7.090769230769231
      },
      "sophistication": 7.090769230769231,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.1726923076923077
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "hedging": 5.41,
        "transgression": 2.025384615384615,
        "aggression": 1.8969230769230767,
        "warmth": 7.512307692307692,
        "grandiosity": 2.230769230769231,
        "tribalism": 1.435384615384615,
        "formality": 6.0515384615384615,
        "authenticity": 6.794615384615384,
        "depth": 7.564615384615385,
        "sophistication": 7.179615384615385
      },
      "sophistication": 7.179615384615385,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.8971153846153845
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.513076923076923,
        "transgression": 2.281538461538461,
        "aggression": 1.8461538461538463,
        "warmth": 7.383846153846154,
        "grandiosity": 1.8199999999999998,
        "tribalism": 1.5638461538461537,
        "formality": 5.2823076923076915,
        "authenticity": 7.0515384615384615,
        "depth": 7.384615384615385,
        "sophistication": 7.218076923076923
      },
      "sophistication": 7.218076923076923,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.8778846153846152
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.717692307692308,
        "transgression": 1.4092307692307693,
        "aggression": 1.4092307692307693,
        "warmth": 6.973846153846154,
        "grandiosity": 2.077692307692308,
        "tribalism": 1.0,
        "formality": 7.896923076923077,
        "authenticity": 6.718461538461539,
        "depth": 8.102307692307692,
        "sophistication": 7.410384615384615
      },
      "sophistication": 7.410384615384615,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.4740384615384616
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.41,
        "transgression": 2.3338461538461535,
        "aggression": 1.9230769230769231,
        "warmth": 7.283076923076923,
        "grandiosity": 1.845384615384615,
        "tribalism": 1.4615384615384615,
        "formality": 4.769230769230769,
        "authenticity": 7.512307692307692,
        "depth": 7.359230769230769,
        "sophistication": 7.43576923076923
      },
      "sophistication": 7.43576923076923,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.8909615384615384
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.64,
        "transgression": 2.2830769230769237,
        "aggression": 2.076153846153846,
        "warmth": 7.384615384615385,
        "grandiosity": 1.9984615384615383,
        "tribalism": 1.59,
        "formality": 4.538461538461538,
        "authenticity": 7.538461538461538,
        "depth": 7.357692307692307,
        "sophistication": 7.448076923076923
      },
      "sophistication": 7.448076923076923,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.986923076923077
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.102307692307692,
        "transgression": 2.4369230769230774,
        "aggression": 1.9484615384615382,
        "warmth": 7.230769230769231,
        "grandiosity": 2.076923076923077,
        "tribalism": 1.4615384615384615,
        "formality": 5.076923076923077,
        "authenticity": 7.435384615384615,
        "depth": 7.563846153846153,
        "sophistication": 7.499615384615384
      },
      "sophistication": 7.499615384615384,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.9809615384615387
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.486923076923077,
        "transgression": 1.6415384615384612,
        "aggression": 1.7946153846153845,
        "warmth": 6.897692307692308,
        "grandiosity": 2.0000000000000004,
        "tribalism": 1.23,
        "formality": 6.975384615384616,
        "authenticity": 7.153846153846154,
        "depth": 8.026153846153846,
        "sophistication": 7.59
      },
      "sophistication": 7.59,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.6665384615384613
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.820769230769231,
        "transgression": 2.2823076923076924,
        "aggression": 1.8707692307692303,
        "warmth": 7.487692307692308,
        "grandiosity": 1.8192307692307685,
        "tribalism": 1.59,
        "formality": 4.563846153846153,
        "authenticity": 7.563846153846153,
        "depth": 7.666153846153846,
        "sophistication": 7.615
      },
      "sophistication": 7.615,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.8905769230769227
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.384615384615385,
        "transgression": 2.103846153846154,
        "aggression": 1.999230769230769,
        "warmth": 6.768461538461538,
        "grandiosity": 2.3323076923076917,
        "tribalism": 1.0769230769230769,
        "formality": 6.513076923076923,
        "authenticity": 7.204615384615384,
        "depth": 8.179230769230768,
        "sophistication": 7.691923076923077
      },
      "sophistication": 7.691923076923077,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.878076923076923
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.896923076923077,
        "transgression": 2.7953846153846156,
        "aggression": 2.666153846153846,
        "warmth": 6.6923076923076925,
        "grandiosity": 1.9992307692307694,
        "tribalism": 1.6915384615384617,
        "formality": 4.974615384615385,
        "authenticity": 7.614615384615385,
        "depth": 7.7700000000000005,
        "sophistication": 7.6923076923076925
      },
      "sophistication": 7.6923076923076925,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.288076923076923
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.024615384615384,
        "transgression": 2.4630769230769234,
        "aggression": 2.23,
        "warmth": 6.922307692307692,
        "grandiosity": 1.9476923076923072,
        "tribalism": 1.743846153846154,
        "formality": 5.026153846153846,
        "authenticity": 7.667692307692308,
        "depth": 7.743846153846154,
        "sophistication": 7.705769230769231
      },
      "sophistication": 7.705769230769231,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.096153846153846
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.462307692307693,
        "transgression": 3.103846153846154,
        "aggression": 2.6415384615384623,
        "warmth": 6.46076923076923,
        "grandiosity": 1.9984615384615383,
        "tribalism": 1.333076923076923,
        "formality": 4.770769230769231,
        "authenticity": 7.794615384615384,
        "depth": 7.821538461538462,
        "sophistication": 7.808076923076923
      },
      "sophistication": 7.808076923076923,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.269230769230769
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.872307692307692,
        "transgression": 2.0015384615384617,
        "aggression": 1.8199999999999998,
        "warmth": 6.923076923076923,
        "grandiosity": 2.077692307692308,
        "tribalism": 1.0761538461538462,
        "formality": 6.282307692307692,
        "authenticity": 7.462307692307693,
        "depth": 8.35923076923077,
        "sophistication": 7.910769230769231
      },
      "sophistication": 7.910769230769231,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.743846153846154
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.9484615384615385,
        "transgression": 2.128461538461538,
        "aggression": 1.8969230769230767,
        "warmth": 6.538461538461538,
        "grandiosity": 2.2569230769230773,
        "tribalism": 1.1284615384615384,
        "formality": 6.563846153846153,
        "authenticity": 7.5138461538461545,
        "depth": 8.48846153846154,
        "sophistication": 8.001153846153848
      },
      "sophistication": 8.001153846153848,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 1.8526923076923076
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 6.05076923076923,
        "transgression": 2.693076923076923,
        "aggression": 2.1792307692307693,
        "warmth": 6.717692307692308,
        "grandiosity": 2.129230769230769,
        "tribalism": 1.333076923076923,
        "formality": 5.411538461538462,
        "authenticity": 8.076923076923077,
        "depth": 8.05,
        "sophistication": 8.063461538461539
      },
      "sophistication": 8.063461538461539,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.083653846153846
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.922307692307692,
        "transgression": 2.769230769230769,
        "aggression": 2.205384615384616,
        "warmth": 7.103076923076923,
        "grandiosity": 2.102307692307692,
        "tribalism": 1.1792307692307693,
        "formality": 5.641538461538461,
        "authenticity": 8.025384615384615,
        "depth": 8.126923076923076,
        "sophistication": 8.076153846153845
      },
      "sophistication": 8.076153846153845,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.0640384615384617
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.076153846153845,
        "transgression": 3.153076923076923,
        "aggression": 2.8723076923076927,
        "warmth": 6.462307692307691,
        "grandiosity": 2.2569230769230773,
        "tribalism": 1.5646153846153845,
        "formality": 5.0,
        "authenticity": 8.025384615384615,
        "depth": 8.127692307692307,
        "sophistication": 8.076538461538462
      },
      "sophistication": 8.076538461538462,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.461730769230769
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.410769230769231,
        "transgression": 3.0507692307692307,
        "aggression": 2.4607692307692304,
        "warmth": 6.28076923076923,
        "grandiosity": 2.1276923076923073,
        "tribalism": 1.2307692307692308,
        "formality": 4.846153846153846,
        "authenticity": 8.052307692307693,
        "depth": 8.126923076923076,
        "sophistication": 8.089615384615385
      },
      "sophistication": 8.089615384615385,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.2175
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.385384615384615,
        "transgression": 2.3084615384615383,
        "aggression": 1.9984615384615383,
        "warmth": 6.793846153846153,
        "grandiosity": 2.2569230769230773,
        "tribalism": 1.5384615384615385,
        "formality": 6.154615384615385,
        "authenticity": 7.820769230769231,
        "depth": 8.512307692307692,
        "sophistication": 8.166538461538462
      },
      "sophistication": 8.166538461538462,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.0255769230769234
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "hedging": 3.718461538461539,
        "transgression": 2.769230769230769,
        "aggression": 2.0761538461538462,
        "warmth": 7.359230769230769,
        "grandiosity": 2.718461538461539,
        "tribalism": 1.7176923076923076,
        "formality": 6.385384615384615,
        "authenticity": 8.000769230769231,
        "depth": 8.641538461538461,
        "sophistication": 8.321153846153846
      },
      "sophistication": 8.321153846153846,
      "n_contributions": 13,
      "classification": "High-Sophistication",
      "disinhibition": 2.3203846153846155
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 7.011468531468532,
      "high_std": 0.42394263137432353,
      "low_mean": 6.919335664335663,
      "low_std": 0.5238763173801432,
      "difference": 0.09213286713286895,
      "pct_difference": 1.3315276437266867,
      "t_statistic": 0.6412315932638589,
      "p_value": 0.5248561592359426,
      "cohens_d": 0.19333859987072774
    },
    "formality": {
      "high_mean": 5.669370629370628,
      "high_std": 0.8921460835199689,
      "low_mean": 7.344825174825176,
      "low_std": 0.3972959589499058,
      "difference": -1.6754545454545475,
      "pct_difference": -22.811360455484596,
      "t_statistic": -8.046786051513934,
      "p_value": 4.814437287021677e-10,
      "cohens_d": -2.4261972819215596
    },
    "hedging": {
      "high_mean": 5.259755244755245,
      "high_std": 0.5690530059214577,
      "low_mean": 5.770419580419581,
      "low_std": 0.4098041734041523,
      "difference": -0.5106643356643366,
      "pct_difference": -8.84969157870501,
      "t_statistic": -3.4156229447392206,
      "p_value": 0.0014230547335303528,
      "cohens_d": -1.0298490666389828
    },
    "aggression": {
      "high_mean": 2.0611888111888113,
      "high_std": 0.3615190336353359,
      "low_mean": 1.5110139860139862,
      "low_std": 0.25327078609345915,
      "difference": 0.5501748251748251,
      "pct_difference": 36.410968413745216,
      "t_statistic": 5.84615937341949,
      "p_value": 6.610364659889599e-07,
      "cohens_d": 1.7626833732956069
    },
    "transgression": {
      "high_mean": 2.3616433566433566,
      "high_std": 0.47340283573646014,
      "low_mean": 1.4105244755244755,
      "low_std": 0.2277057201231845,
      "difference": 0.9511188811188811,
      "pct_difference": 67.43015790386951,
      "t_statistic": 8.49225380647719,
      "p_value": 1.1629887596139567e-10,
      "cohens_d": 2.5605108636865697
    },
    "grandiosity": {
      "high_mean": 2.128111888111888,
      "high_std": 0.2206423583155564,
      "low_mean": 2.0071678321678323,
      "low_std": 0.20267142142928435,
      "difference": 0.12094405594405577,
      "pct_difference": 6.0256075254768655,
      "t_statistic": 1.8934657702353859,
      "p_value": 0.06519850638643779,
      "cohens_d": 0.570901410295642
    },
    "tribalism": {
      "high_mean": 1.3926573426573425,
      "high_std": 0.2417118352215087,
      "low_mean": 1.1922027972027973,
      "low_std": 0.1981262317024656,
      "difference": 0.20045454545454522,
      "pct_difference": 16.813795935126237,
      "t_statistic": 3.0083440474529377,
      "p_value": 0.00442549376768156,
      "cohens_d": 0.907049858700047
    },
    "depth": {
      "high_mean": 7.888076923076924,
      "high_std": 0.42161209952787276,
      "low_mean": 5.691258741258741,
      "low_std": 0.7721662139087674,
      "difference": 2.196818181818183,
      "pct_difference": 38.59986483995825,
      "t_statistic": 11.71212495015255,
      "p_value": 8.170061957035096e-15,
      "cohens_d": 3.5313385415832688
    },
    "authenticity": {
      "high_mean": 7.472132867132868,
      "high_std": 0.4692690149439714,
      "low_mean": 4.560734265734267,
      "low_std": 0.7985603232515793,
      "difference": 2.9113986013986013,
      "pct_difference": 63.83618145158197,
      "t_statistic": 14.743195980228998,
      "p_value": 3.3144548360448847e-18,
      "cohens_d": 4.445240843372325
    },
    "sophistication": {
      "high_mean": 7.680104895104895,
      "high_std": 0.3870594357305914,
      "low_mean": 5.125996503496503,
      "low_std": 0.7687303560874899,
      "difference": 2.554108391608392,
      "pct_difference": 49.82657303543232,
      "t_statistic": 13.919111125165353,
      "p_value": 2.4848157019650406e-17,
      "cohens_d": 4.196769910675913
    },
    "disinhibition": {
      "high_mean": 1.9859003496503498,
      "high_std": 0.2494219323120392,
      "low_mean": 1.5302272727272728,
      "low_std": 0.17958794564519348,
      "difference": 0.455673076923077,
      "pct_difference": 29.77813067669002,
      "t_statistic": 6.953981688396987,
      "p_value": 1.6913246817940326e-08,
      "cohens_d": 2.0967043690377225
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.4118868288650007
  }
}