# ============================================================================
# SINGLE-PROMPT JOB - QUICK REFERENCE
# ============================================================================
# Copy this template and fill in your values
# See TEMPLATE.yaml for detailed documentation
# ============================================================================

# -------------------------
# REQUIRED FIELDS
# -------------------------
job_id: my_batch_001

prompt: |
  Your prompt text here...

# -------------------------
# MODELS (choose one method)
# -------------------------
# Method 1: Simple list
models:
  - us.anthropic.claude-sonnet-4-5-20250929-v1:0

# Method 2: Per-model config (for extended thinking/reasoning)
# models:
#   - model_id: us.anthropic.claude-sonnet-4-5-20250929-v1:0
#     extended_thinking: true  # Claude 4+ only
#   - openai:gpt-5.1:GPT-5.1|reasoning_effort=high  # OpenAI
#   - grok:grok-3:Grok-3|reasoning_effort=high      # Grok
#   - gemini:gemini-2.5-pro:Gemini-2.5|reasoning_effort=medium  # Gemini

# Method 3: Model list file (RECOMMENDED - reusable across jobs)
# model_list: model_config/main_list
#
# Model list format examples:
#   *bedrock:model_id:display_name|extended_thinking=true
#   *openai:model_id:display_name|reasoning_effort=high
#   *grok:model_id:display_name|reasoning_effort=high
#   *gemini:model_id:display_name|reasoning_effort=medium

# -------------------------
# OPTIONAL FEATURES
# -------------------------
# Export human-readable markdown chat
# export_chat: true

# Prepend additional context from file
# prompt_file: payload/prompts/response_guidelines.txt

# Configure retry behavior (for both models and judge)
# retry_config:
#   max_retries: 3
#   initial_timeout: 120
#   backoff_multiplier: 2.0
#   max_timeout: 300

# -------------------------
# JUDGE EVALUATION (optional)
# -------------------------
# Option 1: Reference external config
# judge: payload/judge_configs/response_quality.yaml

# Option 2: Inline configuration
# judge:
#   judge_prompt: |
#     Evaluate the response...
#   models:
#     - us.anthropic.claude-sonnet-4-5-20250929-v1:0
#   anonymize_pass1: true
#   append_to_source: true
#
#   # Pass 2: Comparative judge can be external file OR inline
#   comparative_judge: payload/judge_configs/comparative.yaml
#   # OR inline:
#   # comparative_judge:
#   #   models:
#   #     - us.anthropic.claude-opus-4-20250514-v1:0
#   #   prompt: |
#   #     Rank models and compare...
#   #   reveal_names: true
