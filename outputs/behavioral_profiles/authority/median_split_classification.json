{
  "median_sophistication": 6.721960784313726,
  "n_high_sophistication": 23,
  "n_low_sophistication": 22,
  "models": [
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.83,
        "transgression": 1.2733333333333328,
        "grandiosity": 1.9015686274509802,
        "tribalism": 1.1437254901960785,
        "authenticity": 3.536078431372549,
        "depth": 4.869411764705882,
        "hedging": 4.869411764705882,
        "aggression": 1.3264705882352938,
        "warmth": 5.476862745098038,
        "sophistication": 4.202745098039216
      },
      "sophistication": 4.202745098039216,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4112745098039212
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "formality": 8.201176470588234,
        "transgression": 1.208039215686274,
        "grandiosity": 2.085686274509804,
        "tribalism": 1.0196078431372548,
        "authenticity": 3.947647058823529,
        "depth": 5.535882352941175,
        "hedging": 6.770196078431371,
        "aggression": 1.1698039215686273,
        "warmth": 5.725294117647058,
        "sophistication": 4.7417647058823515
      },
      "sophistication": 4.7417647058823515,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.37078431372549
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "formality": 5.035098039215686,
        "transgression": 1.7874509803921568,
        "grandiosity": 2.055686274509804,
        "tribalism": 1.0850980392156864,
        "authenticity": 4.653529411764705,
        "depth": 5.0362745098039206,
        "hedging": 4.656666666666667,
        "aggression": 1.5186274509803919,
        "warmth": 3.4582352941176464,
        "sophistication": 4.844901960784313
      },
      "sophistication": 4.844901960784313,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6117156862745097
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 5.022156862745098,
        "transgression": 1.8164705882352938,
        "grandiosity": 1.9870588235294118,
        "tribalism": 1.0850980392156864,
        "authenticity": 4.711764705882355,
        "depth": 4.993725490196078,
        "hedging": 4.386470588235293,
        "aggression": 1.6325490196078427,
        "warmth": 3.4380392156862745,
        "sophistication": 4.852745098039216
      },
      "sophistication": 4.852745098039216,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6302941176470587
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.136666666666667,
        "transgression": 1.2211764705882349,
        "grandiosity": 1.961372549019608,
        "tribalism": 1.026078431372549,
        "authenticity": 4.640392156862745,
        "depth": 5.405294117647059,
        "hedging": 8.476078431372546,
        "aggression": 1.2088235294117646,
        "warmth": 5.502352941176472,
        "sophistication": 5.0228431372549025
      },
      "sophistication": 5.0228431372549025,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3543627450980393
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "formality": 8.16294117647059,
        "transgression": 1.2927450980392152,
        "grandiosity": 2.34,
        "tribalism": 1.1501960784313725,
        "authenticity": 4.229019607843135,
        "depth": 5.8819607843137245,
        "hedging": 6.2672549019607855,
        "aggression": 1.3129411764705878,
        "warmth": 5.366274509803921,
        "sophistication": 5.05549019607843
      },
      "sophistication": 5.05549019607843,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5239705882352939
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.234901960784311,
        "transgression": 1.195490196078431,
        "grandiosity": 2.085686274509804,
        "tribalism": 1.052156862745098,
        "authenticity": 4.470392156862745,
        "depth": 5.6927450980392145,
        "hedging": 7.398039215686275,
        "aggression": 1.1631372549019605,
        "warmth": 6.352745098039217,
        "sophistication": 5.08156862745098
      },
      "sophistication": 5.08156862745098,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3741176470588234
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "formality": 8.241176470588236,
        "transgression": 1.299411764705882,
        "grandiosity": 2.294313725490196,
        "tribalism": 1.006470588235294,
        "authenticity": 4.18313725490196,
        "depth": 6.03921568627451,
        "hedging": 7.3133333333333335,
        "aggression": 1.1564705882352941,
        "warmth": 5.0911764705882385,
        "sophistication": 5.111176470588235
      },
      "sophistication": 5.111176470588235,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4391666666666665
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "formality": 8.29392156862745,
        "transgression": 1.3066666666666666,
        "grandiosity": 2.085686274509804,
        "tribalism": 1.0849019607843138,
        "authenticity": 4.417843137254903,
        "depth": 6.0650980392156875,
        "hedging": 8.391764705882352,
        "aggression": 1.234705882352941,
        "warmth": 5.659215686274511,
        "sophistication": 5.241470588235295
      },
      "sophistication": 5.241470588235295,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4279901960784314
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.181960784313723,
        "transgression": 1.2282352941176469,
        "grandiosity": 1.8962745098039218,
        "tribalism": 1.0131372549019608,
        "authenticity": 4.817058823529412,
        "depth": 5.829803921568629,
        "hedging": 8.63313725490196,
        "aggression": 1.0780392156862744,
        "warmth": 6.019411764705882,
        "sophistication": 5.32343137254902
      },
      "sophistication": 5.32343137254902,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3039215686274508
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "formality": 8.313137254901958,
        "transgression": 1.2676470588235293,
        "grandiosity": 2.0529411764705885,
        "tribalism": 1.0586274509803921,
        "authenticity": 4.634313725490196,
        "depth": 6.156470588235293,
        "hedging": 8.228823529411764,
        "aggression": 1.2415686274509803,
        "warmth": 5.685686274509805,
        "ribalism": 1.0,
        "sophistication": 5.395392156862744
      },
      "sophistication": 5.395392156862744,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4051960784313726
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "formality": 8.241176470588234,
        "transgression": 1.189019607843137,
        "grandiosity": 2.1566666666666667,
        "tribalism": 1.0129411764705882,
        "authenticity": 4.614901960784313,
        "depth": 6.255098039215686,
        "hedging": 7.972941176470587,
        "aggression": 1.1694117647058822,
        "warmth": 5.48313725490196,
        "ribalism": 1.0,
        "sophistication": 5.435
      },
      "sophistication": 5.435,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3820098039215685
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.790588235294117,
        "transgression": 1.2741176470588234,
        "grandiosity": 1.935294117647059,
        "tribalism": 1.0719607843137255,
        "authenticity": 5.254705882352941,
        "depth": 5.895882352941176,
        "hedging": 8.685882352941174,
        "aggression": 1.1435294117647057,
        "warmth": 6.248627450980393,
        "sophistication": 5.575294117647059
      },
      "sophistication": 5.575294117647059,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3562254901960784
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "formality": 8.127450980392156,
        "transgression": 1.3327450980392155,
        "grandiosity": 2.1603921568627453,
        "tribalism": 1.0719607843137255,
        "authenticity": 5.061960784313726,
        "depth": 6.153529411764707,
        "hedging": 8.548039215686273,
        "aggression": 1.277450980392157,
        "warmth": 6.084705882352942,
        "sophistication": 5.607745098039216
      },
      "sophistication": 5.607745098039216,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.460637254901961
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.765098039215687,
        "transgression": 1.3382352941176465,
        "grandiosity": 2.1901960784313728,
        "tribalism": 1.078235294117647,
        "authenticity": 4.96078431372549,
        "depth": 6.294705882352941,
        "hedging": 5.483137254901963,
        "aggression": 1.3329411764705883,
        "warmth": 5.633921568627452,
        "ribalism": 1.0,
        "sophistication": 5.627745098039216
      },
      "sophistication": 5.627745098039216,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4849019607843137
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "formality": 8.071960784313724,
        "transgression": 1.3327450980392157,
        "grandiosity": 2.3990196078431376,
        "tribalism": 1.1241176470588234,
        "authenticity": 4.895490196078431,
        "depth": 6.450980392156862,
        "hedging": 7.365490196078433,
        "aggression": 1.3980392156862742,
        "warmth": 5.934313725490198,
        "sophistication": 5.673235294117647
      },
      "sophistication": 5.673235294117647,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5634803921568627
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 8.045294117647058,
        "transgression": 1.4827450980392152,
        "grandiosity": 2.065098039215686,
        "tribalism": 1.0719607843137255,
        "authenticity": 5.05235294117647,
        "depth": 6.353529411764707,
        "hedging": 7.548431372549021,
        "aggression": 1.2478431372549017,
        "warmth": 5.130588235294117,
        "ribalism": 1.0,
        "sophistication": 5.702941176470588
      },
      "sophistication": 5.702941176470588,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4669117647058822
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.771372549019607,
        "transgression": 1.3001960784313726,
        "grandiosity": 2.0525490196078433,
        "tribalism": 1.0719607843137255,
        "authenticity": 5.37921568627451,
        "depth": 6.144509803921567,
        "hedging": 8.156862745098039,
        "aggression": 1.2407843137254897,
        "warmth": 5.803921568627452,
        "sophistication": 5.761862745098039
      },
      "sophistication": 5.761862745098039,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4163725490196077
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "formality": 8.490980392156864,
        "transgression": 1.3839215686274504,
        "grandiosity": 2.261764705882353,
        "tribalism": 1.1956862745098038,
        "authenticity": 4.757843137254902,
        "depth": 6.85607843137255,
        "hedging": 5.8172549019607835,
        "aggression": 1.3388235294117645,
        "warmth": 5.555098039215688,
        "sophistication": 5.806960784313726
      },
      "sophistication": 5.806960784313726,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5450490196078428
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "formality": 8.660588235294117,
        "transgression": 1.266862745098039,
        "grandiosity": 2.2615686274509805,
        "tribalism": 1.15,
        "authenticity": 4.895098039215685,
        "depth": 7.110980392156866,
        "hedging": 5.9929411764705875,
        "aggression": 1.2474509803921565,
        "warmth": 5.39843137254902,
        "sophistication": 6.003039215686275
      },
      "sophistication": 6.003039215686275,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.481470588235294
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "formality": 8.562941176470588,
        "transgression": 1.3839215686274502,
        "grandiosity": 2.2605882352941173,
        "tribalism": 1.1174509803921568,
        "authenticity": 4.954313725490198,
        "depth": 7.05862745098039,
        "hedging": 6.523333333333333,
        "aggression": 1.280392156862745,
        "warmth": 5.195490196078433,
        "sophistication": 6.006470588235294
      },
      "sophistication": 6.006470588235294,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.5105882352941173
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "formality": 8.738627450980395,
        "transgression": 1.2809803921568628,
        "grandiosity": 2.3462745098039215,
        "tribalism": 1.0588235294117647,
        "authenticity": 5.529411764705883,
        "depth": 7.601372549019609,
        "hedging": 8.444117647058823,
        "aggression": 1.3064705882352938,
        "warmth": 5.92764705882353,
        "sophistication": 6.565392156862746
      },
      "sophistication": 6.565392156862746,
      "n_contributions": 51,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4981372549019607
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.006274509803921,
        "transgression": 1.8621568627450977,
        "grandiosity": 1.9931372549019606,
        "tribalism": 1.1241176470588234,
        "authenticity": 6.502941176470588,
        "depth": 6.940980392156864,
        "hedging": 8.359803921568625,
        "aggression": 1.3588235294117643,
        "warmth": 5.640196078431371,
        "sophistication": 6.721960784313726
      },
      "sophistication": 6.721960784313726,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.5845588235294115
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.274509803921568,
        "transgression": 1.8296078431372547,
        "grandiosity": 2.006666666666667,
        "tribalism": 1.1305882352941177,
        "authenticity": 6.4768627450980425,
        "depth": 6.973921568627452,
        "hedging": 8.28764705882353,
        "aggression": 1.4045098039215682,
        "warmth": 5.391960784313726,
        "ribalism": 1.0,
        "sophistication": 6.725392156862747
      },
      "sophistication": 6.725392156862747,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.592843137254902
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "formality": 7.941960784313725,
        "transgression": 1.4239215686274505,
        "grandiosity": 2.2803921568627445,
        "tribalism": 1.1372549019607843,
        "authenticity": 6.064901960784312,
        "depth": 7.588431372549019,
        "hedging": 8.031960784313723,
        "aggression": 1.535098039215686,
        "warmth": 5.581568627450982,
        "sophistication": 6.826666666666666
      },
      "sophistication": 6.826666666666666,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.5941666666666663
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.856862745098038,
        "transgression": 2.0333333333333337,
        "grandiosity": 1.9349019607843139,
        "tribalism": 1.0652941176470587,
        "authenticity": 6.7452941176470596,
        "depth": 6.966078431372548,
        "hedging": 8.130196078431371,
        "aggression": 1.5349019607843135,
        "warmth": 5.079019607843136,
        "sophistication": 6.855686274509804
      },
      "sophistication": 6.855686274509804,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.6421078431372549
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "formality": 8.608235294117648,
        "transgression": 1.725294117647059,
        "grandiosity": 2.5945098039215684,
        "tribalism": 1.2284313725490195,
        "authenticity": 5.967058823529412,
        "depth": 7.96705882352941,
        "hedging": 6.267647058823529,
        "aggression": 1.7574509803921567,
        "warmth": 4.6462745098039235,
        "sophistication": 6.9670588235294115
      },
      "sophistication": 6.9670588235294115,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.8264215686274508
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.143921568627452,
        "transgression": 1.9805882352941178,
        "grandiosity": 2.05921568627451,
        "tribalism": 1.039019607843137,
        "authenticity": 6.8364705882352945,
        "depth": 7.249215686274508,
        "hedging": 8.085098039215689,
        "aggression": 1.5221568627450976,
        "warmth": 5.273529411764706,
        "sophistication": 7.042843137254901
      },
      "sophistication": 7.042843137254901,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.6502450980392156
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "formality": 8.601764705882351,
        "transgression": 1.5678431372549018,
        "grandiosity": 2.2880392156862746,
        "tribalism": 1.1239215686274509,
        "authenticity": 6.340588235294115,
        "depth": 7.862549019607845,
        "hedging": 8.254117647058825,
        "aggression": 1.3586274509803917,
        "warmth": 5.18313725490196,
        "sophistication": 7.10156862745098
      },
      "sophistication": 7.10156862745098,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.5846078431372548
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "formality": 7.777647058823531,
        "transgression": 1.6994117647058822,
        "grandiosity": 2.5227450980392154,
        "tribalism": 1.1437254901960785,
        "authenticity": 6.41843137254902,
        "depth": 7.824117647058823,
        "hedging": 7.99941176470588,
        "aggression": 1.4311764705882353,
        "warmth": 6.73862745098039,
        "sophistication": 7.121274509803921
      },
      "sophistication": 7.121274509803921,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.699264705882353
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.463725490196077,
        "transgression": 2.0394117647058825,
        "grandiosity": 2.215686274509804,
        "tribalism": 1.222156862745098,
        "authenticity": 7.215490196078432,
        "depth": 7.313529411764702,
        "hedging": 8.483137254901962,
        "aggression": 1.6337254901960783,
        "warmth": 5.222156862745097,
        "sophistication": 7.264509803921567
      },
      "sophistication": 7.264509803921567,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.7777450980392155
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 7.087843137254904,
        "transgression": 1.9515686274509807,
        "grandiosity": 2.0686274509803924,
        "tribalism": 1.1307843137254903,
        "authenticity": 7.271176470588234,
        "depth": 7.3696078431372545,
        "hedging": 8.557450980392154,
        "aggression": 1.5096078431372548,
        "warmth": 5.6896078431372565,
        "ribalism": 1.0,
        "sophistication": 7.320392156862744
      },
      "sophistication": 7.320392156862744,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.6651470588235293
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "formality": 8.32078431372549,
        "transgression": 1.7452941176470589,
        "grandiosity": 2.8241176470588236,
        "tribalism": 1.215098039215686,
        "authenticity": 6.757254901960785,
        "depth": 8.071960784313724,
        "hedging": 7.37235294117647,
        "aggression": 1.7313725490196077,
        "warmth": 5.522352941176471,
        "sophistication": 7.414607843137254
      },
      "sophistication": 7.414607843137254,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.878970588235294
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "formality": 8.457843137254901,
        "transgression": 1.4503921568627447,
        "grandiosity": 2.464313725490196,
        "tribalism": 1.1105882352941174,
        "authenticity": 6.692549019607842,
        "depth": 8.346862745098038,
        "hedging": 6.927450980392157,
        "aggression": 1.416666666666666,
        "warmth": 5.444117647058823,
        "sophistication": 7.51970588235294
      },
      "sophistication": 7.51970588235294,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.6104901960784312
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.76764705882353,
        "transgression": 2.5552941176470583,
        "grandiosity": 2.2084313725490192,
        "tribalism": 1.2152941176470586,
        "authenticity": 7.551764705882353,
        "depth": 7.7750980392156865,
        "hedging": 8.208627450980389,
        "aggression": 1.9280392156862745,
        "warmth": 5.281372549019606,
        "sophistication": 7.66343137254902
      },
      "sophistication": 7.66343137254902,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.9767647058823525
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "formality": 8.327058823529413,
        "transgression": 1.8427450980392157,
        "grandiosity": 2.5094117647058822,
        "tribalism": 1.2805882352941174,
        "authenticity": 7.032156862745098,
        "depth": 8.353725490196084,
        "hedging": 7.914901960784311,
        "aggression": 1.5217647058823527,
        "warmth": 4.666666666666668,
        "sophistication": 7.69294117647059
      },
      "sophistication": 7.69294117647059,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.788627450980392
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.362745098039217,
        "transgression": 1.8001960784313724,
        "grandiosity": 2.3298039215686273,
        "tribalism": 1.1694117647058822,
        "authenticity": 6.970588235294118,
        "depth": 8.454117647058823,
        "hedging": 6.6894117647058815,
        "aggression": 1.5515686274509801,
        "warmth": 5.3945098039215695,
        "sophistication": 7.71235294117647
      },
      "sophistication": 7.71235294117647,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.7127450980392154
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "formality": 8.674313725490196,
        "transgression": 1.9017647058823528,
        "grandiosity": 2.7058823529411757,
        "tribalism": 1.2217647058823526,
        "authenticity": 7.19686274509804,
        "depth": 8.542745098039216,
        "hedging": 7.790980392156864,
        "aggression": 1.7970588235294116,
        "warmth": 4.940980392156864,
        "sophistication": 7.869803921568628
      },
      "sophistication": 7.869803921568628,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.9066176470588232
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.150588235294113,
        "transgression": 1.9411764705882353,
        "grandiosity": 2.287450980392157,
        "tribalism": 1.1831372549019608,
        "authenticity": 7.281176470588234,
        "depth": 8.503921568627453,
        "hedging": 6.228431372549018,
        "aggression": 1.7184313725490192,
        "warmth": 5.561568627450982,
        "sophistication": 7.892549019607843
      },
      "sophistication": 7.892549019607843,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.7825490196078428
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.950196078431371,
        "transgression": 2.8170588235294125,
        "grandiosity": 2.402156862745098,
        "tribalism": 1.3392156862745095,
        "authenticity": 7.715882352941177,
        "depth": 8.078235294117647,
        "hedging": 7.9833333333333325,
        "aggression": 2.0258823529411765,
        "warmth": 5.401764705882352,
        "sophistication": 7.897058823529412
      },
      "sophistication": 7.897058823529412,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.1460784313725494
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.162156862745098,
        "transgression": 1.9084313725490198,
        "grandiosity": 2.320392156862745,
        "tribalism": 1.117254901960784,
        "authenticity": 7.2621568627450985,
        "depth": 8.5621568627451,
        "hedging": 6.7513725490196075,
        "aggression": 1.6135294117647057,
        "warmth": 5.390980392156864,
        "sophistication": 7.9121568627451
      },
      "sophistication": 7.9121568627451,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.7399019607843136
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "formality": 7.301372549019606,
        "transgression": 1.9672549019607843,
        "grandiosity": 2.3786274509803924,
        "tribalism": 1.2676470588235293,
        "authenticity": 7.274705882352941,
        "depth": 8.575490196078434,
        "hedging": 6.784117647058823,
        "aggression": 1.7576470588235291,
        "warmth": 5.6270588235294134,
        "sophistication": 7.925098039215687
      },
      "sophistication": 7.925098039215687,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.8427941176470588
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.255294117647059,
        "transgression": 2.6729411764705886,
        "grandiosity": 2.2613725490196077,
        "tribalism": 1.1303921568627449,
        "authenticity": 7.967450980392157,
        "depth": 8.02549019607843,
        "hedging": 7.8554901960784305,
        "aggression": 1.986862745098039,
        "warmth": 5.398627450980391,
        "sophistication": 7.996470588235294
      },
      "sophistication": 7.996470588235294,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.012892156862745
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "formality": 6.418235294117647,
        "transgression": 2.620980392156863,
        "grandiosity": 2.3201960784313727,
        "tribalism": 1.1105882352941174,
        "authenticity": 7.928039215686274,
        "depth": 8.07156862745098,
        "hedging": 8.059607843137256,
        "aggression": 1.9011764705882352,
        "warmth": 5.561960784313727,
        "sophistication": 7.999803921568627
      },
      "sophistication": 7.999803921568627,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 1.988235294117647
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "formality": 8.510784313725495,
        "transgression": 3.3000000000000007,
        "grandiosity": 3.2811764705882354,
        "tribalism": 1.7478431372549017,
        "authenticity": 7.77764705882353,
        "depth": 8.70607843137255,
        "hedging": 7.587450980392159,
        "aggression": 2.6794117647058817,
        "warmth": 3.8231372549019604,
        "sophistication": 8.24186274509804
      },
      "sophistication": 8.24186274509804,
      "n_contributions": 51,
      "classification": "High-Sophistication",
      "disinhibition": 2.7521078431372548
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 5.3243989769820965,
      "high_std": 0.5209614421909918,
      "low_mean": 5.462326203208557,
      "low_std": 0.7338526881045072,
      "difference": -0.13792722622646014,
      "pct_difference": -2.5250638847867055,
      "t_statistic": -0.7295909475454562,
      "p_value": 0.4695961643373061,
      "cohens_d": -0.21757572296544864
    },
    "formality": {
      "high_mean": 7.540076726342711,
      "high_std": 0.7450530635153001,
      "low_mean": 7.90541889483066,
      "low_std": 0.9680550945207363,
      "difference": -0.365342168487949,
      "pct_difference": -4.621414416468754,
      "t_statistic": -1.422531611005906,
      "p_value": 0.16208625782077946,
      "cohens_d": -0.4242217433578161
    },
    "hedging": {
      "high_mean": 7.6786956521739125,
      "high_std": 0.7135053445148626,
      "low_mean": 7.087709447415329,
      "low_std": 1.3941331396591805,
      "difference": 0.5909862047585834,
      "pct_difference": 8.338183289583041,
      "t_statistic": 1.8018275753386424,
      "p_value": 0.07858617247711551,
      "cohens_d": 0.5373338837088042
    },
    "aggression": {
      "high_mean": 1.6815430520034096,
      "high_std": 0.29469053714897,
      "low_mean": 1.2739215686274505,
      "low_std": 0.12526105363383933,
      "difference": 0.40762148337595905,
      "pct_difference": 31.997376715674804,
      "t_statistic": 5.988708298483733,
      "p_value": 3.797321447474884e-07,
      "cohens_d": 1.7859288715895127
    },
    "transgression": {
      "high_mean": 2.0276811594202893,
      "high_std": 0.4611647826292977,
      "low_mean": 1.339188948306595,
      "low_std": 0.1645622210991258,
      "difference": 0.6884922111136942,
      "pct_difference": 51.41113298345934,
      "t_statistic": 6.6088519983199046,
      "p_value": 4.7544738833183524e-08,
      "cohens_d": 1.9708656697889126
    },
    "grandiosity": {
      "high_mean": 2.359011082693947,
      "high_std": 0.30077738500422696,
      "low_mean": 2.1288948306595366,
      "low_std": 0.1493399984175325,
      "difference": 0.23011625203441044,
      "pct_difference": 10.809188350704947,
      "t_statistic": 3.227039592469663,
      "p_value": 0.002394487472831518,
      "cohens_d": 0.9623549671659936
    },
    "tribalism": {
      "high_mean": 1.1936572890025572,
      "high_std": 0.14031023372689608,
      "low_mean": 1.0795543672014258,
      "low_std": 0.05050377585433459,
      "difference": 0.11410292180113135,
      "pct_difference": 10.569446548294287,
      "t_statistic": 3.596498174099206,
      "p_value": 0.0008265784469433372,
      "cohens_d": 1.0725334422063912
    },
    "depth": {
      "high_mean": 7.918388746803069,
      "high_std": 0.562314778165071,
      "low_mean": 6.076417112299466,
      "low_std": 0.6906029251981652,
      "difference": 1.8419716345036035,
      "pct_difference": 30.31344952892077,
      "t_statistic": 9.831516101408265,
      "p_value": 1.442138654928702e-12,
      "cohens_d": 2.9319157958399398
    },
    "authenticity": {
      "high_mean": 7.01075873827792,
      "high_std": 0.5673034013238768,
      "low_mean": 4.708966131907307,
      "low_std": 0.4626953049767191,
      "difference": 2.301792606370613,
      "pct_difference": 48.88106097799224,
      "t_statistic": 14.876037038208361,
      "p_value": 1.458781731050478e-18,
      "cohens_d": 4.436272851709579
    },
    "sophistication": {
      "high_mean": 7.4645737425404945,
      "high_std": 0.4714760699860387,
      "low_mean": 5.392691622103386,
      "low_std": 0.5177552449754225,
      "difference": 2.0718821204371087,
      "pct_difference": 38.420185421783565,
      "t_statistic": 14.046348116157969,
      "p_value": 1.1396842367456334e-17,
      "cohens_d": 4.188846307206996
    },
    "disinhibition": {
      "high_mean": 1.8154731457800508,
      "high_std": 0.2571482747024069,
      "low_mean": 1.4553899286987524,
      "low_std": 0.08596040813234138,
      "difference": 0.3600832170812984,
      "pct_difference": 24.74135693677946,
      "t_statistic": 6.240262449502091,
      "p_value": 1.6347123972412398e-07,
      "cohens_d": 1.8609463542719835
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.5878688286036511
  }
}