{
  "median_sophistication": 5.171928571428571,
  "n_high_sophistication": 23,
  "n_low_sophistication": 23,
  "models": [
    {
      "model_id": "llama-3-70b",
      "display_name": "Llama-3-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.5139999999999998,
        "depth": 2.7622857142857145,
        "hedging": 2.133142857142857,
        "aggression": 1.341428571428571,
        "formality": 3.3419999999999996,
        "tribalism": 1.086,
        "authenticity": 2.342,
        "transgression": 1.256285714285714,
        "warmth": 2.305142857142857,
        "sophistication": 2.552142857142857
      },
      "sophistication": 2.552142857142857,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2994285714285714
    },
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.4948571428571427,
        "depth": 4.190571428571428,
        "hedging": 4.152000000000001,
        "aggression": 1.2182857142857142,
        "formality": 6.885142857142857,
        "tribalism": 1.1522857142857141,
        "authenticity": 3.485142857142857,
        "transgression": 1.321714285714285,
        "warmth": 6.371428571428571,
        "sophistication": 3.8378571428571426
      },
      "sophistication": 3.8378571428571426,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.296785714285714
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.475428571428571,
        "depth": 4.372285714285714,
        "hedging": 4.790285714285714,
        "aggression": 1.1039999999999999,
        "formality": 7.019142857142858,
        "tribalism": 1.0474285714285714,
        "authenticity": 3.514857142857143,
        "transgression": 1.3408571428571425,
        "warmth": 6.066857142857143,
        "sophistication": 3.9435714285714285
      },
      "sophistication": 3.9435714285714285,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2419285714285713
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.5331428571428571,
        "depth": 4.637142857142858,
        "hedging": 4.705142857142857,
        "aggression": 1.0757142857142856,
        "formality": 7.5428571428571445,
        "tribalism": 1.0191428571428571,
        "authenticity": 3.5525714285714285,
        "transgression": 1.2837142857142851,
        "warmth": 6.409714285714287,
        "sophistication": 4.094857142857143
      },
      "sophistication": 4.094857142857143,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2279285714285713
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7434285714285718,
        "depth": 4.609714285714286,
        "hedging": 5.209714285714286,
        "aggression": 1.1522857142857141,
        "formality": 7.552571428571429,
        "tribalism": 1.0571428571428572,
        "authenticity": 3.609714285714286,
        "transgression": 1.3028571428571423,
        "warmth": 6.495714285714286,
        "sophistication": 4.109714285714286
      },
      "sophistication": 4.109714285714286,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3139285714285713
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.647428571428571,
        "depth": 4.675999999999999,
        "hedging": 5.065999999999999,
        "aggression": 1.0945714285714285,
        "formality": 7.5617142857142845,
        "tribalism": 1.0759999999999998,
        "authenticity": 3.5997142857142856,
        "transgression": 1.2648571428571422,
        "warmth": 6.591142857142856,
        "sophistication": 4.1378571428571425
      },
      "sophistication": 4.1378571428571425,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2707142857142852
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.6279999999999994,
        "depth": 4.686571428571429,
        "hedging": 5.342857142857142,
        "aggression": 1.1708571428571428,
        "formality": 7.494285714285716,
        "tribalism": 1.0951428571428572,
        "authenticity": 3.5905714285714287,
        "transgression": 1.2559999999999996,
        "warmth": 6.104000000000002,
        "sophistication": 4.138571428571429
      },
      "sophistication": 4.138571428571429,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2874999999999996
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.5328571428571427,
        "depth": 4.637714285714287,
        "hedging": 5.323714285714286,
        "aggression": 1.1328571428571426,
        "formality": 7.142285714285714,
        "tribalism": 1.0,
        "authenticity": 3.667142857142857,
        "transgression": 1.245714285714285,
        "warmth": 6.3417142857142865,
        "sophistication": 4.152428571428572
      },
      "sophistication": 4.152428571428572,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2278571428571425
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.580571428571428,
        "depth": 4.895999999999999,
        "hedging": 5.285142857142857,
        "aggression": 1.1137142857142854,
        "formality": 7.457714285714285,
        "tribalism": 1.0,
        "authenticity": 3.648,
        "transgression": 1.208285714285714,
        "warmth": 5.791142857142857,
        "sophistication": 4.271999999999999
      },
      "sophistication": 4.271999999999999,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2256428571428568
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.743142857142857,
        "depth": 4.934,
        "hedging": 4.895714285714287,
        "aggression": 1.1428571428571428,
        "formality": 7.580857142857146,
        "tribalism": 1.0854285714285712,
        "authenticity": 3.742857142857143,
        "transgression": 1.3134285714285712,
        "warmth": 6.438285714285714,
        "sophistication": 4.3384285714285715
      },
      "sophistication": 4.3384285714285715,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3212142857142855
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7428571428571427,
        "depth": 4.951428571428572,
        "hedging": 5.247142857142857,
        "aggression": 1.1422857142857141,
        "formality": 7.324857142857143,
        "tribalism": 1.0665714285714285,
        "authenticity": 3.7997142857142854,
        "transgression": 1.2362857142857138,
        "warmth": 6.324,
        "sophistication": 4.375571428571429
      },
      "sophistication": 4.375571428571429,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.297
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.5991428571428568,
        "depth": 5.0288571428571425,
        "hedging": 5.418285714285717,
        "aggression": 1.1237142857142859,
        "formality": 7.247714285714285,
        "tribalism": 1.0191428571428571,
        "authenticity": 3.7234285714285713,
        "transgression": 1.2739999999999996,
        "warmth": 6.41857142857143,
        "sophistication": 4.376142857142857
      },
      "sophistication": 4.376142857142857,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.254
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.6945714285714282,
        "depth": 5.066285714285714,
        "hedging": 5.286285714285714,
        "aggression": 1.1328571428571428,
        "formality": 7.286,
        "tribalism": 1.0094285714285713,
        "authenticity": 3.751714285714285,
        "transgression": 1.2459999999999996,
        "warmth": 6.904571428571429,
        "sophistication": 4.408999999999999
      },
      "sophistication": 4.408999999999999,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2707142857142855
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.6285714285714283,
        "depth": 5.114285714285715,
        "hedging": 5.38057142857143,
        "aggression": 1.1137142857142857,
        "formality": 7.372,
        "tribalism": 1.0665714285714285,
        "authenticity": 3.742571428571429,
        "transgression": 1.284285714285714,
        "warmth": 6.542571428571428,
        "sophistication": 4.428428571428572
      },
      "sophistication": 4.428428571428572,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2732857142857141
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.542285714285714,
        "depth": 5.0182857142857165,
        "hedging": 5.038857142857142,
        "aggression": 1.1134285714285712,
        "formality": 6.828857142857143,
        "tribalism": 1.0,
        "authenticity": 4.028285714285714,
        "transgression": 1.2362857142857138,
        "warmth": 6.513428571428575,
        "ribalism": 1.0,
        "sophistication": 4.523285714285715
      },
      "sophistication": 4.523285714285715,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2229999999999996
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.5708571428571427,
        "depth": 5.0762857142857145,
        "hedging": 4.657142857142858,
        "aggression": 1.1328571428571426,
        "formality": 6.971999999999999,
        "tribalism": 1.086,
        "authenticity": 4.034000000000001,
        "transgression": 1.275142857142857,
        "warmth": 6.45742857142857,
        "observability": 4.0,
        "sophistication": 4.555142857142858
      },
      "sophistication": 4.555142857142858,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2662142857142857
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.6279999999999997,
        "depth": 5.124285714285714,
        "hedging": 5.038571428571428,
        "aggression": 1.171142857142857,
        "formality": 7.219142857142858,
        "tribalism": 1.0188571428571427,
        "authenticity": 4.10342857142857,
        "transgression": 1.2934285714285707,
        "warmth": 6.476285714285711,
        "sophistication": 4.613857142857142
      },
      "sophistication": 4.613857142857142,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2778571428571426
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8197142857142858,
        "depth": 5.228571428571429,
        "hedging": 5.371714285714285,
        "aggression": 1.1808571428571428,
        "formality": 7.399714285714286,
        "tribalism": 1.1142857142857143,
        "authenticity": 4.123428571428572,
        "transgression": 1.3411428571428565,
        "warmth": 6.667142857142856,
        "sophistication": 4.676
      },
      "sophistication": 4.676,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3639999999999999
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7139999999999997,
        "depth": 5.438571428571429,
        "hedging": 4.5048571428571424,
        "aggression": 1.0757142857142856,
        "formality": 7.20857142857143,
        "tribalism": 1.0857142857142856,
        "authenticity": 4.295428571428572,
        "transgression": 1.2839999999999994,
        "warmth": 6.647142857142858,
        "sophistication": 4.867000000000001
      },
      "sophistication": 4.867000000000001,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2898571428571426
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "grandiosity": 1.5034285714285707,
        "depth": 5.390857142857143,
        "hedging": 4.980857142857142,
        "aggression": 1.085142857142857,
        "formality": 6.581428571428571,
        "tribalism": 1.0285714285714285,
        "authenticity": 4.4005714285714275,
        "transgression": 1.2177142857142853,
        "warmth": 6.647714285714287,
        "sophistication": 4.895714285714285
      },
      "sophistication": 4.895714285714285,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2087142857142854
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "grandiosity": 1.7342857142857144,
        "depth": 5.428000000000002,
        "hedging": 5.114285714285714,
        "aggression": 1.0568571428571427,
        "formality": 6.829142857142856,
        "tribalism": 1.0191428571428571,
        "authenticity": 4.447714285714286,
        "transgression": 1.246571428571428,
        "warmth": 7.170571428571429,
        "sophistication": 4.937857142857144
      },
      "sophistication": 4.937857142857144,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2642142857142855
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.5991428571428568,
        "depth": 5.419714285714286,
        "hedging": 5.018857142857143,
        "aggression": 1.1137142857142857,
        "formality": 6.780857142857143,
        "tribalism": 1.0,
        "authenticity": 4.533428571428573,
        "transgression": 1.2845714285714285,
        "warmth": 7.04742857142857,
        "sophistication": 4.976571428571429
      },
      "sophistication": 4.976571428571429,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2493571428571428
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6951428571428568,
        "depth": 5.600285714285715,
        "hedging": 5.429142857142856,
        "aggression": 1.1042857142857143,
        "formality": 7.152571428571428,
        "tribalism": 1.0,
        "authenticity": 4.409714285714286,
        "transgression": 1.3319999999999996,
        "warmth": 6.381142857142857,
        "sophistication": 5.005000000000001
      },
      "sophistication": 5.005000000000001,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2828571428571427
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "grandiosity": 1.5905714285714285,
        "depth": 5.943142857142856,
        "hedging": 4.895428571428571,
        "aggression": 1.170285714285714,
        "formality": 6.752,
        "tribalism": 1.0191428571428571,
        "authenticity": 4.734571428571427,
        "transgression": 1.2279999999999998,
        "warmth": 6.399714285714285,
        "sophistication": 5.338857142857142
      },
      "sophistication": 5.338857142857142,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.2519999999999998
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "grandiosity": 1.9248571428571435,
        "depth": 6.190857142857141,
        "hedging": 5.113714285714285,
        "aggression": 1.1045714285714288,
        "formality": 6.714285714285715,
        "tribalism": 1.1145714285714288,
        "authenticity": 5.076571428571428,
        "transgression": 1.3897142857142855,
        "warmth": 7.018857142857142,
        "sophistication": 5.633714285714284
      },
      "sophistication": 5.633714285714284,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3834285714285717
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "grandiosity": 1.7717142857142854,
        "depth": 6.57142857142857,
        "hedging": 4.772285714285713,
        "aggression": 1.1608571428571426,
        "formality": 7.209428571428572,
        "tribalism": 1.0282857142857142,
        "authenticity": 5.248571428571427,
        "transgression": 1.4177142857142853,
        "warmth": 6.381142857142856,
        "sophistication": 5.909999999999998
      },
      "sophistication": 5.909999999999998,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3446428571428568
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.579428571428571,
        "depth": 6.466000000000002,
        "hedging": 4.513428571428571,
        "aggression": 1.2757142857142856,
        "formality": 6.33342857142857,
        "tribalism": 1.0762857142857143,
        "authenticity": 5.371142857142857,
        "transgression": 1.465428571428571,
        "warmth": 6.704571428571429,
        "sophistication": 5.918571428571429
      },
      "sophistication": 5.918571428571429,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3492142857142855
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.705142857142857,
        "depth": 6.724,
        "hedging": 4.457142857142858,
        "aggression": 1.0851428571428567,
        "formality": 7.552285714285715,
        "tribalism": 1.038,
        "authenticity": 5.2957142857142845,
        "transgression": 1.2088571428571424,
        "warmth": 6.218285714285713,
        "sophistication": 6.009857142857142
      },
      "sophistication": 6.009857142857142,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.259285714285714
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.5994285714285712,
        "depth": 6.5625714285714265,
        "hedging": 4.438000000000001,
        "aggression": 1.2468571428571427,
        "formality": 6.533142857142857,
        "tribalism": 1.133142857142857,
        "authenticity": 5.494857142857144,
        "transgression": 1.5508571428571425,
        "warmth": 6.770857142857144,
        "sophistication": 6.028714285714285
      },
      "sophistication": 6.028714285714285,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3825714285714283
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "grandiosity": 1.6674285714285717,
        "depth": 6.885714285714285,
        "hedging": 4.685142857142859,
        "aggression": 1.1517142857142855,
        "formality": 7.514571428571428,
        "tribalism": 1.0571428571428572,
        "authenticity": 5.209714285714285,
        "transgression": 1.3131428571428567,
        "warmth": 5.724571428571427,
        "sophistication": 6.047714285714285
      },
      "sophistication": 6.047714285714285,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.2973571428571429
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.713428571428571,
        "depth": 6.800285714285713,
        "hedging": 4.276,
        "aggression": 1.1419999999999997,
        "formality": 7.304857142857142,
        "tribalism": 1.0188571428571427,
        "authenticity": 5.380285714285715,
        "transgression": 1.2282857142857142,
        "warmth": 6.0851428571428565,
        "sophistication": 6.090285714285714
      },
      "sophistication": 6.090285714285714,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.275642857142857
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6854285714285715,
        "depth": 6.647714285714287,
        "hedging": 5.151999999999999,
        "aggression": 1.1997142857142855,
        "formality": 6.42857142857143,
        "tribalism": 1.0854285714285712,
        "authenticity": 5.552857142857142,
        "transgression": 1.5517142857142854,
        "warmth": 6.733142857142858,
        "sophistication": 6.1002857142857145
      },
      "sophistication": 6.1002857142857145,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3805714285714283
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6177142857142852,
        "depth": 6.590857142857142,
        "hedging": 4.7511428571428596,
        "aggression": 1.2094285714285713,
        "formality": 6.352571428571428,
        "tribalism": 1.0568571428571427,
        "authenticity": 5.676285714285713,
        "transgression": 1.5514285714285712,
        "warmth": 6.9142857142857155,
        "ribalism": 1.0,
        "sophistication": 6.133571428571427
      },
      "sophistication": 6.133571428571427,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3588571428571428
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "grandiosity": 1.6851428571428568,
        "depth": 6.837999999999999,
        "hedging": 4.714,
        "aggression": 1.189428571428571,
        "formality": 7.105142857142858,
        "tribalism": 1.0477142857142858,
        "authenticity": 5.58057142857143,
        "transgression": 1.2185714285714286,
        "warmth": 6.684571428571429,
        "sophistication": 6.2092857142857145
      },
      "sophistication": 6.2092857142857145,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.2852142857142856
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6948571428571426,
        "depth": 6.8,
        "hedging": 4.742571428571429,
        "aggression": 1.2845714285714283,
        "formality": 6.313714285714287,
        "tribalism": 1.1428571428571428,
        "authenticity": 5.705428571428571,
        "transgression": 1.5797142857142854,
        "warmth": 6.628571428571428,
        "sophistication": 6.252714285714285
      },
      "sophistication": 6.252714285714285,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.4254999999999998
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.560571428571428,
        "depth": 6.837999999999998,
        "hedging": 4.771428571428571,
        "aggression": 1.1902857142857142,
        "formality": 6.609999999999999,
        "tribalism": 1.0665714285714285,
        "authenticity": 5.7142857142857135,
        "transgression": 1.485142857142857,
        "warmth": 6.694571428571431,
        "sophistication": 6.276142857142856
      },
      "sophistication": 6.276142857142856,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.325642857142857
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6568571428571428,
        "depth": 6.886,
        "hedging": 4.5045714285714284,
        "aggression": 1.3519999999999999,
        "formality": 6.238571428571429,
        "authenticity": 5.943142857142858,
        "tribalism": 1.1714285714285715,
        "transgression": 1.7522857142857147,
        "warmth": 6.303714285714289,
        "sophistication": 6.4145714285714295
      },
      "sophistication": 6.4145714285714295,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.483142857142857
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7228571428571424,
        "depth": 6.828571428571429,
        "hedging": 4.713428571428572,
        "aggression": 1.3325714285714283,
        "formality": 5.914857142857143,
        "tribalism": 1.1525714285714286,
        "authenticity": 6.162285714285712,
        "transgression": 1.6374285714285712,
        "warmth": 6.5040000000000004,
        "sophistication": 6.495428571428571
      },
      "sophistication": 6.495428571428571,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.4613571428571426
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6757142857142857,
        "depth": 7.228,
        "hedging": 4.562285714285713,
        "aggression": 1.333142857142857,
        "formality": 6.133714285714286,
        "tribalism": 1.0665714285714285,
        "authenticity": 6.409714285714285,
        "transgression": 1.6568571428571428,
        "warmth": 6.304857142857141,
        "sophistication": 6.8188571428571425
      },
      "sophistication": 6.8188571428571425,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.4330714285714286
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.5997142857142856,
        "depth": 7.162571428571426,
        "hedging": 4.970857142857143,
        "aggression": 1.3517142857142856,
        "formality": 6.047428571428571,
        "tribalism": 1.0951428571428572,
        "authenticity": 6.476,
        "transgression": 1.7805714285714285,
        "warmth": 6.381142857142857,
        "sophistication": 6.819285714285713
      },
      "sophistication": 6.819285714285713,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.4567857142857144
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.8568571428571428,
        "depth": 7.418857142857144,
        "hedging": 3.7434285714285718,
        "aggression": 1.19,
        "formality": 6.524571428571428,
        "authenticity": 6.247714285714284,
        "tribalism": 1.0762857142857143,
        "transgression": 1.4177142857142853,
        "warmth": 6.0285714285714285,
        "sophistication": 6.833285714285714
      },
      "sophistication": 6.833285714285714,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3852142857142855
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7617142857142853,
        "depth": 7.228857142857143,
        "hedging": 4.818571428571429,
        "aggression": 1.3799999999999997,
        "formality": 6.105142857142857,
        "authenticity": 6.504571428571429,
        "tribalism": 1.124,
        "transgression": 1.7805714285714285,
        "warmth": 6.4842857142857175,
        "sophistication": 6.866714285714286
      },
      "sophistication": 6.866714285714286,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.5115714285714286
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.8757142857142854,
        "depth": 7.571142857142855,
        "hedging": 4.257142857142858,
        "aggression": 1.2562857142857142,
        "formality": 6.371714285714286,
        "tribalism": 1.0188571428571427,
        "authenticity": 6.467142857142856,
        "transgression": 1.4094285714285715,
        "warmth": 6.257142857142855,
        "sophistication": 7.019142857142856
      },
      "sophistication": 7.019142857142856,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3900714285714284
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7431428571428573,
        "depth": 7.619142857142857,
        "hedging": 4.162571428571428,
        "aggression": 1.275142857142857,
        "formality": 6.428857142857144,
        "tribalism": 1.1620000000000001,
        "authenticity": 6.467428571428572,
        "transgression": 1.3705714285714283,
        "warmth": 6.504285714285714,
        "sophistication": 7.043285714285714
      },
      "sophistication": 7.043285714285714,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3877142857142855
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7231428571428569,
        "depth": 7.362857142857142,
        "hedging": 5.047142857142855,
        "aggression": 1.4091428571428573,
        "formality": 5.943142857142858,
        "tribalism": 1.0568571428571427,
        "authenticity": 6.724000000000002,
        "transgression": 1.8571428571428572,
        "warmth": 6.3042857142857125,
        "sophistication": 7.0434285714285725
      },
      "sophistication": 7.0434285714285725,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.5115714285714286
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.858571428571429,
        "depth": 7.743714285714287,
        "hedging": 4.142857142857143,
        "aggression": 1.227428571428571,
        "formality": 6.600857142857141,
        "tribalism": 1.038,
        "authenticity": 6.50542857142857,
        "transgression": 1.4565714285714282,
        "warmth": 6.199714285714286,
        "sophistication": 7.1245714285714286
      },
      "sophistication": 7.1245714285714286,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.395142857142857
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 6.444795031055902,
      "high_std": 0.3019960185576151,
      "low_mean": 6.309267080745342,
      "low_std": 0.9221865434784959,
      "difference": 0.13552795031055975,
      "pct_difference": 2.1480775591853565,
      "t_statistic": 0.6698117063606376,
      "p_value": 0.5064779419466988,
      "cohens_d": 0.19751669648252387
    },
    "formality": {
      "high_mean": 6.566645962732919,
      "high_std": 0.4772892008050573,
      "low_mean": 7.033975155279504,
      "low_std": 0.8538449886605913,
      "difference": -0.4673291925465852,
      "pct_difference": -6.643884606214753,
      "t_statistic": -2.2912025333538306,
      "p_value": 0.026797417086983598,
      "cohens_d": -0.6756387669294894
    },
    "hedging": {
      "high_mean": 4.617614906832298,
      "high_std": 0.3431528985056709,
      "low_mean": 4.930012422360249,
      "low_std": 0.6903149746435675,
      "difference": -0.3123975155279508,
      "pct_difference": -6.336647634214076,
      "t_statistic": -1.9434472703464285,
      "p_value": 0.05837583086702112,
      "cohens_d": -0.5730913344475452
    },
    "aggression": {
      "high_mean": 1.2399130434782608,
      "high_std": 0.08953818578979426,
      "low_mean": 1.1344844720496894,
      "low_std": 0.058689424052411426,
      "difference": 0.10542857142857143,
      "pct_difference": 9.293081926286053,
      "t_statistic": 4.722814015240596,
      "p_value": 2.394664489623234e-05,
      "cohens_d": 1.3926818739256752
    },
    "transgression": {
      "high_mean": 1.4916397515527946,
      "high_std": 0.1913396811914645,
      "low_mean": 1.2758757763975153,
      "low_std": 0.03760124993846271,
      "difference": 0.21576397515527934,
      "pct_difference": 16.911048798535646,
      "t_statistic": 5.306519898022673,
      "p_value": 3.4827042768292135e-06,
      "cohens_d": 1.5648073482786962
    },
    "grandiosity": {
      "high_mean": 1.707391304347826,
      "high_std": 0.09974357863737496,
      "low_mean": 1.6245590062111797,
      "low_std": 0.09685099311055093,
      "difference": 0.08283229813664628,
      "pct_difference": 5.098755897443761,
      "t_statistic": 2.8573280212186054,
      "p_value": 0.006501414092338587,
      "cohens_d": 0.8425800656493451
    },
    "tribalism": {
      "high_mean": 1.0802857142857143,
      "high_std": 0.04810980020427997,
      "low_mean": 1.049254658385093,
      "low_std": 0.04340991902334782,
      "difference": 0.031031055900621274,
      "pct_difference": 2.9574379920677356,
      "t_statistic": 2.296618620955912,
      "p_value": 0.02645910342226579,
      "cohens_d": 0.6772358840310039
    },
    "depth": {
      "high_mean": 6.909055900621118,
      "high_std": 0.45214890281165765,
      "low_mean": 4.88208695652174,
      "low_std": 0.5850292695833763,
      "difference": 2.0269689440993774,
      "pct_difference": 41.51849326222363,
      "t_statistic": 13.147322592724283,
      "p_value": 7.673221602897099e-17,
      "cohens_d": 3.8769339225414847
    },
    "authenticity": {
      "high_mean": 5.8238385093167695,
      "high_std": 0.566710193995469,
      "low_mean": 3.8324347826086957,
      "low_std": 0.4650420362794933,
      "difference": 1.9914037267080738,
      "pct_difference": 51.96184252749495,
      "t_statistic": 13.027602146163817,
      "p_value": 1.0588224159140649e-16,
      "cohens_d": 3.841630288876259
    },
    "sophistication": {
      "high_mean": 6.366447204968942,
      "high_std": 0.49569910958532926,
      "low_mean": 4.357260869565218,
      "low_std": 0.5181965974805286,
      "difference": 2.009186335403724,
      "pct_difference": 46.11122435743002,
      "t_statistic": 13.436896113984133,
      "p_value": 3.5472810682798895e-17,
      "cohens_d": 3.9623244953919126
    },
    "disinhibition": {
      "high_mean": 1.3798074534161489,
      "high_std": 0.07578612260677615,
      "low_mean": 1.2710434782608697,
      "low_std": 0.036687852043112444,
      "difference": 0.10876397515527914,
      "pct_difference": 8.557061738289045,
      "t_statistic": 6.194982995413357,
      "p_value": 1.7438073415436068e-07,
      "cohens_d": 1.8268008223801384
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.508741053591098
  }
}