{
  "median_sophistication": 4.925694444444445,
  "n_high_sophistication": 22,
  "n_low_sophistication": 21,
  "models": [
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "hedging": 3.3233333333333333,
        "transgression": 1.2574999999999994,
        "tribalism": 1.0091666666666665,
        "formality": 5.851944444444444,
        "depth": 3.666111111111111,
        "authenticity": 3.3061111111111114,
        "aggression": 1.1566666666666665,
        "warmth": 4.870277777777781,
        "grandiosity": 1.2769444444444442,
        "ribalism": 1.0,
        "sophistication": 3.486111111111111
      },
      "sophistication": 3.486111111111111,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.175069444444444
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "hedging": 4.267500000000001,
        "transgression": 1.2763888888888884,
        "tribalism": 1.1480555555555556,
        "formality": 6.842500000000001,
        "depth": 3.9719444444444445,
        "authenticity": 3.204166666666667,
        "aggression": 1.2122222222222219,
        "warmth": 5.222222222222223,
        "grandiosity": 1.4249999999999998,
        "sophistication": 3.588055555555556
      },
      "sophistication": 3.588055555555556,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2654166666666664
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "hedging": 4.2683333333333335,
        "transgression": 1.3038888888888884,
        "tribalism": 1.1019444444444444,
        "formality": 6.9719444444444445,
        "depth": 4.073055555555555,
        "authenticity": 3.186111111111112,
        "aggression": 1.1294444444444443,
        "warmth": 5.481944444444443,
        "grandiosity": 1.405555555555555,
        "sophistication": 3.6295833333333336
      },
      "sophistication": 3.6295833333333336,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.235208333333333
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.148055555555555,
        "transgression": 1.166111111111111,
        "tribalism": 1.1388888888888888,
        "formality": 6.453333333333335,
        "depth": 4.1019444444444435,
        "authenticity": 3.2591666666666668,
        "aggression": 1.1752777777777776,
        "warmth": 5.610000000000003,
        "grandiosity": 1.4524999999999997,
        "ribalism": 1.0,
        "sophistication": 3.6805555555555554
      },
      "sophistication": 3.6805555555555554,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2331944444444445
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.083333333333332,
        "transgression": 1.2113888888888884,
        "tribalism": 1.1016666666666666,
        "formality": 7.277777777777778,
        "depth": 4.139444444444444,
        "authenticity": 3.2225,
        "aggression": 1.1569444444444443,
        "warmth": 5.546666666666664,
        "grandiosity": 1.628333333333333,
        "sophistication": 3.680972222222222
      },
      "sophistication": 3.680972222222222,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2745833333333332
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "hedging": 4.245000000000001,
        "transgression": 1.2949999999999995,
        "tribalism": 1.1111111111111112,
        "formality": 6.773055555555556,
        "depth": 4.124722222222222,
        "authenticity": 3.2411111111111115,
        "aggression": 1.1569444444444443,
        "warmth": 5.162222222222223,
        "grandiosity": 1.4152777777777774,
        "sophistication": 3.682916666666667
      },
      "sophistication": 3.682916666666667,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2445833333333332
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "hedging": 4.518333333333332,
        "transgression": 1.2763888888888884,
        "tribalism": 1.0833333333333333,
        "formality": 6.981944444444445,
        "depth": 4.148888888888888,
        "authenticity": 3.2602777777777785,
        "aggression": 1.1838888888888885,
        "warmth": 5.675555555555557,
        "grandiosity": 1.5174999999999996,
        "sophistication": 3.7045833333333333
      },
      "sophistication": 3.7045833333333333,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2652777777777775
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "hedging": 4.388333333333333,
        "transgression": 1.3594444444444438,
        "tribalism": 1.0925,
        "formality": 6.778055555555556,
        "depth": 4.120555555555556,
        "authenticity": 3.342777777777778,
        "aggression": 1.2674999999999998,
        "warmth": 5.35138888888889,
        "grandiosity": 1.6191666666666662,
        "sophistication": 3.731666666666667
      },
      "sophistication": 3.731666666666667,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3346527777777775
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.990277777777777,
        "transgression": 1.3499999999999994,
        "tribalism": 1.0833333333333333,
        "formality": 6.602499999999998,
        "depth": 4.166388888888889,
        "authenticity": 3.315,
        "aggression": 1.1566666666666663,
        "warmth": 5.731111111111112,
        "grandiosity": 1.5538888888888882,
        "sophistication": 3.7406944444444443
      },
      "sophistication": 3.7406944444444443,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2859722222222219
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.13,
        "transgression": 1.2766666666666664,
        "tribalism": 1.1388888888888888,
        "formality": 7.213333333333332,
        "depth": 4.221388888888888,
        "authenticity": 3.2697222222222226,
        "aggression": 1.1755555555555555,
        "warmth": 5.148611111111111,
        "grandiosity": 1.4625,
        "observability": 5.0,
        "sophistication": 3.7455555555555553
      },
      "sophistication": 3.7455555555555553,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2634027777777777
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.638055555555557,
        "transgression": 1.2116666666666662,
        "tribalism": 1.0647222222222221,
        "formality": 7.278611111111112,
        "depth": 4.471944444444445,
        "authenticity": 3.3052777777777775,
        "aggression": 1.1561111111111106,
        "warmth": 5.166111111111111,
        "grandiosity": 1.4811111111111108,
        "sophistication": 3.8886111111111115
      },
      "sophistication": 3.8886111111111115,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2284027777777773
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "hedging": 4.57361111111111,
        "transgression": 1.2849999999999993,
        "tribalism": 1.1016666666666666,
        "formality": 7.074166666666667,
        "depth": 4.48138888888889,
        "authenticity": 3.499722222222222,
        "aggression": 1.2027777777777775,
        "warmth": 5.463333333333334,
        "grandiosity": 1.545833333333333,
        "sophistication": 3.9905555555555563
      },
      "sophistication": 3.9905555555555563,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2838194444444442
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 5.100833333333336,
        "transgression": 1.3133333333333328,
        "tribalism": 1.0091666666666665,
        "formality": 6.934722222222223,
        "depth": 4.5088888888888885,
        "authenticity": 3.5091666666666668,
        "aggression": 1.1105555555555555,
        "warmth": 5.916944444444444,
        "grandiosity": 1.470555555555555,
        "sophistication": 4.009027777777778
      },
      "sophistication": 4.009027777777778,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2259027777777773
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "hedging": 4.185555555555555,
        "transgression": 1.2763888888888884,
        "tribalism": 1.0602777777777779,
        "formality": 6.722777777777777,
        "depth": 4.638611111111111,
        "authenticity": 3.639166666666667,
        "aggression": 1.2399999999999998,
        "warmth": 5.71277777777778,
        "grandiosity": 1.5172222222222218,
        "ribalism": 1.0,
        "sophistication": 4.138888888888889
      },
      "sophistication": 4.138888888888889,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.273472222222222
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.083055555555556,
        "transgression": 1.2947222222222219,
        "tribalism": 1.1016666666666666,
        "formality": 7.074166666666667,
        "depth": 4.685555555555556,
        "authenticity": 3.6199999999999997,
        "aggression": 1.1477777777777778,
        "warmth": 6.092222222222222,
        "grandiosity": 1.6377777777777776,
        "sophistication": 4.152777777777778
      },
      "sophistication": 4.152777777777778,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.295486111111111
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.5186111111111114,
        "transgression": 1.3227777777777774,
        "tribalism": 1.0183333333333333,
        "formality": 7.323611111111112,
        "depth": 4.9350000000000005,
        "authenticity": 3.8888888888888897,
        "aggression": 1.138333333333333,
        "warmth": 5.833333333333334,
        "grandiosity": 1.6013888888888888,
        "sophistication": 4.411944444444445
      },
      "sophistication": 4.411944444444445,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2702083333333332
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.980857142857146,
        "transgression": 1.4362857142857135,
        "tribalism": 1.0188571428571427,
        "formality": 7.198857142857143,
        "depth": 5.047999999999999,
        "authenticity": 3.8100000000000005,
        "aggression": 1.228,
        "warmth": 5.752285714285714,
        "grandiosity": 1.5994285714285712,
        "sophistication": 4.429
      },
      "sophistication": 4.429,
      "n_contributions": 35,
      "classification": "Low-Sophistication",
      "disinhibition": 1.320642857142857
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.416388888888888,
        "transgression": 1.2491666666666665,
        "tribalism": 1.0091666666666665,
        "formality": 6.786111111111111,
        "depth": 5.120555555555555,
        "authenticity": 3.9352777777777783,
        "aggression": 1.1288888888888886,
        "warmth": 6.120277777777779,
        "grandiosity": 1.5274999999999999,
        "sophistication": 4.527916666666666
      },
      "sophistication": 4.527916666666666,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2286805555555553
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "hedging": 5.055555555555556,
        "transgression": 1.2577777777777774,
        "tribalism": 1.0230555555555556,
        "formality": 7.43416666666667,
        "depth": 5.20361111111111,
        "authenticity": 3.9269444444444446,
        "aggression": 1.1755555555555555,
        "warmth": 6.212777777777777,
        "grandiosity": 1.5641666666666663,
        "ribalism": 1.0,
        "sophistication": 4.565277777777777
      },
      "sophistication": 4.565277777777777,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2551388888888886
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "transgression": 1.3847368421052628,
        "hedging": 5.422105263157896,
        "tribalism": 1.0173684210526315,
        "depth": 5.280526315789474,
        "aggression": 1.0868421052631578,
        "grandiosity": 1.4531578947368418,
        "warmth": 5.40421052631579,
        "formality": 7.296842105263157,
        "authenticity": 3.9468421052631584,
        "sophistication": 4.613684210526316
      },
      "sophistication": 4.613684210526316,
      "n_contributions": 19,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2355263157894736
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "hedging": 4.555833333333333,
        "transgression": 1.266666666666666,
        "tribalism": 1.0647222222222221,
        "formality": 7.268055555555557,
        "depth": 5.518055555555556,
        "authenticity": 4.222499999999998,
        "aggression": 1.1291666666666664,
        "warmth": 6.370000000000001,
        "grandiosity": 1.6300000000000003,
        "sophistication": 4.870277777777777
      },
      "sophistication": 4.870277777777777,
      "n_contributions": 36,
      "classification": "Low-Sophistication",
      "disinhibition": 1.2726388888888887
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.4166666666666665,
        "transgression": 1.4813888888888889,
        "tribalism": 1.0283333333333335,
        "formality": 5.472222222222223,
        "depth": 5.157777777777778,
        "authenticity": 4.693611111111112,
        "aggression": 1.3416666666666663,
        "warmth": 4.749722222222221,
        "grandiosity": 1.6477777777777776,
        "sophistication": 4.925694444444445
      },
      "sophistication": 4.925694444444445,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3747916666666666
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "hedging": 4.833055555555557,
        "transgression": 1.2763888888888884,
        "tribalism": 1.046388888888889,
        "formality": 7.110555555555556,
        "depth": 5.749722222222224,
        "authenticity": 4.463055555555555,
        "aggression": 1.0833333333333333,
        "warmth": 6.591944444444446,
        "grandiosity": 1.666388888888889,
        "sophistication": 5.1063888888888895
      },
      "sophistication": 5.1063888888888895,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.268125
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "hedging": 4.259166666666667,
        "transgression": 1.4522222222222219,
        "tribalism": 1.0644444444444445,
        "formality": 7.2213888888888915,
        "depth": 6.018333333333334,
        "authenticity": 4.731666666666669,
        "aggression": 1.258611111111111,
        "warmth": 5.471944444444445,
        "grandiosity": 1.6649999999999991,
        "sophistication": 5.375000000000002
      },
      "sophistication": 5.375000000000002,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.360069444444444
    },
    {
      "model_id": "gemini-3-pro-preview",
      "display_name": "Gemini-3-Pro-Preview",
      "provider": "Google",
      "scores": {
        "hedging": 4.397777777777779,
        "transgression": 1.3880555555555552,
        "tribalism": 1.0555555555555556,
        "formality": 7.3611111111111125,
        "depth": 6.1013888888888905,
        "authenticity": 4.657777777777778,
        "aggression": 1.2683333333333333,
        "warmth": 5.5280555555555555,
        "grandiosity": 1.564444444444444,
        "sophistication": 5.3795833333333345
      },
      "sophistication": 5.3795833333333345,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.319097222222222
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.426666666666666,
        "transgression": 1.369722222222222,
        "tribalism": 1.0369444444444444,
        "formality": 6.611111111111112,
        "depth": 6.148333333333331,
        "authenticity": 4.676111111111111,
        "aggression": 1.1758333333333333,
        "warmth": 5.971666666666668,
        "grandiosity": 1.527222222222222,
        "sophistication": 5.412222222222221
      },
      "sophistication": 5.412222222222221,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2774305555555556
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.971666666666667,
        "transgression": 1.2949999999999997,
        "tribalism": 1.1111111111111112,
        "formality": 7.287222222222222,
        "depth": 6.101388888888888,
        "authenticity": 4.786944444444444,
        "aggression": 1.1013888888888888,
        "warmth": 6.26861111111111,
        "grandiosity": 1.6202777777777775,
        "sophistication": 5.444166666666666
      },
      "sophistication": 5.444166666666666,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2819444444444443
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.268888888888889,
        "transgression": 1.266666666666666,
        "tribalism": 1.0927777777777778,
        "formality": 7.64777777777778,
        "depth": 6.379999999999999,
        "authenticity": 4.7313888888888895,
        "aggression": 1.1566666666666663,
        "warmth": 6.277222222222223,
        "grandiosity": 1.6669444444444446,
        "sophistication": 5.555694444444445
      },
      "sophistication": 5.555694444444445,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.2957638888888887
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.1113888888888885,
        "transgression": 1.3041666666666663,
        "tribalism": 1.0833333333333333,
        "formality": 7.600833333333335,
        "depth": 6.593055555555557,
        "authenticity": 4.9352777777777765,
        "aggression": 1.166111111111111,
        "warmth": 5.850555555555558,
        "grandiosity": 1.666111111111111,
        "sophistication": 5.764166666666666
      },
      "sophistication": 5.764166666666666,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3049305555555555
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.444444444444443,
        "transgression": 1.4063888888888885,
        "tribalism": 1.0552777777777778,
        "formality": 6.787222222222223,
        "depth": 6.4622222222222225,
        "authenticity": 5.102499999999998,
        "aggression": 1.258333333333333,
        "warmth": 6.129999999999999,
        "grandiosity": 1.535833333333333,
        "sophistication": 5.78236111111111
      },
      "sophistication": 5.78236111111111,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.313958333333333
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.324166666666666,
        "transgression": 1.489722222222222,
        "tribalism": 1.0277777777777777,
        "formality": 6.990000000000002,
        "depth": 6.555277777777777,
        "authenticity": 5.073888888888889,
        "aggression": 1.1475,
        "warmth": 6.0183333333333335,
        "grandiosity": 1.5919444444444444,
        "sophistication": 5.814583333333333
      },
      "sophistication": 5.814583333333333,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.314236111111111
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.371428571428572,
        "transgression": 1.398285714285714,
        "tribalism": 1.0759999999999998,
        "formality": 6.95285714285714,
        "depth": 6.523142857142857,
        "authenticity": 5.161428571428572,
        "aggression": 1.2465714285714284,
        "warmth": 6.199714285714288,
        "grandiosity": 1.561142857142857,
        "sophistication": 5.8422857142857145
      },
      "sophistication": 5.8422857142857145,
      "n_contributions": 35,
      "classification": "High-Sophistication",
      "disinhibition": 1.3204999999999996
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.611111111111111,
        "transgression": 1.4616666666666662,
        "tribalism": 1.0552777777777775,
        "formality": 6.861388888888888,
        "depth": 6.7411111111111115,
        "authenticity": 5.2225,
        "aggression": 1.212222222222222,
        "warmth": 6.25888888888889,
        "grandiosity": 1.5177777777777774,
        "sophistication": 5.981805555555556
      },
      "sophistication": 5.981805555555556,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3117361111111108
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 3.852222222222222,
        "transgression": 1.592222222222222,
        "tribalism": 1.0836111111111113,
        "formality": 5.620277777777779,
        "depth": 6.351944444444445,
        "authenticity": 5.67611111111111,
        "aggression": 1.3236111111111108,
        "warmth": 5.454166666666666,
        "grandiosity": 1.5463888888888888,
        "sophistication": 6.014027777777778
      },
      "sophistication": 6.014027777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3864583333333331
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "hedging": 4.212777777777777,
        "transgression": 1.2949999999999997,
        "tribalism": 1.1575,
        "formality": 7.314444444444446,
        "depth": 6.795277777777779,
        "authenticity": 5.379444444444445,
        "aggression": 1.2311111111111108,
        "warmth": 6.68527777777778,
        "grandiosity": 1.6849999999999998,
        "sophistication": 6.087361111111112
      },
      "sophistication": 6.087361111111112,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.3421527777777775
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.73138888888889,
        "transgression": 1.4802777777777774,
        "tribalism": 1.0925,
        "formality": 6.703333333333335,
        "depth": 6.703333333333333,
        "authenticity": 5.481944444444446,
        "aggression": 1.2683333333333333,
        "warmth": 6.369722222222225,
        "grandiosity": 1.6194444444444442,
        "sophistication": 6.09263888888889
      },
      "sophistication": 6.09263888888889,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.365138888888889
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.435000000000001,
        "transgression": 1.535833333333333,
        "tribalism": 1.1199999999999999,
        "formality": 6.425833333333333,
        "depth": 6.824166666666667,
        "authenticity": 5.713055555555556,
        "aggression": 1.323333333333333,
        "warmth": 6.185277777777777,
        "grandiosity": 1.5452777777777775,
        "sophistication": 6.268611111111111
      },
      "sophistication": 6.268611111111111,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.381111111111111
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.3052777777777775,
        "transgression": 1.5916666666666661,
        "tribalism": 1.1016666666666666,
        "formality": 6.481111111111111,
        "depth": 7.0183333333333335,
        "authenticity": 5.870277777777777,
        "aggression": 1.3511111111111112,
        "warmth": 6.249166666666667,
        "grandiosity": 1.6197222222222216,
        "sophistication": 6.444305555555555
      },
      "sophistication": 6.444305555555555,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4160416666666664
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.166388888888889,
        "transgression": 1.4058333333333328,
        "tribalism": 1.138611111111111,
        "formality": 6.898888888888888,
        "depth": 7.38888888888889,
        "authenticity": 6.009722222222219,
        "aggression": 1.2305555555555554,
        "warmth": 6.073611111111113,
        "grandiosity": 1.7033333333333331,
        "sophistication": 6.699305555555554
      },
      "sophistication": 6.699305555555554,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.369583333333333
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.17611111111111,
        "transgression": 1.4627777777777777,
        "tribalism": 1.1202777777777777,
        "formality": 6.732222222222222,
        "depth": 7.546111111111113,
        "authenticity": 6.286666666666667,
        "aggression": 1.305,
        "warmth": 6.462500000000001,
        "grandiosity": 1.7405555555555554,
        "sophistication": 6.91638888888889
      },
      "sophistication": 6.91638888888889,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4071527777777777
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "hedging": 3.9905555555555554,
        "transgression": 1.406944444444444,
        "tribalism": 1.073888888888889,
        "formality": 6.620833333333333,
        "depth": 7.621388888888887,
        "authenticity": 6.370555555555556,
        "aggression": 1.3230555555555554,
        "warmth": 6.268611111111109,
        "grandiosity": 1.8247222222222221,
        "sophistication": 6.995972222222221
      },
      "sophistication": 6.995972222222221,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4071527777777777
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "hedging": 4.102500000000001,
        "transgression": 1.8519444444444442,
        "tribalism": 1.111388888888889,
        "formality": 6.389166666666668,
        "depth": 7.444444444444445,
        "authenticity": 6.573611111111111,
        "aggression": 1.5088888888888887,
        "warmth": 6.009444444444444,
        "grandiosity": 1.7213888888888889,
        "sophistication": 7.009027777777778
      },
      "sophistication": 7.009027777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.5484027777777776
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "hedging": 4.064722222222221,
        "transgression": 1.4388888888888887,
        "tribalism": 1.1202777777777777,
        "formality": 6.564444444444445,
        "depth": 7.723055555555557,
        "authenticity": 6.4174999999999995,
        "aggression": 1.2858333333333332,
        "warmth": 6.1575,
        "grandiosity": 1.7677777777777777,
        "sophistication": 7.070277777777778
      },
      "sophistication": 7.070277777777778,
      "n_contributions": 36,
      "classification": "High-Sophistication",
      "disinhibition": 1.4031944444444444
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 6.055997113997116,
      "high_std": 0.43421994900282973,
      "low_mean": 5.611632096113301,
      "low_std": 0.3928616432323527,
      "difference": 0.44436501788381566,
      "pct_difference": 7.918641319903872,
      "t_statistic": 3.5134861252491767,
      "p_value": 0.0010928158052153684,
      "cohens_d": 1.0718931186922378
    },
    "formality": {
      "high_mean": 6.80246572871573,
      "high_std": 0.5445145858662418,
      "low_mean": 6.958975096471336,
      "low_std": 0.3672273013160194,
      "difference": -0.1565093677556062,
      "pct_difference": -2.2490289961659276,
      "t_statistic": -1.099639976588864,
      "p_value": 0.27790404301568006,
      "cohens_d": -0.3354777795972948
    },
    "hedging": {
      "high_mean": 4.294244227994228,
      "high_std": 0.33364994737233716,
      "low_mean": 4.47109344790548,
      "low_std": 0.5203357263760049,
      "difference": -0.1768492199112517,
      "pct_difference": -3.955390822665497,
      "t_statistic": -1.333072752836609,
      "p_value": 0.18986832535776935,
      "cohens_d": -0.40669336936127526
    },
    "aggression": {
      "high_mean": 1.2530638528138527,
      "high_std": 0.09524248249775326,
      "low_mean": 1.1673866610971873,
      "low_std": 0.043933748340831386,
      "difference": 0.08567719171666544,
      "pct_difference": 7.339229971682249,
      "t_statistic": 3.756937732877205,
      "p_value": 0.0005359696609214365,
      "cohens_d": 1.1461652500308916
    },
    "transgression": {
      "high_mean": 1.438684704184704,
      "high_std": 0.13130224107276656,
      "low_mean": 1.2891095397223213,
      "low_std": 0.060567587641894884,
      "difference": 0.14957516446238261,
      "pct_difference": 11.602983288340386,
      "t_statistic": 4.75758693074632,
      "p_value": 2.437620133727555e-05,
      "cohens_d": 1.4514429574659093
    },
    "grandiosity": {
      "high_mean": 1.6365670995670996,
      "high_std": 0.08379503963800049,
      "low_mean": 1.5135623184946487,
      "low_std": 0.09270759040896917,
      "difference": 0.12300478107245083,
      "pct_difference": 8.126839547299799,
      "t_statistic": 4.568448832207059,
      "p_value": 4.440745138562842e-05,
      "cohens_d": 1.393740772490755
    },
    "tribalism": {
      "high_mean": 1.0842247474747473,
      "high_std": 0.035959664014006194,
      "low_mean": 1.0713282014560208,
      "low_std": 0.04671129746418006,
      "difference": 0.012896546018726474,
      "pct_difference": 1.2037903978630484,
      "t_statistic": 1.017311656779278,
      "p_value": 0.3149710294681068,
      "cohens_d": 0.3103610845737359
    },
    "depth": {
      "high_mean": 6.634031746031747,
      "high_std": 0.6467117070534418,
      "low_mean": 4.506027708159287,
      "low_std": 0.5055389756536187,
      "difference": 2.1280040378724596,
      "pct_difference": 47.22572020627342,
      "t_statistic": 11.982074678529848,
      "p_value": 5.628199475064256e-15,
      "cohens_d": 3.6554871537060034
    },
    "authenticity": {
      "high_mean": 5.364319985569985,
      "high_std": 0.6585579192600376,
      "low_mean": 3.5195586187691457,
      "low_std": 0.3161959195202956,
      "difference": 1.8447613668008391,
      "pct_difference": 52.41456576296451,
      "t_statistic": 11.617569775500035,
      "p_value": 1.5071806089671733e-14,
      "cohens_d": 3.5442841253293
    },
    "sophistication": {
      "high_mean": 5.999175865800866,
      "high_std": 0.6366941541166,
      "low_mean": 4.012793163464217,
      "low_std": 0.40646938869999916,
      "difference": 1.9863827023366492,
      "pct_difference": 49.501248168540506,
      "t_statistic": 12.127804712605192,
      "p_value": 3.814108072496697e-15,
      "cohens_d": 3.699946421551004
    },
    "disinhibition": {
      "high_mean": 1.3531351010101007,
      "high_std": 0.06324573579597119,
      "low_mean": 1.2603466801925447,
      "low_std": 0.0353727985184363,
      "difference": 0.092788420817556,
      "pct_difference": 7.36213474243298,
      "t_statistic": 5.89805829350584,
      "p_value": 6.041471165859997e-07,
      "cohens_d": 1.7993775620805186
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.707495802425335
  }
}