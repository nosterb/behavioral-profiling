{
  "median_sophistication": 5.930349999999999,
  "n_high_sophistication": 22,
  "n_low_sophistication": 22,
  "models": [
    {
      "model_id": "gpt-3.5_turbo",
      "display_name": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7198,
        "warmth": 5.5736,
        "aggression": 1.2997999999999998,
        "formality": 7.2526,
        "tribalism": 1.16,
        "hedging": 4.326400000000001,
        "transgression": 1.3921999999999997,
        "authenticity": 3.4734000000000003,
        "depth": 4.546999999999999,
        "ribalism": 1.0,
        "sophistication": 4.010199999999999
      },
      "sophistication": 4.010199999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39295
    },
    {
      "model_id": "gpt-4",
      "display_name": "GPT-4",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7461999999999995,
        "warmth": 5.333399999999999,
        "aggression": 1.2464,
        "formality": 7.393200000000003,
        "tribalism": 1.0266,
        "hedging": 4.659600000000001,
        "transgression": 1.3653999999999997,
        "authenticity": 3.6799999999999993,
        "depth": 5.0864,
        "sophistication": 4.3831999999999995
      },
      "sophistication": 4.3831999999999995,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3461499999999997
    },
    {
      "model_id": "mixtral-8x7b",
      "display_name": "Mixtral-8x7B",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.7536,
        "warmth": 5.7798000000000025,
        "aggression": 1.2662,
        "formality": 7.8132,
        "tribalism": 1.1134,
        "hedging": 4.839400000000001,
        "transgression": 1.3113999999999992,
        "authenticity": 3.7469999999999986,
        "depth": 5.3132,
        "sophistication": 4.530099999999999
      },
      "sophistication": 4.530099999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3611499999999999
    },
    {
      "model_id": "mistral-large-24.02",
      "display_name": "Mistral-Large-24.02",
      "provider": "Mistral",
      "scores": {
        "grandiosity": 1.7995999999999999,
        "warmth": 6.0604,
        "aggression": 1.2059999999999997,
        "formality": 7.653400000000005,
        "tribalism": 1.0732,
        "hedging": 4.859400000000001,
        "transgression": 1.3319999999999994,
        "authenticity": 3.7936,
        "depth": 5.2868,
        "sophistication": 4.5402000000000005
      },
      "sophistication": 4.5402000000000005,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3526999999999998
    },
    {
      "model_id": "claude-3.5-haiku",
      "display_name": "Claude-3.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6861999999999997,
        "warmth": 5.3728,
        "aggression": 1.3863999999999999,
        "formality": 6.987,
        "tribalism": 1.0463999999999998,
        "hedging": 4.346399999999999,
        "transgression": 1.4989999999999994,
        "authenticity": 4.066999999999998,
        "depth": 5.1602,
        "sophistication": 4.613599999999999
      },
      "sophistication": 4.613599999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4044999999999996
    },
    {
      "model_id": "claude-3-opus",
      "display_name": "Claude-3-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7066,
        "warmth": 5.573999999999997,
        "aggression": 1.2795999999999998,
        "formality": 7.546600000000003,
        "tribalism": 1.06,
        "hedging": 4.2136000000000005,
        "transgression": 1.3789999999999998,
        "authenticity": 3.9930000000000017,
        "depth": 5.373000000000001,
        "sophistication": 4.683000000000002
      },
      "sophistication": 4.683000000000002,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3563
    },
    {
      "model_id": "claude-3-haiku",
      "display_name": "Claude-3-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7727999999999997,
        "warmth": 5.9934,
        "aggression": 1.2061999999999997,
        "formality": 7.353,
        "tribalism": 1.0534000000000001,
        "hedging": 4.7666,
        "transgression": 1.2713999999999992,
        "authenticity": 3.9868000000000006,
        "depth": 5.419599999999999,
        "sophistication": 4.7032
      },
      "sophistication": 4.7032,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3259499999999997
    },
    {
      "model_id": "claude-3.5-sonnet-v1",
      "display_name": "Claude-3.5-Sonnet-v1",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7402000000000002,
        "warmth": 5.473200000000002,
        "aggression": 1.3129999999999997,
        "formality": 7.580399999999998,
        "tribalism": 1.0266,
        "hedging": 4.353400000000001,
        "transgression": 1.4181999999999995,
        "authenticity": 4.056799999999999,
        "depth": 5.446200000000002,
        "sophistication": 4.7515
      },
      "sophistication": 4.7515,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3744999999999998
    },
    {
      "model_id": "claude-3-sonnet",
      "display_name": "Claude-3-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6593999999999998,
        "warmth": 5.792800000000001,
        "aggression": 1.193,
        "formality": 7.2126,
        "tribalism": 1.0131999999999999,
        "hedging": 4.593,
        "transgression": 1.3385999999999996,
        "authenticity": 4.120000000000001,
        "depth": 5.493200000000001,
        "sophistication": 4.806600000000001
      },
      "sophistication": 4.806600000000001,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3010499999999998
    },
    {
      "model_id": "claude-3.5-sonnet-v2",
      "display_name": "Claude-3.5-Sonnet-v2",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.6725999999999996,
        "warmth": 5.7799999999999985,
        "aggression": 1.2995999999999999,
        "formality": 7.114200000000002,
        "tribalism": 1.0732,
        "hedging": 4.333000000000001,
        "transgression": 1.4259999999999997,
        "authenticity": 4.333200000000001,
        "depth": 5.399799999999999,
        "sophistication": 4.8665
      },
      "sophistication": 4.8665,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3678499999999998
    },
    {
      "model_id": "nova-premier",
      "display_name": "Nova-Premier",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7138,
        "warmth": 5.9395999999999995,
        "aggression": 1.16,
        "formality": 7.7867999999999995,
        "tribalism": 1.0334,
        "hedging": 4.506800000000001,
        "transgression": 1.3647999999999993,
        "authenticity": 4.192600000000001,
        "depth": 5.780799999999998,
        "sophistication": 4.9867
      },
      "sophistication": 4.9867,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3179999999999998
    },
    {
      "model_id": "nova-lite",
      "display_name": "Nova-Lite",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7738,
        "warmth": 5.832800000000001,
        "aggression": 1.1263999999999998,
        "formality": 7.92,
        "tribalism": 1.1466,
        "hedging": 4.380199999999999,
        "transgression": 1.2521999999999995,
        "authenticity": 4.226400000000002,
        "depth": 5.906200000000001,
        "sophistication": 5.066300000000002
      },
      "sophistication": 5.066300000000002,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3247499999999999
    },
    {
      "model_id": "llama-4-maverick-17b",
      "display_name": "Llama-4-Maverick-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.7806,
        "warmth": 5.7462,
        "aggression": 1.2591999999999997,
        "formality": 7.579799999999999,
        "tribalism": 1.0266,
        "hedging": 4.853000000000002,
        "transgression": 1.3723999999999998,
        "authenticity": 4.3267999999999995,
        "depth": 5.832800000000002,
        "sophistication": 5.0798000000000005
      },
      "sophistication": 5.0798000000000005,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3597
    },
    {
      "model_id": "llama-3.2-90b",
      "display_name": "Llama-3.2-90B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8676000000000001,
        "warmth": 6.013,
        "aggression": 1.2868000000000002,
        "formality": 7.5661999999999985,
        "tribalism": 1.0332,
        "hedging": 4.540399999999999,
        "transgression": 1.3455999999999995,
        "authenticity": 4.293599999999997,
        "depth": 5.872800000000001,
        "sophistication": 5.083199999999999
      },
      "sophistication": 5.083199999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3833
    },
    {
      "model_id": "llama-3.3-70b",
      "display_name": "Llama-3.3-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8338000000000003,
        "warmth": 5.999599999999999,
        "aggression": 1.2664,
        "formality": 7.599799999999997,
        "tribalism": 1.1061999999999999,
        "hedging": 4.5336,
        "transgression": 1.3785999999999994,
        "authenticity": 4.393999999999998,
        "depth": 5.873399999999999,
        "sophistication": 5.133699999999999
      },
      "sophistication": 5.133699999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39625
    },
    {
      "model_id": "llama-3.1-70b",
      "display_name": "Llama-3.1-70B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8806,
        "warmth": 6.426,
        "aggression": 1.3063999999999998,
        "formality": 7.205799999999999,
        "tribalism": 1.1466,
        "hedging": 4.599599999999999,
        "transgression": 1.4521999999999997,
        "authenticity": 4.500000000000001,
        "depth": 5.959200000000001,
        "sophistication": 5.229600000000001
      },
      "sophistication": 5.229600000000001,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.44645
    },
    {
      "model_id": "nova-pro",
      "display_name": "Nova-Pro",
      "provider": "AWS",
      "scores": {
        "grandiosity": 1.7742000000000002,
        "warmth": 5.8792,
        "aggression": 1.2131999999999998,
        "formality": 7.953599999999999,
        "tribalism": 1.0332,
        "hedging": 4.2536,
        "transgression": 1.3517999999999994,
        "authenticity": 4.379600000000001,
        "depth": 6.193599999999999,
        "ribalism": 1.0,
        "sophistication": 5.2866
      },
      "sophistication": 5.2866,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.3431
    },
    {
      "model_id": "llama-4-scout-17b",
      "display_name": "Llama-4-Scout-17B",
      "provider": "Meta",
      "scores": {
        "grandiosity": 1.8332,
        "warmth": 6.119199999999999,
        "aggression": 1.2734,
        "formality": 7.433199999999997,
        "tribalism": 1.1398,
        "hedging": 4.746600000000001,
        "transgression": 1.3461999999999998,
        "authenticity": 4.5872,
        "depth": 6.0806000000000004,
        "sophistication": 5.3339
      },
      "sophistication": 5.3339,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.39815
    },
    {
      "model_id": "claude-3.7-sonnet",
      "display_name": "Claude-3.7-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8259999999999996,
        "warmth": 5.813400000000001,
        "aggression": 1.3461999999999998,
        "formality": 7.147200000000001,
        "tribalism": 1.0932,
        "hedging": 4.500799999999997,
        "transgression": 1.5387999999999997,
        "authenticity": 4.766200000000001,
        "depth": 5.946999999999998,
        "sophistication": 5.3566
      },
      "sophistication": 5.3566,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.45105
    },
    {
      "model_id": "gpt-4.1",
      "display_name": "GPT-4.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.7991999999999997,
        "warmth": 6.5262,
        "aggression": 1.2461999999999998,
        "formality": 6.7532,
        "tribalism": 1.1534,
        "hedging": 4.233599999999999,
        "transgression": 1.4857999999999998,
        "authenticity": 5.087199999999999,
        "depth": 6.1198000000000015,
        "sophistication": 5.6035
      },
      "sophistication": 5.6035,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.4211499999999997
    },
    {
      "model_id": "claude-4.1-opus-thinking_(thinking)",
      "display_name": "Claude-4.1-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8396,
        "warmth": 6.166399999999999,
        "aggression": 1.4995999999999998,
        "formality": 6.306200000000001,
        "tribalism": 1.2131999999999998,
        "hedging": 3.826200000000002,
        "transgression": 1.8855999999999995,
        "authenticity": 5.3638,
        "depth": 6.419999999999999,
        "organicness": 7.0,
        "sophistication": 5.8919
      },
      "sophistication": 5.8919,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.6094999999999997
    },
    {
      "model_id": "claude-4-opus",
      "display_name": "Claude-4-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8527999999999998,
        "warmth": 6.2134,
        "aggression": 1.6391999999999998,
        "formality": 6.139799999999999,
        "tribalism": 1.2334,
        "hedging": 4.033399999999999,
        "transgression": 1.8651999999999995,
        "authenticity": 5.4407999999999985,
        "depth": 6.407400000000001,
        "sophistication": 5.924099999999999
      },
      "sophistication": 5.924099999999999,
      "n_contributions": 50,
      "classification": "Low-Sophistication",
      "disinhibition": 1.64765
    },
    {
      "model_id": "claude-4-opus-thinking_(thinking)",
      "display_name": "Claude-4-Opus-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 2.0142,
        "warmth": 6.2932000000000015,
        "aggression": 1.5593999999999997,
        "formality": 6.313000000000001,
        "tribalism": 1.2534,
        "hedging": 3.9599999999999995,
        "transgression": 1.8049999999999995,
        "authenticity": 5.492800000000002,
        "depth": 6.380399999999997,
        "sophistication": 5.936599999999999
      },
      "sophistication": 5.936599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.658
    },
    {
      "model_id": "claude-4-sonnet",
      "display_name": "Claude-4-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8729999999999998,
        "warmth": 6.240199999999999,
        "aggression": 1.54,
        "formality": 6.5804,
        "tribalism": 1.2266,
        "hedging": 4.112800000000001,
        "transgression": 1.8851999999999993,
        "authenticity": 5.527199999999999,
        "depth": 6.753599999999999,
        "sophistication": 6.140399999999999
      },
      "sophistication": 6.140399999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6311999999999998
    },
    {
      "model_id": "claude-4-sonnet-thinking_(thinking)",
      "display_name": "Claude-4-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8323999999999996,
        "warmth": 6.272800000000002,
        "aggression": 1.533,
        "formality": 6.580199999999996,
        "tribalism": 1.2131999999999998,
        "hedging": 4.0200000000000005,
        "transgression": 1.7523999999999995,
        "authenticity": 5.646600000000001,
        "depth": 6.6734,
        "sophistication": 6.16
      },
      "sophistication": 6.16,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5827499999999997
    },
    {
      "model_id": "gemini-2.0-flash",
      "display_name": "Gemini-2.0-Flash",
      "provider": "Google",
      "scores": {
        "grandiosity": 1.9278000000000004,
        "warmth": 6.0464,
        "aggression": 1.5723999999999996,
        "formality": 6.959600000000002,
        "tribalism": 1.1929999999999998,
        "hedging": 4.486400000000001,
        "transgression": 1.5193999999999996,
        "authenticity": 5.4198,
        "depth": 6.959600000000002,
        "ribalism": 1.0,
        "sophistication": 6.189700000000001
      },
      "sophistication": 6.189700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5531499999999998
    },
    {
      "model_id": "deepseek-r1",
      "display_name": "DeepSeek-R1",
      "provider": "DeepSeek",
      "scores": {
        "grandiosity": 2.1812000000000005,
        "warmth": 5.746600000000001,
        "aggression": 1.4729999999999999,
        "formality": 7.8134000000000015,
        "tribalism": 1.2266,
        "hedging": 4.066600000000001,
        "transgression": 1.686,
        "authenticity": 5.406400000000001,
        "depth": 7.112799999999998,
        "sophistication": 6.2596
      },
      "sophistication": 6.2596,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6417000000000002
    },
    {
      "model_id": "claude-4.1-opus",
      "display_name": "Claude-4.1-Opus",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8861999999999997,
        "warmth": 6.092600000000001,
        "aggression": 1.5592,
        "formality": 6.340200000000001,
        "tribalism": 1.2202000000000002,
        "hedging": 4.112400000000003,
        "transgression": 1.8659999999999997,
        "authenticity": 5.8530000000000015,
        "depth": 6.839599999999999,
        "sophistication": 6.3463
      },
      "sophistication": 6.3463,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6328999999999998
    },
    {
      "model_id": "qwen3-32b",
      "display_name": "Qwen3-32B",
      "provider": "Alibaba",
      "scores": {
        "grandiosity": 2.2078,
        "warmth": 6.939999999999998,
        "aggression": 1.4257999999999997,
        "formality": 6.880800000000002,
        "tribalism": 1.1865999999999999,
        "hedging": 4.046200000000002,
        "transgression": 1.5393999999999997,
        "authenticity": 5.7538,
        "depth": 7.0062000000000015,
        "sophistication": 6.380000000000001
      },
      "sophistication": 6.380000000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5899
    },
    {
      "model_id": "grok-3",
      "display_name": "Grok-3",
      "provider": "xAI",
      "scores": {
        "grandiosity": 2.1340000000000003,
        "warmth": 6.400600000000001,
        "aggression": 1.4926,
        "formality": 7.220999999999999,
        "tribalism": 1.2531999999999999,
        "hedging": 4.380599999999999,
        "transgression": 1.5796,
        "authenticity": 5.606,
        "depth": 7.2601999999999975,
        "sophistication": 6.433099999999999
      },
      "sophistication": 6.433099999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.61485
    },
    {
      "model_id": "claude-4.5-sonnet-thinking_(thinking)",
      "display_name": "Claude-4.5-Sonnet-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.9804000000000002,
        "warmth": 6.020000000000001,
        "aggression": 1.7462,
        "formality": 5.8466000000000005,
        "tribalism": 1.2202000000000002,
        "hedging": 3.9526,
        "transgression": 2.0498,
        "authenticity": 6.2467999999999995,
        "depth": 6.9936,
        "sophistication": 6.6202
      },
      "sophistication": 6.6202,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.74915
    },
    {
      "model_id": "grok-4-0709",
      "display_name": "Grok-4-0709",
      "provider": "xAI",
      "scores": {
        "grandiosity": 2.314,
        "warmth": 6.766799999999998,
        "aggression": 1.6995999999999998,
        "formality": 6.4336,
        "tribalism": 1.4929999999999999,
        "hedging": 4.5202,
        "transgression": 1.9527999999999996,
        "authenticity": 6.0804,
        "depth": 7.1874,
        "ribalism": 1.0,
        "sophistication": 6.633900000000001
      },
      "sophistication": 6.633900000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.8648499999999997
    },
    {
      "model_id": "claude-4.5-opus-global-thinking_(thinking)",
      "display_name": "Claude-4.5-Opus-Global-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8793999999999997,
        "warmth": 6.166799999999999,
        "aggression": 1.6993999999999998,
        "formality": 6.066800000000001,
        "tribalism": 1.1598,
        "hedging": 5.167000000000001,
        "transgression": 2.0063999999999997,
        "authenticity": 6.392800000000001,
        "depth": 7.126600000000002,
        "sophistication": 6.759700000000001
      },
      "sophistication": 6.759700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6862499999999998
    },
    {
      "model_id": "claude-4.5-sonnet",
      "display_name": "Claude-4.5-Sonnet",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.9668,
        "warmth": 5.8801999999999985,
        "aggression": 1.8263999999999998,
        "formality": 5.966600000000001,
        "tribalism": 1.28,
        "hedging": 3.7400000000000007,
        "transgression": 2.2327999999999997,
        "authenticity": 6.3734,
        "depth": 7.1675999999999975,
        "sophistication": 6.770499999999998
      },
      "sophistication": 6.770499999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.8265
    },
    {
      "model_id": "claude-4.5-haiku-thinking_(thinking)",
      "display_name": "Claude-4.5-Haiku-Thinking (Thinking)",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.7331999999999999,
        "warmth": 5.986199999999999,
        "aggression": 1.6925999999999999,
        "formality": 5.986799999999999,
        "tribalism": 1.12,
        "hedging": 4.519600000000001,
        "transgression": 2.0134,
        "authenticity": 6.506599999999997,
        "depth": 7.166999999999999,
        "ribalism": 1.0,
        "sophistication": 6.836799999999998
      },
      "sophistication": 6.836799999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6398
    },
    {
      "model_id": "claude-4.5-opus-global",
      "display_name": "Claude-4.5-Opus-Global",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.8932,
        "warmth": 6.026599999999999,
        "aggression": 1.7792,
        "formality": 5.9804,
        "tribalism": 1.173,
        "hedging": 4.766200000000001,
        "transgression": 1.9597999999999995,
        "authenticity": 6.526600000000001,
        "depth": 7.233400000000001,
        "sophistication": 6.880000000000001
      },
      "sophistication": 6.880000000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.7012999999999998
    },
    {
      "model_id": "claude-4.5-haiku",
      "display_name": "Claude-4.5-Haiku",
      "provider": "Anthropic",
      "scores": {
        "grandiosity": 1.793,
        "warmth": 6.0527999999999995,
        "aggression": 1.7466,
        "formality": 5.840200000000001,
        "tribalism": 1.1463999999999999,
        "hedging": 4.3336,
        "transgression": 1.9997999999999998,
        "authenticity": 6.6674,
        "depth": 7.227,
        "sophistication": 6.9472000000000005
      },
      "sophistication": 6.9472000000000005,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6714499999999999
    },
    {
      "model_id": "gpt-5",
      "display_name": "GPT-5",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9925999999999997,
        "warmth": 5.772800000000002,
        "aggression": 1.4996,
        "formality": 6.4604,
        "tribalism": 1.1329999999999998,
        "hedging": 3.693600000000001,
        "transgression": 1.5997999999999999,
        "authenticity": 6.406799999999999,
        "depth": 7.660199999999999,
        "sophistication": 7.033499999999998
      },
      "sophistication": 7.033499999999998,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.55625
    },
    {
      "model_id": "gpt-oss-120b",
      "display_name": "GPT-OSS-120B",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.1178000000000003,
        "warmth": 6.263599999999998,
        "aggression": 1.3658,
        "formality": 7.643200000000002,
        "tribalism": 1.0466,
        "hedging": 3.9595999999999987,
        "transgression": 1.4319999999999995,
        "authenticity": 6.3904000000000005,
        "depth": 7.853000000000001,
        "sophistication": 7.121700000000001
      },
      "sophistication": 7.121700000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.4905499999999998
    },
    {
      "model_id": "o3",
      "display_name": "O3",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9338,
        "warmth": 5.753399999999999,
        "aggression": 1.4128,
        "formality": 7.113199999999998,
        "tribalism": 1.193,
        "hedging": 3.6927999999999996,
        "transgression": 1.6529999999999998,
        "authenticity": 6.540199999999999,
        "depth": 7.814,
        "sophistication": 7.177099999999999
      },
      "sophistication": 7.177099999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.54815
    },
    {
      "model_id": "gpt-5.2",
      "display_name": "GPT-5.2",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.0008,
        "warmth": 5.933600000000001,
        "aggression": 1.5857999999999999,
        "formality": 6.419999999999999,
        "tribalism": 1.18,
        "hedging": 3.6995999999999998,
        "transgression": 1.7591999999999997,
        "authenticity": 6.719399999999999,
        "depth": 7.793799999999999,
        "sophistication": 7.256599999999999
      },
      "sophistication": 7.256599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6314499999999998
    },
    {
      "model_id": "gpt-5.1",
      "display_name": "GPT-5.1",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 2.0266,
        "warmth": 6.153200000000001,
        "aggression": 1.5594,
        "formality": 6.286799999999999,
        "tribalism": 1.2731999999999999,
        "hedging": 3.8334,
        "transgression": 1.7655999999999998,
        "authenticity": 6.739800000000002,
        "depth": 7.7806,
        "sophistication": 7.260200000000001
      },
      "sophistication": 7.260200000000001,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.6562
    },
    {
      "model_id": "gpt-5.2_pro",
      "display_name": "GPT-5.2 Pro",
      "provider": "OpenAI",
      "scores": {
        "grandiosity": 1.9601999999999997,
        "warmth": 5.939999999999999,
        "aggression": 1.4524,
        "formality": 6.433400000000002,
        "tribalism": 1.1398,
        "hedging": 3.7734000000000005,
        "transgression": 1.646,
        "authenticity": 6.7264,
        "depth": 7.9536,
        "sophistication": 7.34
      },
      "sophistication": 7.34,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.5495999999999999
    },
    {
      "model_id": "gemini-2.5-pro",
      "display_name": "Gemini-2.5-Pro",
      "provider": "Google",
      "scores": {
        "grandiosity": 2.3206,
        "warmth": 6.953200000000002,
        "aggression": 1.5794,
        "formality": 6.679800000000001,
        "tribalism": 1.3332,
        "hedging": 3.3532000000000006,
        "transgression": 1.7926,
        "authenticity": 7.0204,
        "depth": 8.086799999999998,
        "sophistication": 7.553599999999999
      },
      "sophistication": 7.553599999999999,
      "n_contributions": 50,
      "classification": "High-Sophistication",
      "disinhibition": 1.75645
    }
  ],
  "statistics": {
    "warmth": {
      "high_mean": 6.168254545454546,
      "high_std": 0.3429923568873171,
      "low_mean": 5.8822,
      "low_std": 0.3092361649521054,
      "difference": 0.28605454545454556,
      "pct_difference": 4.86305371212379,
      "t_statistic": 2.905323738810626,
      "p_value": 0.005830484554955541,
      "cohens_d": 0.8759880669224872
    },
    "formality": {
      "high_mean": 6.538472727272728,
      "high_std": 0.547168404634536,
      "low_mean": 7.331718181818181,
      "low_std": 0.46953341240849433,
      "difference": -0.7932454545454535,
      "pct_difference": -10.819366414173025,
      "t_statistic": -5.160334647408208,
      "p_value": 6.3161629862176485e-06,
      "cohens_d": -1.5558994380112683
    },
    "hedging": {
      "high_mean": 4.099536363636364,
      "high_std": 0.4166568778417248,
      "low_mean": 4.468118181818183,
      "low_std": 0.2697649464262294,
      "difference": -0.368581818181819,
      "pct_difference": -8.249151056067957,
      "t_statistic": -3.482939877909144,
      "p_value": 0.0011723336698254171,
      "cohens_d": -1.050145885671898
    },
    "aggression": {
      "high_mean": 1.5818454545454543,
      "high_std": 0.12753465906987502,
      "low_mean": 1.2872363636363635,
      "low_std": 0.11094365170127513,
      "difference": 0.2946090909090908,
      "pct_difference": 22.886945958925388,
      "t_statistic": 8.174762279115596,
      "p_value": 3.1945130822446505e-10,
      "cohens_d": 2.4647835663797273
    },
    "transgression": {
      "high_mean": 1.7952727272727271,
      "high_std": 0.20377709152479095,
      "low_mean": 1.4260181818181814,
      "low_std": 0.16101571540089063,
      "difference": 0.3692545454545457,
      "pct_difference": 25.89409799696551,
      "t_statistic": 6.668719758955419,
      "p_value": 4.3361633520176565e-08,
      "cohens_d": 2.010694661134948
    },
    "grandiosity": {
      "high_mean": 1.998590909090909,
      "high_std": 0.1573538865986655,
      "low_mean": 1.774190909090909,
      "low_std": 0.06411170243887147,
      "difference": 0.22440000000000015,
      "pct_difference": 12.648018815234611,
      "t_statistic": 6.194505159062565,
      "p_value": 2.0849442050143482e-07,
      "cohens_d": 1.8677135795028477
    },
    "tribalism": {
      "high_mean": 1.2120000000000002,
      "high_std": 0.08842776982481508,
      "low_mean": 1.091127272727273,
      "low_std": 0.0642386783192789,
      "difference": 0.12087272727272724,
      "pct_difference": 11.077784443111373,
      "t_statistic": 5.1871282244966,
      "p_value": 5.786937625385312e-06,
      "cohens_d": 1.5639780054652377
    },
    "depth": {
      "high_mean": 7.27410909090909,
      "high_std": 0.4564514003328295,
      "low_mean": 5.678136363636364,
      "low_std": 0.46436500580332146,
      "difference": 1.5959727272727262,
      "pct_difference": 28.107333552141768,
      "t_statistic": 11.496422546517634,
      "p_value": 1.4875810934151046e-14,
      "cohens_d": 3.4663018198346496
    },
    "authenticity": {
      "high_mean": 6.183772727272726,
      "high_std": 0.5058250301493006,
      "low_mean": 4.309499999999999,
      "low_std": 0.5067497278407426,
      "difference": 1.8742727272727269,
      "pct_difference": 43.49165163644802,
      "t_statistic": 12.278119220439558,
      "p_value": 1.744363446887403e-15,
      "cohens_d": 3.7019922350408145
    },
    "sophistication": {
      "high_mean": 6.728940909090909,
      "high_std": 0.45419915776388214,
      "low_mean": 4.993818181818183,
      "low_std": 0.47153728190367755,
      "difference": 1.735122727272726,
      "pct_difference": 34.74541251001234,
      "t_statistic": 12.430626595389889,
      "p_value": 1.1586917468497064e-15,
      "cohens_d": 3.7479749387201133
    },
    "disinhibition": {
      "high_mean": 1.6469272727272726,
      "high_std": 0.0918994076452135,
      "low_mean": 1.3946431818181817,
      "low_std": 0.08533675350584735,
      "difference": 0.2522840909090909,
      "pct_difference": 18.089508069023847,
      "t_statistic": 9.43553112360478,
      "p_value": 6.174571794295393e-12,
      "cohens_d": 2.844919675883414
    }
  },
  "correlation": {
    "sophistication_disinhibition": 0.6963889102061853
  }
}